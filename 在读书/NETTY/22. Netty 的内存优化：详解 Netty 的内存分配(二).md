大家好，上一章我为大家引入了内存分配体系的两个简单的小组件，并且，我相信在上节课也把该组件的功能以及实现原理讲解清楚了。所以在这一章，我将接着为大家引入内存分配体系的其他组件。比如，PoolArena 和 ByteBufAllocator。当然，这两个新的组件包含了很多知识，代码也就要一点点地迭代。在开始讲解之前，我再次给大家提一个小建议，不要对着我提供的代码敲。尤其是对着文章中提供的代码敲，因为文章中提供的代码都是极简版的，而且为了讲解顺利，大多还是伪代码，敲了也运行不起来。至于提供的 20 个版本源码，我建议大家不要照着源码一行行敲，如果你理解了文章的内容，也掌握了源码的编写思路，那么就自己去编写。对着源码复制一份代码毫无意义，只是做无用功而已。

**梳理内存分配流程**

上一章的结尾，我为大家把 PoolChunkList 和 PoolChunk 这两个类重构得差不多了，并且向大家提出了一个问题，问大家内存分配是从哪个类开始分配的，换句话说，就是在问大家内存分配的入口方法应该定义在哪个类中。上一章的结尾，我还未大家提供了下面的代码块。

java

复制代码

`//内存使用率为1%到50%%的Chunk集合 private final PoolChunkList<T> q000; //内存使用率为25%到75%的Chunk集合 private final PoolChunkList<T> q025; //内存使用率为50%到100%的Chunk集合 private final PoolChunkList<T> q050; //内存使用率为75%到100%的Chunk集合 private final PoolChunkList<T> q075; //内存使用率为100%的Chunk集合 private final PoolChunkList<T> q100; //内存使用率为0到25%的Chunk集合 private final PoolChunkList<T> qInit; //开始连接这些链表对象，可以发现，现在qInit对象成了头节点 qInit = new PoolChunkList<T>(this, q000, 0, 25, chunkSize); q000 = new PoolChunkList<T>(this, q025, 1, 50, chunkSize); q025 = new PoolChunkList<T>(this, q050, 25, 75, chunkSize); q050 = new PoolChunkList<T>(this, q075, 50, 100, chunkSize); q075 = new PoolChunkList<T>(this, q100, 75, 100, chunkSize); q100 = new PoolChunkList<T>(this, null, 100, Integer.MAX_VALUE, chunkSize); //通过上面的连接方式，这5个PoolChunkList对象的连接顺序就成了下面这样 //qInit ——> q000 ——> q025 ——> q050 ——> q075 ——> q100 //但是PoolChunkList对象构成的新链表是一个双向链表，因此，还要把前节点的指针补上 q100.prevList(q075); q075.prevList(q050); q050.prevList(q025); q025.prevList(q000); //这里可以看到，q000没有前置节点，这意味着当q000中的PoolChunk的内存使用率过低 //整个PoolChunk就会被释放了，不会再存在于链表中 q000.prevList(null) //这里可以看到qInit的前置节点是自己，这意味着当qInit中的PoolChunk的内存使用率低于临界值 //并不会被释放。其实也不会低于临界值了，因为qInit的最低内存使用率是0，PoolChunk的最低内存 //使用率也为0，就是相等的情况，既然相等，肯定就不会释放了，这个在下一章会在代码层面实现 //只有进入了q000集合中的Chunk才会被释放 qInit.prevList(qInit);`

可以看到，在上面的代码块中，这些成员变量的定义和创建非常随意，并没有放在具体的类中。因为我们还不能确定，内存分配究竟要从里开始，它的起点是什么。但我们肯定知道，绝对不会直接就从 PoolChunk 和 PoolChunkList 这两个类中直接开始分配。因为上一章我已经为大家分析过了，PoolChunk 这个类是内存分配的核心类，可以说，内存分配经过一个漫长的调用链路，最后就会在 PoolChunk 中把管理的 16 MB 内存分配出去一部分。而 PoolChunkList 就持有了多个 PoolChunk，所以，PoolChunkList 类中定义的 allocate 方法显然就会在 PoolChunk 上一层调用。那么，PoolChunkList 之上呢？这个类的 allocate 方法应该在哪个地方被调用呢？

在分析这个问题之前，我想先问问大家，提到内存分配，大家脑海中的分配过程是怎样的？或者说大家的分配思路是什么？再换句话说，是以哪里为入手点呢？难道创建一个对象就直接分配一点内存，那么创建对象的时候，要从哪里获得被分配的内存呢？要理清楚这个问题，就要从创建对象的起点开始思考。请大家想一想，当我们创建对象的时候，究竟是谁在执行这个动作？毫无疑问是线程，对吧？一旦启动一个新的线程，这个线程就要开始执行方法了，并且会在这个方法中执行另一个方法，在另一个方法中再执行另一个方法，如果方法链很长，这个线程就要执行很多方法，直到线程执行结束。在执行这些方法的过程中，难免会遇到创建对象，使用对象的情况，当对象使用结束，退出方法也就意味着引用消失了，那么对象就会等待被垃圾回收。好了，既然是线程来创建对象，那我是不是就可以这样认为，当一个线程在执行任务的过程中，需要创建对象了，就意味着要申请内存了。这时候恰好 PoolChunk 中提前申请了 16MB 的内存，并且可能有多个 PoolChunk 构成了 PoolChunkList，内存分配要先经过 PoolChunkList，由 PoolChunkList 对象内部判断哪个 PoolChunk 中管理的内存足够分配出去创建对象需要的内存，这样一来，创建对象的线程是不是就要首先去访问这个 PoolChunkList 链表了？而且还有一点大家要注意，线程不单单是访问 PoolChunkList 链表，而是首先访问 PoolChunkList 链表对象构建的那个链表，这个大家应该能理解吧。这就是我刚刚分析的内存分配的起点，就是需要内存的线程去访问由多个 PoolChunkList 链表对象构成的那个链表。然后会访问合适的 PoolChunkList，接着访问合适的 PoolChunk，在PoolChunk 中把内存真正分配给需要的对象。

既然内存分配的时候，线程首先要访问 PoolChunkList 链表对象构成的链表，但是现在这个最外层的链表连容身之处都没有，所以，为了在代码层面直观得展示一下刚才我分析的流程，现在，我打算为自己的内存分配器再引入一个新的组件，那就是 PoolArena 类，这个类的作用很简单，就是用来封装最开始我为大家展示的那一大段代码。请看下面的代码块。

java

复制代码

`abstract class PoolArena<T> {     //Chunk块的大小，也就是事先申请的一大块内存的大小，为16M     private static final int CHUNK_SIZE = 1024 * 1024 * 16;          //内存使用率为1%到50%%的Chunk集合 	private final PoolChunkList<T> q000; 	 	//内存使用率为25%到75%的Chunk集合 	private final PoolChunkList<T> q025; 	 	//内存使用率为50%到100%的Chunk集合 	private final PoolChunkList<T> q050; 	 	//内存使用率为75%到100%的Chunk集合 	private final PoolChunkList<T> q075; 	 	//内存使用率为100%的Chunk集合 	private final PoolChunkList<T> q100; 	 	//内存使用率为0到25%的Chunk集合 	private final PoolChunkList<T> qInit; 	      //构造方法，在构造方法中把定义的链表初始化，并且连接起来了      protected PoolArena(){          //开始连接这些链表对象，可以发现，现在qInit对象成了头节点 		 qInit = new PoolChunkList<T>(this, q000, 0, 25, chunkSize); 		 q000 = new PoolChunkList<T>(this, q025, 1, 50, chunkSize); 		 q025 = new PoolChunkList<T>(this, q050, 25, 75, chunkSize); 		 q050 = new PoolChunkList<T>(this, q075, 50, 100, chunkSize); 		 q075 = new PoolChunkList<T>(this, q100, 75, 100, chunkSize); 		 q100 = new PoolChunkList<T>(this, null, 100, Integer.MAX_VALUE, chunkSize); 		 //通过上面的连接方式，这5个PoolChunkList对象的连接顺序就成了下面这样 		 //qInit ——> q000 ——> q025 ——> q050 ——> q075 ——> q100 		 //但是PoolChunkList对象构成的新链表是一个双向链表，因此，还要把前节点的指针补上 		 q100.prevList(q075); 		 q075.prevList(q050); 		 q050.prevList(q025); 		 q025.prevList(q000); 		 //这里可以看到，q000没有前置节点，这意味着当q000中的PoolChunk的内存使用率过低 		 //整个PoolChunk就会被释放了，不会再存在于链表中 		 q000.prevList(null) 		 //这里可以看到qInit的前置节点是自己，这意味着当qInit中的PoolChunk的内存使用率低于临界值 		 //并不会被释放。其实也不会低于临界值了，因为qInit的最低内存使用率是0，PoolChunk的最低内存 		 //使用率也为0，就是相等的情况，既然相等，肯定就不会释放了，这个在下一章会在代码层面实现 		 //只有进入了q000集合中的Chunk才会被释放 		 qInit.prevList(qInit);      }     /**      * @Author: PP-jessica      * @Description:分配内存的方法，现在还是非常简化的方法，返回值并不正确      */     boolean allocate(int reqCapacity) {        //这里的优先使用哪个利用率范围的Chunk来分配内存也是很有讲究的，这里可以明显看到，是先从q050这个Chunk链表中的Chunk         //中分配的，之前我们提到过，Netty的内存分配有其自身的均衡之道，优先使用利用率范围在中间的Chunk，然后使用q025和q000以提高内存         //利用率，之所以把qInit放在第四是因为该Chunk链表中的Chunk不会被回收。而q075放在最后是因为这个链表中的Chunk使用率比较高         //分配内配不容易成功。大家可以在仔细品味品味。         if (q050.allocate(reqCapacity) || q025.allocate(reqCapacity) || q000.allocate(reqCapacity) || qInit.allocate(reqCapacity) ||                 q075.allocate(reqCapacity)) {             //分配成功就返回true             return true;         }         //程序第一次申请内存时，肯定还没有创建ChunkPool，这时候要创建一个chunk内存块         //如果上面都没有分配成功，那就意味着所有的chunk中剩余可分配内存都不够了，这时候就要创建         //新的PoolChunk，让操作系统帮助申请16MB内存供程序内部使用         //这里使用的是堆外内存，这是上一章的知识了         PoolChunk<T> c = new PoolChunk(new DirectByteBuffer(CHUNK_SIZE),CHUNK_SIZE);         //分配内存          boolean success = c.allocate(reqCapacity);         //接着把这个chunk内存块加入到init链表中         qInit.add(c);         return success;     } }`

根据上面的代码块，我们之后再分配内存的时候，就可以把 PoolArena 类中的 allocate 方法，当作内存分配的起点了。这样一来，只要程序中的线程需要创建对象了，就要从内存分配的起点类 PoolArena 中开始分配内存，经过一系列的方法调用，最终会在 PoolChunk 中得到分配的内存。这时候，我的内存分配系统的运行流程其实已经很清晰了。但是，还是那句老话，既然我们提到了线程， 就不得不考虑程序并发执行的情况，也就是多线程可能会带来的并发问题。说得直接一点，就是程序中如果只有一个线程执行任务，那没任何问题。可是，一旦有多个线程同时执行任务，这就意味着多个线程肯定会有很大的概率同时创建对象，如果是这样的话，多个线程肯定就要同时去分配内存吧？既然是同时分配内存，是不是就意味着要同时访问同一个 PoolArena 对象？也就意味着很可能同时访问同一个 PoolChunk。在上一章我已经让大家把内存当作字节数组了，既然是访问同一个字节数组，从字节数组中分配可用的空闲字节，多个线程同时操纵一个数组，显然，并发问题就会成为一个大麻烦了。

当然，事态还没有那么紧急。我们先不直接探讨针对内存分配的并发问题该怎么解决，让我们先来想想，就这么直接把 PoolArena 当作内存分配的最外层起点到底合适吗？如果程序中只有一个 PoolArena 对象，那么所有线程就直接就从 PoolArena 对象中分配内存，都来访问这个 PoolArena 对象似乎还挺合适的。但是，请大家想一想，如果我在自己的程序中创建多个 PoolArena 对象，这对我的程序来说，会有什么好处呢？首先有一个显而易见的好处，那就是在程序中可以创建更多的 PoolChunk 对象了，因为 PoolArena 是管理 PoolChunk 对象的最外层类，多创建一个 PoolArena 对象，程序中就可以多增加很多 PoolChunk 对象。这也就意味着会有更多的内存供程序使用。第二个好处就比较隐性一点了，没那么直接，但是其重要程度远远超过了第一个好处。让我来启发一下大家，当程序中有 10 个线程，但只有一个 PoolArena 对象，如果这 10 个线程恰好要在同一时间创建对象，要同时去访问 PoolArena 对象申请内存，先不管我们是否要使用同步锁来确保并发安全，只看并发量的话，这 10 个线程都去访问这一个 PoolArena 对象，并发量相对来说是很高的。可程序中又创建了一个 PoolArena 对象后，程序中就存在两个 PoolArena 对象。这时候，我们是不是就可以让 5 个线程访问同一个 PoolArena 对象，这么一来，每个 PoolArena 对象对接 5 个线程，对每一个 PoolArena 对象来说，并发量就大大减少了。如果使用同步锁的话，竞争同步锁的强度也就没那么强烈了。如果我们的程序中存在 5 个 PoolArena 对象，每个对象对接 2 个线程，我相信没有程序员会拒绝这种做法吧？

看到这里，我相信肯定有很多程序员有了一个新的想法，既然要解决并发问题，那为什么不最大限度的解决呢？比如说程序总有 10 个线程并发执行任务，需要并发申请内存，那就在程序中创建 10 个 PoolArena 对象，给每个线程分配一个 PoolArena 对象，这样一来不就没有并发问题了吗？这确实是一个不错的想法，尤其是结合 18 和 19 章讲解的对象池知识，运用无锁化思想解决并发问题，用空间换时间，非常不错的想法。技术本身是没有问题的，但是在真正的开发中，不得不考虑其他情况，就比如说，这个程序创建的 PoolArena 对象越多，那么这个程序就有可能让操作系统帮它申请的内存越多，尽管上一章我们讲解了，利用率非常低的 PoolChunk 会释放自己的持有的 16 MB 内存，但是这显然也有一点滞后。所谓滞后，就是在整个服务器中，其他正在运行的程序需要使用内存但是无法立刻让操作系统申请成功，因为更多的内存被 PoolChunk 对象申请走了，只能等它释放了，其他程序才能使用这些内存。因此，大家应该也意识到了，在程序中肯定不能随心所欲地创建 PoolArena 对象，要创建几个 PoolArena 对象，还是要经过设计的，最好和程序中存在的并发执行的线程数相关联。

究竟创建几个 PoolArena 对象，这个还要在编写代码的时候具体探讨一下。不过，让我们先来看看，既然程序中可以存在多个 PoolArena 对象，那大家就要认真思考一下了，内存分配从 PoolArena 开始进行分配，但是现在可以有多个 PoolArena，这就和 PoolChunk、PoolChunkList 一样了，显然是需要被管理的。否则线程开始申请内存的时候，要从哪个 PoolArena 对象中申请呢？这肯定需要经过精心规划呀。因此，PoolArena 显然也不太适合作为内存分配的起点，肯定也是需要被管理起来。就像创建了多个 PoolChunkList 链表对象，这几个链表对象需要交给 PoolArena 来管理，那么创建了多个 PoolArena 对象，肯定也需要交给某个组件来管理，这个逻辑理解起来没问题吧？

如果是这样，那我可不可以为我的内存分配系统定义一个最外层的内存分配组件，然后把创建的多个 PoolArena 对象，全都交给这个内存分配组件来管理。这个组件内部封装了所有的分配逻辑，然后对外暴露简单的方法即可，这样，当线程来申请内存的时候，直接调用这个内存分配组件暴露的方法即可。并且，我们还可以在这个内存分配组件中实现一个非常重要的功能，那就是把内部管理的 PoolArena 对象均分给程序内部并发执行任务的线程。这个逻辑并不难实现，很快我就会为大家分析其实现思路。但现在，我先为自己的内存分配系统引入这个新的组件，也就是 ByteBufAllocator 接口。通常，我都会直接称它为内存分配器。

**引入 ByteBufAllocator 内存分配器**

既然现在是要定义真正的内存分配器了，就不能只是嘴上说说了，要真正的为一个对象分配内存了。既然我们所有的努力都是为了实现 Netty 的内存分配系统，而 Netty 的内存分配系统是为 ByteBuf 来分配内存的，因此，从现在开始，我的程序就会为 ByteBuf 分配内存。在第 20 章的时候，我为大家把 Netty 中的 ByteBuf 做了一个细分，请看下面的代码块。

java

复制代码

`//非池化的堆内缓冲区 UnpooledHeapByteBuf //可池化的堆内缓冲区 PooledHeapByteBuf //可池化的堆外缓冲区 PooledDirectByteBuf //非池化的队内缓冲区 PooledHeapByteBuf`

因为 Netty 中默认使用的是 PooledDirectByteBuf 对象来作为消息数据的载体，因此，在我的内存分配系统中，最终就是为这个对象分配内存。该对象是 ByteBuf 抽象类的子类，这个在第 20 章已经讲过了，就不再重复了。

既然有了真正要分配内存的对象，接下来，我就可以定义自己的内存分配器接口中的方法了。请看下面的代码块。

java

复制代码

`//该接口并不完整，被我删去了部分方法，完整实现可从我为大家提供的源码中学习 public interface ByteBufAllocator {     //该方法就会为程序返回一个ByteBuf对象，其实就是PooledDirectByteBuf对象     //并且为PooledDirectByteBuf对象分配好可以存放数据消息的内存     //注意，这里我想再为大家强调一下，大家千万不要把ByteBuf对象持有的内存     //和这个对象本身占用的堆内存搞混了。Bytebuf对象被创建出来肯定是在堆中     //是要占用堆内存的，这点内存就从堆中分配。但是ByteBuf本身还包装着一块堆外内存     //这块堆外内存才是要从PoolChunk对象中分配的内存，这个千万不要搞混了     //该方法中没有任何参数，没有指定要给ByteBuf分配多少内存     //因此会使用程序中默认的值，下面两个方法都指定了要给ByteBuf分配的内存大小     ByteBuf buffer(); 	     ByteBuf buffer(int initialCapacity); 	//initialCapacity就是用户需要申请的内存     //maxCapacity就是可以分配给这个ByteBuf的最大内存，这个最大内存都会使用程序中的默认值     ByteBuf buffer(int initialCapacity, int maxCapacity); 	//该方法就是直接分配一块堆外内存，交给ByteBuf来包装     //并且返回该ByteBuf，显然，这个方法会被该接口中的第一个方法调用     ByteBuf directBuffer();     ByteBuf directBuffer(int initialCapacity);     ByteBuf directBuffer(int initialCapacity, int maxCapacity); }`

内存分配器的顶级接口已经定义好了，接下来，就该为该接口定义实现类了。但是在定义实现类之前，还是让我再来为大家分析一下。这个接口的实现类该怎么定义，直接定义成默认实现类吗？还是定义成一个抽象的实现类？其实这个问题的答案已经很明显了。既然在 Netty 中，最终使用的包装内存的对象分为池化的和非池化的，那么内存分配器自然也应该分为池化和非池化。所以，在 ByteBufAllocator 接口之下，不妨再定义一个抽象类 AbstractByteBufAllocator，在这个抽象类中定义一些公共的方法，然后再从这个抽象类开始细分，分为可池化的内存分配器和非池化的内存分配器，当然，这里说的池化指的是分配的内存是否可以池化。非池化的内存分配器可以定义为 UnpooledByteBufAllocator，而可池化的内存分配器可以定义为 PooledByteBufAllocator。具体的类关系，就像下面这幅简图展示得这样。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/49f38112ac1f42c09a14a05ef92dd9fc~tplv-k3u1fbpfcp-jj-mark:1890:0:0:0:q75.awebp#?w=1486&h=636&s=35341&e=jpg&b=ffffff)

当然，既然 Netty 中默认使用的是堆外内存，也就是 PooledDirectByteBuf 对象来作为消息的载体，所以，在文章中，我只讲解 PooledByteBufAllocator 类，因为该类就是专门用来为 PooledDirectByteBuf 分配堆外内存的。接下来，就让我来为大家展示一下，我定义好的 ByteBufAllocator 接口的实现类 AbstractByteBufAllocator 类。请看下面的代码块。

java

复制代码

`/**  * @Author: PP-jessica  * @Description:该类没有什么特别需要关注的方法，都是一些模版方法，交给不同的子类去实现  * 唯一值得重点关注的就是内存泄漏检测器。但是，这节课我们暂且注释掉，下一节课会继续讲解  */ public abstract class AbstractByteBufAllocator implements ByteBufAllocator {     //默认分配的内存的初始大小     static final int DEFAULT_INITIAL_CAPACITY = 256;     //默认的分配内存的最大值     static final int DEFAULT_MAX_CAPACITY = Integer.MAX_VALUE; 	//默认使用堆外内存     private final boolean directByDefault = true;      /**      * @Author: PP-jessica      * @Description:创建一个ByteBuf，也许是基于堆内存，也许是基于直接内存      */     @Override     public ByteBuf buffer() {         //这里为true，就创建一个直接内存的buffer         if (directByDefault) {             return directBuffer();         }         return heapBuffer();     }     /**      * @Author: PP-jessica      * @Description:创建一个ByteBuf，也许是基于堆内存，也许是基于直接内存      */     @Override     public ByteBuf buffer(int initialCapacity) {         if (directByDefault) {             return directBuffer(initialCapacity);         }         return heapBuffer(initialCapacity);     }     /**      * @Author: PP-jessica      * @Description:创建一个ByteBuf，也许是基于堆内存，也许是基于直接内存      */     @Override     public ByteBuf buffer(int initialCapacity, int maxCapacity) {         if (directByDefault) {             return directBuffer(initialCapacity, maxCapacity);         }         return heapBuffer(initialCapacity, maxCapacity);     }      /**      * @Author: PP-jessica      * @Description:创建一个ByteBuf，基于直接内存      */     @Override     public ByteBuf directBuffer() {         return directBuffer(DEFAULT_INITIAL_CAPACITY, DEFAULT_MAX_CAPACITY);     }     /**      * @Author: PP-jessica      * @Description:创建一个ByteBuf，基于直接内存      */     @Override     public ByteBuf directBuffer(int initialCapacity) {         return directBuffer(initialCapacity, DEFAULT_MAX_CAPACITY);     }     /**      * @Author: PP-jessica      * @Description:创建一个ByteBuf，基于直接内存      */     @Override     public ByteBuf directBuffer(int initialCapacity, int maxCapacity) {         if (initialCapacity == 0 && maxCapacity == 0) {             return emptyBuf;         }         validate(initialCapacity, maxCapacity);         return newDirectBuffer(initialCapacity, maxCapacity);     }     //接下来就是两个抽象方法     //该方法用来创建堆内存的对象，在我们的课程中不会使用这个方法     protected abstract ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity); 	//这个方法就是创建一个使用堆外内存的ByteBuf对象     protected abstract ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity);     private static void validate(int initialCapacity, int maxCapacity) {         checkPositiveOrZero(initialCapacity, "initialCapacity");         if (initialCapacity > maxCapacity) {             throw new IllegalArgumentException(String.format(                     "initialCapacity: %d (expected: not greater than maxCapacity(%d)",                     initialCapacity, maxCapacity));         }     } }`

接下来就是真正的可池化的堆外内存的内存分配器 PooledByteBufAllocator。

java

复制代码

`/**  * @Author: PP-jessica  * @Description:该类就是分配池化内存的内存分配器  */ public class PooledByteBufAllocator extends AbstractByteBufAllocator{     //这里有两个PoolArena的数组，一个数组的泛型为字节数组，一个数组的泛型为ByteBuffer     //显然，为Byte数组就意味着PoolChunk包装的堆内存，而使用的是ByteBuffer的，就意味着     //PoolChunk管理的是操作系统帮忙申请的堆外内存，在我们的文章中，重点讲解的是第二个成员变量     //也就是directArenas，第一个大家可以自行到源码中学习     private final PoolArena<byte[]>[] heapArenas;          private final PoolArena<ByteBuffer>[] directArenas;     /**      * @Author: PP-jessica      * @Description:池化的内存分配器在这里创建了      */     public static final PooledByteBufAllocator DEFAULT =             new PooledByteBufAllocator();      /**      * @Author: PP-jessica      * @Description:池化的内存分配器的核心构造函数，这里也先不实现      */     public PooledByteBufAllocator(){              }               //下面这两个就是要实现的父类的抽象方法     @Override     protected ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity) {         //我们的文章并不涉及堆内存的分配，所以这个方法就做一个空实现好了         return null;     }     /**      * @Author: PP-jessica      * @Description:创建一个直接内存的ByteBuf，      */     @Override     protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) {         //暂时先不实现，但是大家肯定可以猜出来，PoolArena的allocate方法肯定要在         //这个方法中被调用     } }`

在上面的代码块中，一个十分简陋的内存分配器就实现了，并且，这个内存分配器中也定义了 PoolArena 对象的数组，到这里，我们终于可以明白了，程序中确实要创建多个 PoolArena 对象交给内存分配器来管理，至于这些 PoolArena 对象要怎么创建，也就是 PoolArena 数组该怎么初始化，以及之后要怎么分配给线程，解决多线程申请内存的并发问题，后面的内容再进行讲解。总之，到此为止，内存分配器终于实现了，我们也可以明确了，这个内存分配器，就是内存分配的最外层的入口。假如在我的内存分配系统中，要给一个 ByteBuf 对象分配其包装的堆外内存，现在我就可以这么做了。请看下面的代码块。

java

复制代码

`public class PooledByteBufAllocatorTest {     public static void main(String[] args) {         //直接创建一个池化的直接内存分配器，该分配器默认分配的都是直接内存，当然也可以分配堆内存，但一般不会走到那些分支中去         PooledByteBufAllocator pooledAllocator = PooledByteBufAllocator.DEFAULT;                  //申请2KB的直接内存，其实真正创建的是PooledDirectByteBuf对象，但这里把它的父类PooledByteBuf返回了         PooledByteBuf byteBuf = (PooledByteBuf) pooledAllocator.buffer(1024 * 2);     } }`

当程序执行到上面代码块的第 6 行时，也就是执行到 PooledByteBufAllocator.DEFAULT 这行代码，程序就会随着这行代码来到 PooledByteBufAllocator 类内部，执行该类的构造方法，但是该类的构造方法目前我们还未实现，所以大家在脑海里想象一下即可。然后，得到了分配可池化的堆外内存的内存分配器，程序就会使用这个分配器真正开始分配内存了，所谓分配内存，就是创建一个 ByteBuf 对象，同时向程序内部管理的堆外内存中申请一块 2 KB 的内存交给这个 ByteBuf 对象使用，最后把这个 ByteBuf 对象返回给用户。当程序执行 pooledAllocator.buffer(1024 * 2) 这行代码的时候，其实执行的就是 PooledByteBufAllocator 父类 AbstractByteBufAllocator 中的 buffer(int initialCapacity) 方法，就是下面代码块中的方法。

java

复制代码

`/**  * @Author: PP-jessica  * @Description:创建一个ByteBuf，也许是基于堆内存，也许是基于直接内存  */ @Override public ByteBuf buffer(int initialCapacity) {     if (directByDefault) {         return directBuffer(initialCapacity);     }     return heapBuffer(initialCapacity); }`

而执行这个代码块中的方法时，程序就会调用到 directBuffer(initialCapacity) 方法。该方法也是 AbstractByteBufAllocator 类中的方法。请看下面代码块。

java

复制代码

`/**  * @Author: PP-jessica  * @Description:创建一个ByteBuf，基于直接内存  */ @Override public ByteBuf directBuffer(int initialCapacity) {     return directBuffer(initialCapacity, DEFAULT_MAX_CAPACITY); }`

在上面这个代码块中，程序又会执行到 directBuffer(initialCapacity, DEFAULT_MAX_CAPACITY) 这个方法，其中 initialCapacity 是用户指定的申请内存的大小，DEFAULT_MAX_CAPACITY 是 AbstractByteBufAllocator 类中的一个成员变量，是可分配的最大内存的默认值。directBuffer 也是 AbstractByteBufAllocator 类中的方法，代码如下。

java

复制代码

`/**  * @Author: PP-jessica  * @Description:创建一个ByteBuf，基于直接内存  */ @Override public ByteBuf directBuffer(int initialCapacity, int maxCapacity) {     if (initialCapacity == 0 && maxCapacity == 0) {         return emptyBuf;     }     validate(initialCapacity, maxCapacity);     return newDirectBuffer(initialCapacity, maxCapacity); }`

在上面的代码块中，最终会执行到 newDirectBuffer(initialCapacity, maxCapacity) 这个方法，而这个方法就是 AbstractByteBufAllocator 类中的抽象方法了，是需要让子类来实现的。而 AbstractByteBufAllocator 的子类就是 PooledByteBufAllocator 类，当然，我目前还没有在 PooledByteBufAllocator 类中实现 newDirectBuffer 方法。但是，我相信大家一定会都能想到，接下来肯定就要执行真正的内存分配的流程了。在这个过程中肯定会创建一个 PooledDirectByteBuf 对象，因为最后返回给了用户这样一个对象，而分配好的内存最终就会交给 PooledDirectByteBuf 对象来使用。其实到这里，就和我们之前讲解过的知识连接起来了，既然 PooledByteBufAllocator 类中定义了 PoolArena 对象的数组，那么在 PooledByteBufAllocator 类的 newDirectBuffer 方法中，不用我说大家应该也能想到了，肯定就是使用 PoolArena 数组中的某个 PoolArena 对象开始分配内存，一旦开始申请了，接下来就会经过 PoolArena 对象管理的那些 PoolChunkList 链表对象了，一旦经过 PoolChunkList 链表对象了，就肯定要进一步访问 PoolChunkList 内部管理的 PoolChunk 对象了，最终从 PoolChunk 对象中把需要的内存分配出来，交给 PooledDirectByteBuf 对象来使用。在下面的简图中，我为大家把整个分配内存的流程展示出来了，当然，内部的具体细节是缺失的，在后面随着代码的重构，不不断完善和补充的。请看下面的流程简图。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1ec2550d68024d7193cdd30bc4d4ced5~tplv-k3u1fbpfcp-jj-mark:1890:0:0:0:q75.awebp#?w=660&h=680&s=25256&e=jpg&b=fefefe)

根据上面的流程图，我们也能清楚地看到，如今我自己的内存分配系统中，PooledByteBufAllocator 就是内存分配的起点类，而 PoolChunk 就是内存分配的重点类。当然，这里定论的一切都是基于目前的内存分配系统，如果内存分配系统又经过重构，新的组件被添加进来，内存分配的流程当然又会有新的变动。所以，接下来，我当然就要继续完善我的内存分配系统，在分析中思考内存分配系统的不足之处。那目前整个程序中最大的不足就是有几个方法尚未实现，就是最关键的 allocate 方法从来还没有真正实现过。这个方法在很多个组件中都存在，是很多组件中都存在的同名方法。之前一直没有实现是因为时机不对，现在我已经指定了自己的内存分配系统转为 ByteBuf 对象分配可以使用的堆外内存，恰好在上面我也再一次为大家简单回顾了一下 PooledDirectByteBuf，所以，接下来，我就开始着手实现程序中的多个 allocate 方法，让该方法专门为 PooledDirectByteBuf 对象分配内存。但是，在实现这些方法之前还有一件事，那就是为大家剖析一下分配到的内存究竟该怎么交给 PooledDirectByteBuf 对象使用。而且，我好像也还没和大家讲解 PooledDirectByteBuf 的内部结构呢。那么，接下来就让我们来看看 PooledDirectByteBuf 这个类吧。

**PooledDirectByteBuf 的简单构造**

我们文章的重点是内存分配，并不是 PooledDirectByteBuf 这个类本身，因此，我并不会花费大量的时间来为大家讲解这个类，我只会讲解最关键的地方。我相信文章讲解到这里，大家应该对 Netty 自己定义的 ByteBuf 有一个清晰的概念了。所谓的 ByteBuf，其本质和 ByteBuffer 是一样的，这个对象本身不会存储任何字节消息，真正存储消息的是这个对象内部持有的一块字节数组，或者是一块堆外内存。如果使用的是堆外内存存放要收发的字节消息，那么 ByteBuffer 内存持有的就是一个堆外内存的地址，然后通过 Unsafe 对象直接操纵这个地址，以这个堆外内存的地址为起点，开始向之后连续的内存空间中存放字节消息。这些知识和代码在第 20 章都讲解过了，所以这里就不再重复展示代码了。

我刚才说了，ByteBuf 和 ByteBuffer 的本质是类似的，如果使用的是堆内存，那么 ByteBuf 对象内部直接持有一个字节数组即可，如果使用的是堆外内存，那么 ByteBuf 持有的就是一个堆外内存的地址，然后通过 Unsafe 对象操纵这个地址。并且，我还记得我在第 20 章的时候跟大家讲过，既然使用堆外内存的方式和 ByteBuffer 一模一样，就可以直接把一个 ByteBuffer 交给 ByteBuf 来管理，这样一来，虽然堆外暴露的是 ByteBuf 的方法，好像在操作这个 ByteBuf 对象，其实内部真正操作的还是 ByteBuf 持有的这个 ByteBuffer 对象，如果进一步查看，会发现 ByteBuffer 对象内部实际上就是 Unsafe 对象在操作一个堆外内存的地址。如果用一幅流程简图来概括的话，就可以画成下面这样。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5574476ac02f4ed1bb6088fac5657d83~tplv-k3u1fbpfcp-jj-mark:1890:0:0:0:q75.awebp#?w=644&h=602&s=33926&e=jpg&b=fefefe)

如果上面这个逻辑大家已经理解了，那么接下来，我们就该认真想想了，一个 ByteBuffer 该怎么交给 ByteBuf 来包装呢？这也是第 20 章的知识，但是在那一章里我只是简单的提了一句，并没有真正为大家讲解 ByteBuf 的内部结构。当然，我指的是 PooledDirectByteBuf 这个类的内部结构，因为这个类的对象就是用来当作 Netty 中收发消息的载体。既然这个类要管理一个 ByteBuffer，那是不是就意味着这个 PooledDirectByteBuf 类中要定义一个 ByteBuffer 成员变量了？那么，这个 ByteBuffer 成员变量怎么被赋值呢？确切地说，在哪里赋值，被谁赋值呢？要弄清楚这个问题，我们就又要回到内存分配的本质上来了。请大家跟我一起思考下面一个场景。

大家都知道，内存其实就可以当成一大块连续的字节数组，不管是使用堆外内存还是堆内存，只要我得到了一个内存地址，就可以把该地址当作起点，然后操作该地址之后的连续内存。举一个最简单的例子，比如操作系统帮助程序申请了一块堆外内存，把返回的堆外内存的首地址交给了 ByteBuffer 来保管，现在堆外内存的起始地址有了，如果程序一开始申请的就是 32 个字节大小的堆外内存，那么就以堆外内存的起始地址为起点，可以向该地址以及之后连续的 32 个空闲字节中写入数据了。直接调用下面代码块的 put(byte x) 方法即可。请看下面代码块。

java

复制代码

`//可以看到，该类并没有直接继承ByteBuffer，而是继承了MappedByteBuffer类，该类继承了ByteBuffer class DirectByteBuffer extends MappedByteBuffer implements DirectBuffer{     //首先得到了Unsafe类的对象，这个对象可以处理一些底层操作，比如说分配对外内存     protected static final Unsafe unsafe = Bits.unsafe();     //在下面这个构造方法中，分配到的堆外内存的起始地址就赋值给了ByteBuffer     //中的address成员变量，Unsafe对象就可以操作这个内存地址     DirectByteBuffer(int cap) {         super(-1, 0, cap, cap);         //直接内存是否按页对齐         boolean pa = VM.isDirectMemoryPageAligned();         //得到每一页的大小         int ps = Bits.pageSize();         //该方法作用就是在要申请的内存的基础上多增加一页，得到真正要分配的内存         long size = Math.max(1L, (long)cap + (pa ? ps : 0));         //这里就是在真正分配内存之前，先看看内存充足，是否可分配这么多内存         //当然，这里判断的是虚拟机可以使用的直接内存是否充足         //如果不够就要进行内存释放，总之，要保证有充足的内存可以被分配出来         Bits.reserveMemory(size, cap);         long base = 0;         try {             //size就是要真正分配的内存大小，Unsafe对象真正分配了内存             base = unsafe.allocateMemory(size);         } catch (OutOfMemoryError x) {             Bits.unreserveMemory(size, cap);             throw x;         }         //初始化内存，默认每一位都是0         unsafe.setMemory(base, size, (byte) 0);         if (pa && (base % ps != 0)) {             //给address赋值，分配的对外内存的地址就在这里赋值了             //这个成员变量是定义在顶级父类Buffer中的             address = base + ps - (base & (ps - 1));         } else {             address = base;         }         //这里创建了一个cleaner对象，并且该对象关联了这个DirectByteBuffer         //因为是对外内存，不可能直接被虚拟机垃圾回收，所以关联DirectByteBuffer         //DirectByteBuffer是堆内的对象，可以被垃圾回收，当这个对象被垃圾回收后         //cleaner就会感知到，然后通知堆外内存释放         cleaner = Cleaner.create(this, new Deallocator(base, size, cap));         att = null;     }     //这是两个读取字节消息的方法     //可以看到都是unsafe来操纵的     public byte get() {         return ((unsafe.getByte(ix(nextGetIndex()))));     }     public byte get(int i) {         return ((unsafe.getByte(ix(checkIndex(i)))));     }     //下面是两个写入字节消息的方法，也都是unsafe来操纵的     public ByteBuffer put(byte x) {         unsafe.putByte(ix(nextPutIndex()), ((x)));         return this;     }     public ByteBuffer put(int i, byte x) {         unsafe.putByte(ix(checkIndex(i)), ((x)));         return this;     }     //该方法就是计算要操作的具体的内存地址     //就是用起始内存地址加上偏移量     private long ix(int i) {         return address + ((long)i << 0);     } }`

上面的代码块大家肯定很熟悉，在第 20 章已经见过了。不过，现在我不想以分配到的堆外内存的地址为起始地址了。我想自己指定地址，然后向这个指定地址之后写入字节消息。这该怎么做呢？要想彻底搞清楚这个问题，就应该先弄清楚，操作系统申请了堆外内存之后，返回给程序的堆外内存的地址究竟是什么？这个问题对大家来说应该很简单了吧，所谓的这个地址，其实就是内存中每个字节位置的编号。这在上一章一开始就为大家讲解了。请看下面的简图。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b285292ce0f14b2c9bf2a8d247def233~tplv-k3u1fbpfcp-jj-mark:1890:0:0:0:q75.awebp#?w=1270&h=704&s=53495&e=jpg&b=fefefe)

如果操作系统要帮助程序申请一块堆外内存，肯定也是到整个内存中申请，而整个内存实际上就是一大块字节数组。如果要申请 32 字节的堆外内存，并且内存数组是完全空闲的，是不是就直接可以把 0 到 31 字节分配给程序使用。这时候，程序中的那个 ByteBuffer 中的 address 就会被 0 赋值，这个不难理解吧？如果要向这块堆外内存中写入字节，就可以让 Unsafe 对象操作这个 0 地址，直接向其后面的空闲字节中写入数据。但现在我厌倦了总是看见 0 了，我不想总是从 0 开始写入数据，我想可以自己指定一个位置，就比如说从 2 开始写入数据。这样的话，我们只要得到 2 这个内存地址不就行了吗？而得到这个地址的方法十分简单，就是直接让起始地址 0 加上内存偏移量 2，得到的就是 2 这个地址。因为每个内存单元都代表一个字节，也就是每个内存地址都对应一个字节，所以才可以这样直接相加，得到用户想使用的地址。如果用代码表示，调用的就是 DirectByteBuffer 类中的 put(int i, byte x) 方法，其中参数 i 代表的就是用户指定的这个地址相对于分配到的堆外内存起始地址的偏移量，参数 x 就是要写入的字节数。具体代码如下。

java

复制代码

 `public ByteBuffer put(int i, byte x) {     //checkIndex方法是为了保证用户指定的这个位置不会超过ByteBuffer可以使用内存最大容量     //其实就是limit     unsafe.putByte(ix(checkIndex(i)), ((x)));     return this; } //该方法就是计算要操作的具体的内存地址 //就是用起始内存地址加上偏移量 private long ix(int i) {     return address + ((long)i << 0); }`

当用户调用上面代码块的 put 方法时，用户会觉得自己仅仅是在操作一个字节数组，指定的 i 实际上就是字节数组的索引下标。不管操作系统给用户分配到的堆外内存的起始地址是多少，对用户来说，似乎都是从字节数组的 0 号索引位置开始向数组中写入数据的。现在，用户想直接从字节数组的 3 号位置还是写入数据，于是直接传入参数 3。所以，3 就是相对于字节数组首地址的偏移量，让 0 加上 3 就能得到 Unsafe 对象要操作的地址。具体方法的逻辑就在上面代码块的 ix 方法中。那如果堆外内存的起始地址并不是 0 ，而是 8 呢？这也很简单，继续沿用上面的思路分析即可，既然这个堆外内存的起始地址得到了，就是 8，当然，这个地址对用户来说仍然是透明的，用户感知不到，仍然会觉得自己操控的只是一个字节数组。现在用户想往字节数组的第 5 位写入数据，那么直接让起始地址 8 加上偏移量 5，得到的不就是 Unsafe 对象应该操作的内存地址了吗？得到的内存地址为 13，这个 13 就是一个真正的内存地址，相对于内存的起始地址 0，偏移量是 13。这些逻辑，我相信大家应该也明白了。总结起来就是一句话，只要给我们一个内存起始地址和偏移量，我们就可以得到一个新的，并且是可以具体操作的内存地址。

可是我们最终要解决的是 ByteBuffer 对象怎么交给 ByteBuf 来管理，对吧？刚才讲的那些东西好像和我们要解决的问题毫不相干，那我剖析那些逻辑有什么用呢？当然是有用处的，请大家换一个更加开阔的视角去思考一下，既然给我们一个内存起始地址和偏移量就可以得到一个新的内存地址，而这个内存地址就是用户想要直接操作的地址，换句话说，知道一个内存起始地址和偏移量，就可以在合理的范围内操纵任何地址，以新的地址为起点开始写入字节数，不同的偏移量都会对应不同的内存地址。如果是这样，那么，请大家仔细想想，在我目前的内存分配系统中，是不是已经引入了 PoolChunk 类？并且如果使用的是堆外内存，那么 PoolChunk 中是不是持有了一个ByteBuffer 对象？这是上一章的知识，请看下面的代码块。

java

复制代码

`final class PoolChunk<T>{ 	//这个成员变量就是用来对接事先申请好的内存的     final T memory;     //当前Chunk还可以分配的字节数量     private int freeBytes;     //该Chunk属于哪个PoolChunkList     PoolChunkList<T> parent;          //该Chunk内存块在PoolChunkList中的前驱节点     PoolChunk<T> prev;          //该Chunk内存块在PoolChunkList中的下一个节点     PoolChunk<T> next;     //构造方法     PoolChunk(T memory,int chunkSize){         this.memory = memory;         //该chunk内存块还可以分配的内存值，初始值为16MB         freeBytes = chunkSize;     }     //该方法就是Poolchunk分配内存的方法，在该方法中，会进行内存的分配     //分配成功了就返回true，失败则返回false     //多了一个参数，就是要分配的内存大小     boolean allocate(int reqCapacity) {         //暂且不实现         //但这里我要多解释一下，freeBytes会在每次分配出一点内存后就更新一下         //就是减去分配出去的内存大小     }     /**      * @Author: PP-jessica      * @Description:计算该Chunk的内存利用率的方法      */     @Override     public int usage() {         final int freeBytes = this.freeBytes;               return usage(freeBytes);     }     /**      * @Author: PP-jessica      * @Description:计算该Chunk的内存利用率的方法      */     private int usage(int freeBytes) {         if (freeBytes == 0) {             //走到这里说明利用率已经100%了             return 100;         }         //chunkSize是16MB         int freePercentage = (int) (freeBytes * 100L / chunkSize);         //因为int会省略小数点，所以走到这里肯定就是0.xx         //剩余这么多，说明使用了99。xx%，因此直接返回99，说明使用了99%了         if (freePercentage == 0) {             return 99;         }         //减去剩下的百分比，就是使用的百分比         return 100 - freePercentage;     }     //其他的方法暂时不考虑实现 }`

在 PoolChunk 中有一个 memory 成员变量，如果 PoolChunk 管理的是堆外内存，那么这个 memory 就会被一个 ByteBuffer 对象赋值，而 ByteBuffer 对象在创建的时候，就会让操作系统申请 16 MB 的内存，交给 ByteBuffer 对象管理。就像下面这样。

java

复制代码

`//使用直接内存的情况 new PoolChunk<ByteBuffer>(allocateDirect(chunkSize),chunkSize); //接下来就是allocateDirect方法的逻辑，从名字上就能看出来，该方法是用来分配直接内存的 /**  * @Author: PP-jessica  * @Description:分配直接内存的方法  */ private static ByteBuffer allocateDirect(int capacity) { 	//这里可以看到，就是直接分配了一个DirectByteBuffer     return  ByteBuffer.allocateDirect(capacity); } //这个方法上一章应该都已经讲过了吧，到此为止，就和上一章的内容衔接起来了 public static ByteBuffer allocateDirect(int capacity) {     return new DirectByteBuffer(capacity); }`

当然，这都是上一章的知识了，这里重新回顾它们，是因为很快我就要将这个 ByteBuffer 对象和 ByteBuf 对象连接起来。在第 20 章的时候，我为大家提供了一幅简图，简单展示了一下以堆外内存为例的几个类的结构关系。就是下面这幅简图。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e1d903842bb2491bbdbd8d44254f312e~tplv-k3u1fbpfcp-jj-mark:1890:0:0:0:q75.awebp#?w=830&h=717&s=20383&e=jpg&b=ffffff)

可以看到，在 PooledByteBuf 类下面直接就是 PooledDirectByteBuf 类了。但实际上，还有另一个类也是 PooledByteBuf 的子类。类比一下 ByteBuffer 的类关系，在 Netty 中可以使用的内存也应该分为直接内存和堆外内存，那么 PooledByteBuf 这个类继续细分，其实就可以分为 PooledDirectByteBuf 和 PooledHeapByteBuf 类。在 Netty 中默认使用的是 PooledDirectByteBuf，所以我才在文章中一直以这个类为例子为大家讲解知识。那么，请大家想一想，目前的情况，其实就已经可以仿照 PoolChunk 来定义 PooledByteBuf 类中的成员变量了。比如说，因为不能确定用户究竟想使用堆内存还是堆外内存，所以在 PoolChunk 中定义了一个泛型成员变量 memory，如果使用的是堆内存，就创建一个字节数组为该成员变量赋值，如果使用的是堆外内存，就创建一个 ByteBuffer 为该成员变量赋值。那么，在 PooledByteBuf 类中，因为也不能确定用户究竟是想要使用 PooledDirectByteBuf 堆外内存缓冲区还是 PooledHeapByteBuf 堆内存缓冲区来作为收发消息的载体，因此，我是不是就可以直接在 PooledByteBuf 类中也定义一个泛型成员变量 memory？就像下面这样。

php

复制代码

`/**  * @Author: PP-jessica  * @Description:该类是池化内存的一个抽象类，它的构造方法非常重要，创建的ByteBuf都要向上调用到该类的构造方法中  */ public abstract class PooledByteBuf<T>{          protected T memory;     //其他的内容暂不实现 }`

为什么我要突然在 PooledByteBuf 类中定义一个泛型成员变量，我来给大家解释一下，实际上，我的思路很简单，这里的这个泛型 memory 成员变量，对应的就是 PoolChunk 中的那个 memory 成员变量。我们就以堆外内存为例，既然创建一个 ByteBuf 对象的同时，就要给这个 ByteBuf 对象分配内存，而这个内存还是堆外内存，这个堆外内存还被一个 ByteBuffer 对象包装着。而所谓的堆外内存其实就是一个 Unsafe 对象可操作的内存地址。既然是这样，我把那个创建好的 ByteBuffer 对象也赋值在这里，那么，这个 PooledByteBuf 不就也可以得到堆外内存的起始地址了吗？这个时候，在程序中持有着这个 ByteBuffer 对象引用的就不只是 PoolChunk 对象了，还有这个新创建的 PooledByteBuf 对象。这样一来，当我们调用 PooledByteBuf 的方法来向这个 PooledByteBuf 缓冲区中写入字节消息的时候，表面上调用的是该对象的方法，实际上，真正操作的还是这个 memory 成员变量，也就是一个 ByteBuffer 对象，更进一步，操作的起始就是 ByteBuffer 对象持有的 堆外内存的起始地址，这就是 Unsafe 对象要干得活了。

当然，我知道大家肯定会有一个疑问，这一套流程之前已经很熟悉了，把 PoolChunk 持有的 ByteBuffer 放在这里听起来很有道理，但是该怎么操作呢？程序内部内存分配体现何在呢？哪里体现出把操作系统申请到的内存，也就是 PoolChunk 中持有的那个 ByteBuffer 合理地分配给程序内部使用了呢？别着急，我这就要讲到了。在我的内存分配系统中，每创建一个 ByteBuf 对象，肯定要去 PoolChunk 中为这个对象分配指定的堆外内存。如果现在有一块完整的 16 MB 堆外内存交给一个 PoolChunk 对象来保管了，并且这 16 MB 内存已经分配出去了 4 个字节。现在要继续分配出去 4 个字节让程序内部使用。如下图所示。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d58c5724e3d045bf9a60d082a7b69a27~tplv-k3u1fbpfcp-jj-mark:1890:0:0:0:q75.awebp#?w=1108&h=704&s=46947&e=jpg&b=fefefe)

前四个字节已经分配出去了，那就是第 16 到 19 字节都无法使用了。现在要从第 20 的位置开始分配，分配出去 4 个字节让程序内部使用。是不是直接就把 20 这个内存地址分配出去呢？把这个地址交给 ByteBuf 对象使用就行。如果是这样，那就舍近求远了，为什么这么说，因为堆外内存的地址需要 Unsafe 对象操作才能发挥作用，ByteBuf 中并没有 Unsafe 对象呀，Unsafe 对象在 ByteBuffer 中，而 ByteBuffer 已经被 ByteBuf 对象持有了，对吧，我刚刚把 PoolChunk 中的 memory 属性赋值给 PooledByteBuf 中的 memory 属性。但是在 ByteBuf 对象中是无法把 ByteBuffer 对象中的 Unsafe 对象取出来直接使用的。Unsafe 对象只能在 ByteBuffer 对象中使用，而交给 ByteBuf 的这个 20 内存地址，ByteBuffer 中的 Unsafe 对象也是无法得到的，这就很尴尬了。那该怎么办呢？其实很简单，就让 ByteBuffer 中的 Unsafe 继续操纵内存地址就行了，那该怎么操纵呢？让起始内存地址加上偏移量，这样一来，ByteBuffer 中的 Unsafe 对象就仍然可以操纵这个内存地址。比如说，现在明确要把 20 这个内存地址返回给程序使用，但并不直接返回这个地址，而是直接返回一个偏移量，20 这个地址距离这块 16 MB 的堆外内存的起始地址的偏移量是 4，那么就把 4 返回出去，交给 ByteBuf 对象来保管。说来说去不如几行代码直观，下面请大家看一下我重构之后的 PooledByteBuf 类。

java

复制代码

`public abstract class PooledByteBuf<T> {     //这个属性就是表明了这个PooledByteBuf对象使用的     //堆外内存是从哪个PoolChunk中分配来的     protected PoolChunk<T> chunk;     //把PoolChunk管理的ByteBuffer的引用也赋值给这里     //这样一来，该类也可以直接使用ByteBuffer的方法来直接操作堆外内存了     protected T memory;     //每创建一个PooledByteBuf对象，就要从PoolChunk持有的堆外内存中分配一块内存     //但是并不直接返回分配到的内存起始地址，而是返回分配到的内存地址距16MB堆外内存起始地址的偏移量     protected int offset;     //PooledByteBuf对象分配到的内存大小     protected int length;     //给成员变量赋值的方法，该方法会在PoolChunk类中被调用     void init(PoolChunk<T> chunk,int offset, int length) {         init0(chunk, offset, length);     }     private void init0(PoolChunk<T> chunk,int offset, int length) {         assert chunk != null;         this.chunk = chunk;         memory = chunk.memory;         this.offset = offset;         this.length = length;     }     //写入字节的方法，这里的index参数，其实很好理解。因为在用户看来他得到的是一个ByteBuf     //对象，他操作的就是这个对象中的字节容器，这个字节容器对用户来说就是从0到其容量这么大     //所以用户指定了index为几，就希望把字节消息从字节容器的第几位开始写入     public ByteBuf setByte(int index, int value) {         memory.put(idx(index), (byte) value);     }     protected final int idx(int index) {         return offset + index;     } }`

创建好一个 PooledByteBuf 对象的时候，该对象内部的成员变量都会赋值成功，其中最重要的 memory 和 offset 都会赋值成功。offset 就是从 PoolChunk 中分配到的内存相对于 PoolChunk 内部持有的 16 MB 堆外内存起始位置的偏移量，这个一定要理清楚。如果现在要调用 PooledByteBuf 的 setByte(int index, int value) 方法，在指定的位置写入指定的值，程序就会执行 memory.put(idx(index), (byte) value) 这行代码，在这行代码中，会执行 idx(int index) 方法，在这个方法中，会用 offset 加上用户指定 index，就得到了一个新的内存偏移量，这个偏移量就是用户真正要操作的内存地址。而得到了这个新的偏移量，会被传到 memory 对象的 put 方法中。memory 不就是 ByteBuffer 吗？其 put 方法已经讲解过了呀。就是下面代码块展示的这样。

java

复制代码

 `//下面是两个写入字节消息的方法，也都是unsafe来操纵的     public ByteBuffer put(int i, byte x) {         unsafe.putByte(ix(checkIndex(i)), ((x)));         return this;     }     //该方法就是计算要操作的具体的内存地址     //就是用起始内存地址加上偏移量     private long ix(int i) {         return address + ((long)i << 0);     }`

在 ByteBuffer 中，会根据传入的这个真正的内存偏移量，再和 address 相加，address 就是为 PoolChunk 分配的 16 MB 堆外内存的起始地址，这样一来，就得到了一个真正的内存地址，而这个内存地址，就是用户想要写入数据的起始地址。到此为止，我们就把 PooledByteBuf 的核心功能讲解完了，同时大家应该也能明白了，所谓的从 PoolChunk 管理的 16 MB 堆外内存中分配内存，其实最终需要的就是分配到的内存相对于 16 MB 内存起始地址的内存偏移量，这个是最重要的。内存分配系统最终分配给每一个 ByteBuf 对象的，也就是这个内存偏移量。同时大家应该也能意识到，使用堆外内存的情况下，程序内部创建的每一个 ByteBuf 对象其内部其实都会持有一个 ByteBuffer 的引用，就是那个 memory 成员变量。这样，才能通过 ByteBuffer 中的 Unsafe 对象来直接操作堆外内存。当然，中间被赋值的过程我还没为大家讲解，这是后面两章的知识，大家先明白原理即可。

讲到这里，PooledByteBuf 类的核心功能其实就讲得差不多了，但是这个类的子类 PooledDirectByteBuf，才是我们真正要用到的类呀，在程序中创建的所有 ByteBuf 对象，实际上都是 PooledDirectByteBuf 类的对象。这个类我还没有为大家讲解。但说实话，这个类没什么可讲的，只有一个知识点，而且是旧知识。大家都知道，以 Netty 构建的客户端和服务端要进行网络通信，而网络通信其实就是收发消息，消息虽然是存放到内存中，但是为了方便大家操纵这些字节消息，于是给大家提供了一个缓冲区对象，并且在缓冲区对象中定义了操作消息的方法。消息就以缓冲区对象为载体存储。既然是这样，当程序中频繁收发消息时，肯定会在短时间内创建大量的缓冲区对象，也就意味着要创建大量 PooledDirectByteBuf 对象。既然这个对象要频繁使用，如果频繁地创建然后再被垃圾回收，显然很消耗性能，所以对象池就可以闪亮登场了。没错，在 Netty 中，该对象就拥有自己的对象池。下面我就给大家展示一下该类的部分代码，请看下面代码块。

java

复制代码

`/**  * @Author: PP-jessica  * @Description:池化的直接内存类，我们就是用这个类的对象来包装分配的内存的  */ final class PooledDirectByteBuf extends PooledByteBuf<ByteBuffer> {     //创建对象池，从静态属性可以看出来，该对象池只创建一次，只创建一个     private static final Recycler<PooledDirectByteBuf> RECYCLER = new Recycler<PooledDirectByteBuf>() {         @Override         protected PooledDirectByteBuf newObject(Handle<PooledDirectByteBuf> handle) {             return new PooledDirectByteBuf(handle, 0);         }     };     //这里可以看出来，所有想要获得对象池中对象的线程，都可以访问该对象池获得对象。获得对象的过程中会首先创建属于该线程的stack。     //得到的对象就缓存在该对象的stack中。     static PooledDirectByteBuf newInstance(int maxCapacity) {         //从对象池中获取对象         PooledDirectByteBuf buf = RECYCLER.get();         buf.reuse(maxCapacity);         return buf;     }     private PooledDirectByteBuf(Recycler.Handle<PooledDirectByteBuf> recyclerHandle, int maxCapacity) {         super(recyclerHandle, maxCapacity);     } 	//其他内容暂时省略      }`

到此为止，围绕着 PooledDirectByteBuf 类的核心知识点就讲解完毕了。在整个这一小节的内容中，我为大家详细剖析了给 ByteBuf 对象分配内存，分配的究竟是什么，分配的内存又是怎样使用的，在分析的过程中，逐渐将 PooledDirectByteBuf 和其父类 PooledByteBuf 的内部构造展示清楚了。既然这一块的知识讲完了，接下来，似乎就应该重新把目光集中到 PooledByteBufAllocator 类中，要着重实现其中的 newDirectBuffer 方法，这个方法算是内存分配的起点方法了，然后再实现 PoolArena、PoolChunkList、PoolChunk 中的 allocate 方法。而这些方法的实现，就意味着我要真正为自己的内存分配系统构建分配流程了。这就要涉及到很多细节问题的解决，比如最直接的，PooledByteBufAllocator 中定义了 PoolArena 数组，这个数组中的 PoolArena 显然是要分给不同的线程，以此来减少并发度，对吧，这是之前讲过的知识。那么该怎么分配呢？内存分配系统中该定义几个线程呢？ByteBuf 对象应该在哪里创建呢？像这样的问题还有很多，这一章肯定是讲不完了，而且这一节章的内容实在是太多了，也该到此为止了。所以，我们就下一章再见吧。

**总结**

这一章的内容非常多，知识点也比较密集，都是一个连着一个，紧密相光的。所以，文章可能需要读好几遍，才能把其中的知识完全消化。我其实并不太擅长为大家总结什么，如果说能学到什么知识，那也是大家自己总结和消化的，甚至是举一反三，这样知识会掌握得更牢固。就比如说，这一章讲完，大家肯定已经彻底明白了所谓的 ByteBuffer 和 ByteBuf 的本质究竟是是什么，也知道内存分配给它们之后，分配的究竟是什么，以及它们怎么通过分配到的这个内存地址去存放字节消息的，还有所谓的偏移量是什么。总之，这些知识都明白了之后，其实大家就可以去定义或者实现自己的缓冲区类型了。这个缓冲区类型叫 BadByteBuffer 也好，还是叫 GoodByteBuf 都没关系，因为本质都没什么区别，最后都是把字节消息存放到内存中。当然，这一章也有一个遗憾，那就是我为大家讲解完了 PooledDirectByteBuf 和其父类 PooledByteBuf，但是并没有紧接着把 PoolArena、PoolChunkList、PoolChunk 中的 allocate 方法做一下重构，既然是给 ByteBuf 对象分配内存，肯定要把这个对象当作参数传到方法中呀，要一路传到 PoolChunk 中呢。这一章显然是没时间重构了，就留到下一章重构吧。下一章，大家就会明白 ByteBuf 对象是在哪里，是怎么创建的了。