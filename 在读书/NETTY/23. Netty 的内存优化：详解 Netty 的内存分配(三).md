大家好，在上一章，我为大家把我内存分配系统的几个重要组件都引入了，连内存分配的起点类，也就是内存分配器 PooledByteBufAllocator 也为大家讲解了，当然在讲解该类的同时，我记得我也为大家把该类的抽象父类 AbstractByteBufAllocator 以及顶级接口 ByteBufAllocator 都讲解了。内存分配的入口方法以及后续的链路调用，我相信大家应该都还有点印象。所以我就简单提一下，就不再详细回顾了。内存分配显然会先从内存分配器 ByteBufAllocator 开始，然后经过 PoolArena，然后经过 PoolChunkList，然后再到达 PoolChunk，在 PoolChunk 对象中分配内存。当然，是为一个 ByteBuf 分配内存，因为从 PoolChunk 中分配的内存会被包装在一个 ByteBuf 对象中。

在我的内存分配系统中，默认使用的是堆外内存，所以在内存分配的过程中会先创建一个 PooledDirectByteBuf 对象，就是从该对象的对象池中获取一个对象，然后随着调用链路传递到 PoolChunk 中，在 PoolChunk 中把分配的内存交给 PooledDirectByteBuf 对象来管理，然后再把这个 PooledDirectByteBuf 对象返回给用户，到此，内存分配的链路就算是结束了。上一章的后半部分几乎都在为大家剖析 PooledDirectByteBuf 的内部构造，以及分配的内存究竟是怎么被它包装的，我相信已经剖析得十分详细了。因此，在开始讲解本章的内容之前，我希望能先把 PoolArena、PoolChunkList、PoolChunk 中的 allocate 方法重构一下，因为最终内存是要分配到 ByteBuf 对象中的，所以，allocate 方法中肯定需要一个 ByteBuf 对象，当然，该对象会随着调用链路传递到 PoolChunk 中，allocate 方法的参数也要重构一下。接下来，就先看看重构后的这几个类吧。

**重构内存分配系统中的 allocate 方法**

还是从头开始梳理吧，首先还是从 PooledByteBufAllocator 内存分配的起点类开始。首先是这个类的 newDirectBuffer 方法。当然，我们创建的内存分配器肯定不是直接就调用 newDirectBuffer 方法，而是调用的 抽象父类中的 buffer(int initialCapacity) 方法，然后再一路调用到 PooledByteBufAllocator 类中的 newDirectBuffer 方法，这个链路上一章也分析过了，所以就不再用代码展示了。大家知道就行。

java

复制代码

`/**  * @Author: PP-jessica  * @Description:创建一个直接内存的ByteBuf，注意，下面这个方法中的maxCapacity实际上已经被  * AbstractByteBufAllocator类中的静态成员变量DEFAULT_MAX_CAPACITY赋值了，就是Integer.MAX_VALUE  */ @Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) {     //这个方法仍然是还不能实现，但是我们已经知道了，PooledByteBufAllocator类中持有着     //PoolArena数组，肯定是从数组中获得一个PoolArena对象，从这个对象中开始分配内存     //所以不妨就先写一行伪代码，然后开始分配内存之旅     //得到了一个PoolArena对象，并且该PoolArena对象包装的是堆外内存     PoolArena<ByteBuffer> directArena = System.out.println("得到一个PoolArena对象！");     //接下来就要从PoolArena对象中分配内存了，该方法会返回一个ByteBuf，并且该ByteBuf中管理的堆外内存已经分配好了     ByteBuf buf = directArena.allocate(initialCapacity, maxCapacity);     //返回ByteBuf      return buf; }` 

接下来程序就会执行到 PoolArena 对象的 allocate 方法来进一步分配内存，所以，下面我们就看看 PoolArena 对象的 allocate 方法该怎是重构。当然，我已经为大家重构好了，请看下面的代码块。

java

复制代码

`abstract class PoolArena<T> {     //只展示部分代码     /**      * @Author: PP-jessica      * @Description:分配内存的方法，这个是本次重构新增的方法。参数都是从PooledByteBufAllocator      * 类的newDirectBuffer方法中传过来的      */     PooledByteBuf<T> allocate(int reqCapacity, int maxCapacity) {         //得到一个池化的ByteBuf，这里就会和我们之前学的对象池连接起来了，因为newByteBuf该方法会         //调用到PooledDirectByteBuf的newInstance方法内，在该方法内就是从线程私有的对象池内获得一个ByteBuf对象         //也就是说，哪个线程正在执行该方法，就会从哪个线程的对象池中获得PooledDirectByteBuf对象         PooledByteBuf<T> buf = newByteBuf(maxCapacity);         //给ByteBuf分配内存，这里大家可以看到，我们分配的是直接内存，而该内存是被一个ByteBuf包装着的         allocate(buf, reqCapacity);         return buf;     }     //该方法也是新添加的，就是用来得到一个PooledDirectByteBuf对象     //并且是从PooledDirectByteBuf的对象池中得到的     protected PooledByteBuf<ByteBuffer> newByteBuf(int maxCapacity) {         return PooledDirectByteBuf.newInstance(maxCapacity);     }     /**      * @Author: PP-jessica      * @Description:分配内存的方法，现在还是非常简化的方法，返回值并不正确      */     boolean allocate(PooledByteBuf<T> buf, int reqCapacity) {         //可以看到，PoolChunList的allocate方法也重构了         if (q050.allocate(buf，reqCapacity) || q025.allocate(buf，reqCapacity) || q000.allocate(buf，reqCapacity) || qInit.allocate(buf，reqCapacity) ||                 q075.allocate(buf，reqCapacity)) {             //分配成功就返回true             return true;         }         //程序第一次申请内存时，肯定还没有创建ChunkPool，这时候要创建一个chunk内存块         //如果上面都没有分配成功，那就意味着所有的chunk中剩余可分配内存都不够了，这时候就要创建         //新的PoolChunk，让操作系统帮助申请16MB内存供程序内部使用，这里的CHUNK_SIZE就是该类的成员变量         //只不过没有列出来，是16MB         PoolChunk<T> c = new PoolChunk(new DirectByteBuffer(CHUNK_SIZE),CHUNK_SIZE);         //分配内存          boolean success = c.allocate(buf，reqCapacity);         //接着把这个chunk内存块加入到init链表中         qInit.add(c);         return success;     } }`

根据上面的代码块，我们就可以知道，在 PoolArena 对象中，如果 PoolChunkList 分配内存没有成功，就会创建一个新的 PoolChunk 对象，从这个对象中分配内存，所以就应该到 PoolChunk 中进行真正的内存分配了。但是分配成功的时候，就会先到 PoolChunkList 中分配内存，不过即便是到了 PoolChunkList 中分配内存，最后还是会走到 PoolChunk 中进行内存分配。所以接下来，就针对这两种情况，我们先来看看 PoolChunkList 的 allocate 方法究竟是怎么重构的。然后再到 PoolChunk 中，看看该类的 allocate 方法该怎么重构。

首先，先来看看 PoolChunkList 中的 allocate 方法是如何重构的。请看下面代码块。

java

复制代码

`final class PoolChunkList<T>{      	//只展示部分代码           /**      * @Author: PP-jessica      * @Description:分配内存的方法，该方法经过重构了      * 多了一个参数reqCapacity，就是要分配的内存大小      */     boolean allocate(PooledByteBuf<T> buf,int reqCapacity) {         //如果要申请的内存超过了一个Chunk可分配的最大内存值         if (normCapacity > maxCapacity) {            //分配不了就直接退出             return false;         }         //便遍历该链表中的Chunk         for (PoolChunk<T> cur = head; cur != null; cur = cur.next) {             //从Chunk中分配经过规整的内存，具体的方法都在PoolChunk中，这里我们知识粗讲逻辑             //核心会在PoolChunk中讲到，在这里重构了一下，把ByteBuf传进来了             if (cur.allocate(buf,reqCapacity)) {                 //这里就会判断当前分配完内存的Chunk的内存利用率是否超过了它的最大内存利用率                 if (cur.usage() >= maxUsage) {                     //超过了就从当前链表中移除该Chunk                     remove(cur);                     //把该Chunk添加到链表的下一个节点中                     //注意，这里的下一个节点是PoolChunkList组成的链表的下一个节点                     nextList.add(cur);                 }                 return true;             }         }         return false;     } }`

可以看到，在 PoolChunkList 的 allocate 方法中，重构后的逻辑和之前几乎一样，只不过是方法的参数多了一个 ByteBuf 对象，然后把这个对象传到 PoolChunk 的 allocate 方法中了。所以，接下来，还是要去 PoolChunk 中查看 allocate 的方法是怎么实现的。

java

复制代码

`final class PoolChunk<T>{     //只展示部分代码          //该方法就是Poolchunk分配内存的方法，在该方法中，会进行内存的分配     //分配成功了就返回true，失败则返回false     //多了一个参数，就是要分配的内存大小     boolean allocate(PooledByteBuf<T> buf,int reqCapacity) {         //暂且不实现         //但这里我要多解释一下，freeBytes会在每次分配出一点内存后就更新一下         //就是减去分配出去的内存大小         //该方法现在还是实现不了，因为还没有到应该讲解的时候，那么我们就先假装它已经被实现了         //就先写成伪代码         分配好的内存 = System.out.println("内存分配成功！");         //然后拿着分配好的内存去交给ByteBuf管理         initBuf(buf, 分配好的内存, reqCapacity);         return true;     }     /**      * @Author: PP-jessica      * @Description:初始化buf的方法，其实就是把分配好的堆外内存交给ByteBuf对象来管理      */     void initBuf(PooledByteBuf<T> buf, 分配好的内存, int reqCapacity) {         //调用PooledByteBuf对象的init方法就行了，这里就和上一章的内容串联起来了         //在上一章讲解PooledByteBuf类时，我在里面定义了一个init方法，跟大家说这个方法         //会在PoolChunk类中被调用。就是在这里调用，内存分配成功后，把内存交给ByteBuf对象来包装         buf.init(this,分配好的内存,reqCapacity);     }          //其他的方法暂时不考虑实现 }`

到此为止，我们就用真伪代码交叉重构，总算是把内存分配的流程又快速地演示了一遍，并且也把各个重要组件的 allocate 方法重构了一下。当然，这还只是个开胃小菜，顶多算是帮助大家回顾一下前两章的内容。接下来，才要开始讲解新的知识。

**重构 PooledByteBufAllocator**

如果大家通过上面几个代码块，已经彻底掌握了内存分配的大概流程，调用链路要经过那几个组件，也就是哪几个类，并且也清楚了这些组件的核心作用究竟是什么。那么接下来，我想问问大家，一个内存分配核心问题，那就是内存分配究竟是谁在分配，谁去申请？换句话说，内存分配的执行者是谁？分配出来的内存的接收者是谁？这是我们目前理清楚的一个问题。当然，这个问题在上一章我也不是没跟大家讨论过，我记得我说过，内存分配的发起者实际上就是线程，而内存的接收者本质上也是线程。虽然分配出来的内存是交给一个 ByteBuf 对象包装了，但是这个 ByteBuf 对象是从执行内存分配动作的线程的对象池中获取的，所以，本质上就是交给这个线程使用了。既然这样，那让我们思考一下，程序中存在的所有线程都会执行执行内存申请和内存分配的动作吗？这个问题就要放在特定的环境中来思考了。

假如大家就把环境放到 Netty 中来思考这个问题，因为我的内存分配系统其实也就是仿照 Netty 中的那个设计的。那么请大家想一想，在 Netty 中，使用了 Reactor 线程模型，也就是主从线程组，主线程组就用来专门接受客户端连接，而从线程组就专门用来和各个连接进行 IO 通信。而 Netty 的从线程组一般会设置成 CPU 的核心乘以 2。假如就把从线程组的线程数设定为 8，这就意味着在 Netty 程序中有 8 个单线程执行器要不停地和主线程组接收到的连接进行 IO 通信。也就是接收客户端发来的消息，然后把消息发送给客户端。而这些消息的载体我们之前已经分析过了，就是 ByteBuf 对象。所以，既然要频繁地收发消息，就意味着要在这些从线程组的所有线程中频繁地使用 ByteBuf 来接收消息和发送消息。 这样一来就会频繁地创建 ByteBuf 对象，但是 ByteBuf 在 Netty 中是有对象池的，每一个线程都会从自己的对象池中获得 ByteBuf 对象。但是只有该对象是不够的，因为 Netty 中默认使用的是堆外内存来存放字节消息，因此每次从对象池中获得一个 ByteBuf 对象，就要给这个对象分配相应的堆外内存。而分配内存的操作当然也是在同一个线程中进行的。这样一来，不就恰好证明了在 Netty 中，从线程组中的所有线程都会频繁地执行内存申请和内存分配这个动作吗？所以，回到我自己搭建的内存分配系统中，也应该默认程序中的每个线程都会进行内存分配的操作。所以，内存分配是多线程并发执行的，这一点想必大家都理解了吧？

如果是这样，也就意味着在某些情况下，多个线程其实都有可能执行到下面这两行代码。然后以这行代码为起点开始进行内存分配。

java

复制代码

`//直接创建一个池化的直接内存分配器，该分配器默认分配的都是直接内存，当然也可以分配堆内存，但一般不会走到那些分支中去 PooledByteBufAllocator pooledAllocator = PooledByteBufAllocator.DEFAULT; //申请2KB的直接内存 PooledByteBuf byteBuf = (PooledByteBuf) pooledAllocator.buffer(1024 * 2);`

如果是这样的话，顺着调用链路，线程的执行流程很快就会来到 PooledByteBufAllocator 类的 newDirectBuffer 方法中。当然，newDirectBuffer 方法我们目前还没有实现，但是我们都知道，在该方法中，会从 PooledByteBufAllocator 类持有的 PoolArena 数组中获得一个 PoolArena 对象，然后从该对象开始进行真正的内存分配。就像下面这段伪代码展示的这样。

java

复制代码

`@Override protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) {     //这个方法仍然是还不能实现，但是我们已经知道了，PooledByteBufAllocator类中持有着     //PoolArena数组，肯定是从数组中获得一个PoolArena对象，从这个对象中开始分配内存     //所以不妨就先写一行伪代码，然后开始分配内存之旅     //得到了一个PoolArena对象，并且该PoolArena对象包装的是堆外内存     PoolArena<ByteBuffer> directArena = System.out.println("得到一个PoolArena对象！");     //接下来就要从PoolArena对象中分配内存了，该方法会返回一个ByteBuf，并且该ByteBuf中管理的堆外内存已经分配好了     ByteBuf buf = directArena.allocate(initialCapacity, maxCapacity);     //返回ByteBuf      return buf; }` 

所以，我们现在的问题就成了如何从 PooledByteBufAllocator 持有的 PoolArena 数组中获得一个 PoolArean 对象，然后就可以真正开始分配内存了。那么获得 PoolArena 对象的过程中会发生什么问题呢？显然，不用我提示大家应该也想到了，肯定是并发问题呀。因为是多个线程要同时从 PoolArena 对象中分配内存。当然，这个问题也不是不能解决，只要仿照对象池的设计思路，给每个线程都分配一个 PoolArena 对象，并发问题不就没有了吗？这样一来，PoolArena 管理的所有 PoolChunk 都只是给一个线程提供服务的，线程要申请分配内存，也只是从自己的私有 PoolArena 中得到分配的堆外内存。这样一来，问题不就全部解决了吗？设计思想肯定是没问题的，但是很遗憾，我们不可能给每一个线程都创建一个私有的 PoolArena 对象，至于原因，我在上一章也解释过了。当然，这本来就是一个动态的问题，如果你的服务器资源充足，或者说你根本就没哟几个线程在并发执行任务，比如就 4 个线程，那么直接创建 4 个 PoolArena 对象也是可以的。但假如你的服务器压力比较大，Netty 构建的服务器中有非常多的单线程执行器在执行任务，这时候如果给每一个线程都创建私有的 PoolArena 显然就不太合适了。因此，我们尽可以直面这个问题，在设计的时候就要考虑这个并发问题。既然并发问题是不可避免的，那么该怎么设计才能最大限度的减少程序中的并发程度呢？所谓并发程度，就是看看几个线程同时操作一个 PoolArena 对象，同时操作的线程越多，并发程度就越高。

我自己当然没亲自做过实验，也是直接参照 Netty 源码开始设计自己的内存分配系统。在 Netty 源码中，要创建的 PoolArena 对象的个数通常是 CPU 的核数乘以 2。所以，这里我也就这么设计了。假如我的服务器是 8 核的，那么创建的 PoolArena 对象就是 16 个。如果我程序中执行任务的线程也是 CPU 的核数乘以 2，这样一来，不就做到了每一个线程对应一个 PoolArena 对象吗？当然，如果执行任务的线程是 32，这样一来，为了减少并发程度，就需要每两个线程共同操纵同一个 PoolArena 对象。这就是我目前确定好的编码思路了。

那么，假如我现在就把一个 PoolArena 对象分配给了一个线程，怎么就让这个线程知道它拥有了一个可以由自己支配的 PoolArena 对象了呢？以后它要是想分配内存，就从自己的 PoolArena 对象中分配即可。方法很简单，就把这个 PoolArena 对象交给线程的私有 Map 保管就行了。这样一来，我们过去学习的知识就又可以派上用场了。如果这一个 PoolArena 对象要同时被两个线程访问，那也简单，就把这个 PoolArena 对象同时交给两个线程的私有 Map 管理即可。所以，接下来，我似乎就该按照当前的设计思路，来重构一下 PooledByteBufAllocator 类。但是先不着急，因为我忽然想到了一个更好的方法，我不想直接就把分配给线程的 PoolArena 对象放到线程的私有 Map 中。因为我意识到我只顾着写自己的程序，忘记了自己的程序是为谁而写的。说得直接一点，如果我只是单纯为自己设计一个内存分配系统，并且指定了只使用堆外内存，那么我直接就把 PoolArena 对象放到线程的私有 Map 中就行了。但实际上，在 Netty 中，还存在堆内存呢？如果用户使用的是堆内存，那该怎么存放到线程的 Map 中呢？别忘了 FastThreadLocal 是要设置泛型的，不可能存储不同类型的对象，除非再创建一个新的 FastThreadLocal 对象，这个对象的泛型设置成堆内存，对吧？

如果是这样，我倒不如直接在自己的程序中设置一个 boolean 变量，让用户来自己赋值，如果为 true 就是使用的堆外内存，如果为 false，使用的就是堆内存。然后我再定义一个 PoolThreadCache 类，在这个类中定义两个成员变量，一个是持有堆内存的 PoolArena 对象，一个是持有堆外内存的 PoolArena 对象，然后把 PoolThreadCache 类型的对象存放到线程的私有 Map 中。这样不就可以使用一个对象来兼容两种内存类型了吗？当然，这个问题解决了之后，其实还有一个小问题。那就是当程序中真的存在并发问题时，就比如说程序中有 16 个线程在执行任务，但显然不可能创建 16 个 PoolArena 对象，给每个线程分配一个，这时候，理想的方法是创建 8 个 PoolArena 对象，让两个线程享有同一个 PoolArena 对象。但是，如果程序连 8 个对象也无法创建呢？比如说程序就只能创建 5 个 PoolArena 对象，然后让 16 个线程来共同享有这 5 个 PoolArena 对象。那该怎么分配呢？这种情况下肯定就不可能做到平均分配了，所以，我的做法和 Netty 保持一直，把平均分配这样的概念直接抛弃，直接在 PoolArena 中定义一个新的成员变量，用来记录该 PoolArena 被几个线程享有。如果是 3 个线程共同享用这个 PoolArena ，那么这个新的成员变量的值就是 3。而在把 PoolArena 对象分配给线程的时候，就判断 PoolArena 数组中每一个 PoolArena 对象的这个成员变量的值，在所有 PoolArena 对象中，如果哪个对象持有的这个成员变量值最小，就优先把该 PoolArena 对象先分配出去。

好了，编码的思路我已经为大家分析得够多了，接下来，就让我们在代码层面实现一下吧。首先，先请大家看一看重构之后的 PoolArena 类。请看下面代码块。

java

复制代码

`abstract class PoolArena<T> {     //Chunk块的大小，也就是事先申请的一大块内存的大小，为16M     private static final int CHUNK_SIZE = 1024 * 1024 * 16;     //新增加的成员变量     //这个值很重要，还记得我们在给线程创建它自己的内存池时，会寻找被其他线程引用最少的PoolArena来使用吗     //这个原子类记录的就是该PoolArena正被多少单线程执行器引用     final AtomicInteger numThreadCaches = new AtomicInteger();     //这个值很重要，还记得我们在给线程创建它自己的内存池时，会寻找被其他线程引用最少的PoolArena来使用吗     //这个原子类记录的就是该PoolArena正被多少单线程执行器引用     final AtomicInteger numThreadCaches = new AtomicInteger();          //内存使用率为1%到50%%的Chunk集合 	private final PoolChunkList<T> q000; 	 	//内存使用率为25%到75%的Chunk集合 	private final PoolChunkList<T> q025; 	 	//内存使用率为50%到100%的Chunk集合 	private final PoolChunkList<T> q050; 	 	//内存使用率为75%到100%的Chunk集合 	private final PoolChunkList<T> q075; 	 	//内存使用率为100%的Chunk集合 	private final PoolChunkList<T> q100; 	 	//内存使用率为0到25%的Chunk集合 	private final PoolChunkList<T> qInit; 	      //构造方法，在构造方法中把定义的链表初始化，并且连接起来了      protected PoolArena(){          //开始连接这些链表对象，可以发现，现在qInit对象成了头节点 		 qInit = new PoolChunkList<T>(this, q000, 0, 25, chunkSize); 		 q000 = new PoolChunkList<T>(this, q025, 1, 50, chunkSize); 		 q025 = new PoolChunkList<T>(this, q050, 25, 75, chunkSize); 		 q050 = new PoolChunkList<T>(this, q075, 50, 100, chunkSize); 		 q075 = new PoolChunkList<T>(this, q100, 75, 100, chunkSize); 		 q100 = new PoolChunkList<T>(this, null, 100, Integer.MAX_VALUE, chunkSize); 		 //通过上面的连接方式，这5个PoolChunkList对象的连接顺序就成了下面这样 		 //qInit ——> q000 ——> q025 ——> q050 ——> q075 ——> q100 		 //但是PoolChunkList对象构成的新链表是一个双向链表，因此，还要把前节点的指针补上 		 q100.prevList(q075); 		 q075.prevList(q050); 		 q050.prevList(q025); 		 q025.prevList(q000); 		 //这里可以看到，q000没有前置节点，这意味着当q000中的PoolChunk的内存使用率过低 		 //整个PoolChunk就会被释放了，不会再存在于链表中 		 q000.prevList(null) 		 //这里可以看到qInit的前置节点是自己，这意味着当qInit中的PoolChunk的内存使用率低于临界值 		 //并不会被释放。其实也不会低于临界值了，因为qInit的最低内存使用率是0，PoolChunk的最低内存 		 //使用率也为0，就是相等的情况，既然相等，肯定就不会释放了，这个在下一章会在代码层面实现 		 //只有进入了q000集合中的Chunk才会被释放 		 qInit.prevList(qInit);      }     /**      * @Author: PP-jessica      * @Description:分配内存的方法，这个是本次重构新增的方法。参数都是从PooledByteBufAllocator      * 类的newDirectBuffer方法中传过来的      */     PooledByteBuf<T> allocate(int reqCapacity, int maxCapacity) {         //得到一个池化的ByteBuf，这里就会和我们之前学的对象池连接起来了，因为newByteBuf该方法会         //调用到PooledDirectByteBuf的newInstance方法内，在该方法内就是从线程私有的对象池内获得一个ByteBuf对象         //也就是说，哪个线程正在执行该方法，就会从哪个线程的对象池中获得PooledDirectByteBuf对象         PooledByteBuf<T> buf = newByteBuf(maxCapacity);         //给ByteBuf分配内存，这里大家可以看到，我们分配的是直接内存，而该内存是被一个ByteBuf包装着的         allocate(buf, reqCapacity);         return buf;     }     //该方法也是新添加的，就是用来得到一个PooledDirectByteBuf对象     //并且是从PooledDirectByteBuf的对象池中得到的     protected PooledByteBuf<ByteBuffer> newByteBuf(int maxCapacity) {         return PooledDirectByteBuf.newInstance(maxCapacity);     }     /**      * @Author: PP-jessica      * @Description:分配内存的方法，现在还是非常简化的方法，返回值并不正确      */     boolean allocate(PooledByteBuf<T> buf, int reqCapacity) {         //可以看到，PoolChunList的allocate方法也重构了         if (q050.allocate(buf，reqCapacity) || q025.allocate(buf，reqCapacity) || q000.allocate(buf，reqCapacity) || qInit.allocate(buf，reqCapacity) ||                 q075.allocate(buf，reqCapacity)) {             //分配成功就返回true             return true;         }         //程序第一次申请内存时，肯定还没有创建ChunkPool，这时候要创建一个chunk内存块         //如果上面都没有分配成功，那就意味着所有的chunk中剩余可分配内存都不够了，这时候就要创建         //新的PoolChunk，让操作系统帮助申请16MB内存供程序内部使用，这里的CHUNK_SIZE就是该类的成员变量         //只不过没有列出来，是16MB         PoolChunk<T> c = new PoolChunk(new DirectByteBuffer(CHUNK_SIZE),CHUNK_SIZE);         //分配内存          boolean success = c.allocate(buf，reqCapacity);         //接着把这个chunk内存块加入到init链表中         qInit.add(c);         return success;     }     //新增加的方法，和numThreadCaches成员变量有关，就是返回该变量的值     public int numThreadCaches() {         return numThreadCaches.get();     } }`

可以看到，我把这个类的所有代码都搬运过来了，其实这个类并没有被怎么重构，只是添加了一个成员变量和一个与成员变量相关的小方法，但为了逻辑上的连贯，所以我就再一次把 PoolArena 的整个类的代码搬运到这里了。因为下面会进行 PooledByteBufAllocator 类的重构，当 PooledByteBufAllocator 在执行它的构造函数时，初始化 PoolArena 数组时会为每一个索引位置创建 PoolArena 对象，当创建 PoolArena 对象的时候，在 PoolArena 对象的构造方法中会发生什么。我担心大家已经忘记了，所以就搬运过来了，就当是温习一下旧知识吧。

接下来就是我新引入的 PoolThreadCache 类。请看下面代码块。

java

复制代码

`final class PoolThreadCache {     //持有的使用次数最少的heapArena     PoolArena<byte[]> heapArena;     //持有的使用次数最少的directArena     PoolArena<ByteBuffer> directArena;     /**      * @Author: PP-jessica      * @Description:构造器方法      */     PoolThreadCache(PoolArena<byte[]> heapArena, PoolArena<ByteBuffer> directArena) {         if (heapArena != null) {             this.heapArena = heapArena;             //被持有的引用计数加1             heapArena.numThreadCaches.getAndIncrement();         }         if (directArena != null) {             this.directArena = directArena;             //被持有的引用计数加1             directArena.numThreadCaches.getAndIncrement();         }     } }`

接下来就是重构之后的 PooledByteBufAllocator 类了，请看下面代码块。

java

复制代码

`/**  * @Author: PP-jessica  * @Description:该类就是分配池化内存的内存分配器  */ public class PooledByteBufAllocator extends AbstractByteBufAllocator{     //这里有两个PoolArena的数组，一个数组的泛型为字节数组，一个数组的泛型为ByteBuffer     //显然，为Byte数组就意味着PoolChunk包装的堆内存，而使用的是ByteBuffer的，就意味着     //PoolChunk管理的是操作系统帮忙申请的堆外内存，在我们的文章中，重点讲解的是第二个成员变量     //也就是directArenas，第一个大家可以自行到源码中学习     private final PoolArena<byte[]>[] heapArenas;          private final PoolArena<ByteBuffer>[] directArenas;     //直接内存类型，也就是direc类型的ARENA的数量，其实就是directArenas数组的长度     //要创建的PoolArena对象的数量，通常情况下默认初始值是CPU核数乘以2     private static final int DEFAULT_NUM_DIRECT_ARENA;     //是否为所有线程都创建自己的私有Map，默认为true，在静态代码块中被赋值     private static final boolean DEFAULT_USE_CACHE_FOR_ALL_THREADS;     //静态代码块中的代码会最先被执行，所以，DEFAULT_NUM_DIRECT_ARENA成员变量会被赋值为CPU的核数乘以2      static {          //得到CPU的核数乘以2的值         final int defaultMinNumArena = NettyRuntime.availableProcessors() * 2;          //在静态代码块中，要创建的PoolArena的个数就被赋值成功了         EFAULT_NUM_DIRECT_ARENA = Math.max(0,                 SystemPropertyUtil.getInt(                         "io.netty.allocator.numDirectArenas",                     //在这里会判断一下，CPU乘以2的核数和PlatformDependent.maxDirectMemory() / defaultChunkSize / 2 / 3)                     //相比，哪个小就用哪个给DEFAULT_NUM_DIRECT_ARENA赋值                         (int) Math.min(                                 defaultMinNumArena,                             //下面这行代码其实没必要在这里讲解了，如果在实际开发中你真的需要关注Netty使用                             //堆外内存的情况，然后根据堆外内存来决定分配PoolArena对象的个数，并且最后计算的个数                             //比CPU核数乘以2的值还小，那就会走到这行代码。在这行代码中会用使用的堆外内存的一半                             //然后除以defaultChunkSize*3，也就是为了保证最后分配的每个PoolArena对象可以管理3个PoolChunk对象                                 PlatformDependent.maxDirectMemory() / defaultChunkSize / 2 / 3)));          DEFAULT_USE_CACHE_FOR_ALL_THREADS = SystemPropertyUtil.getBoolean(                 "io.netty.allocator.useCacheForAllThreads", true);      }     //这个就是可以让用户自己配置的成员变量，如果为true，就是用堆外内存     //在这里我就不真的重构这个功能了，如果重构就必须要引入更多的类，实在是麻烦     //大家可以去第14版本代码中查看源码，这里我就先写死了，写成true，默认使用堆外内存 	private static final boolean DIRECT_BUFFER_PREFERRED = true;          /**      * @Author: PP-jessica      * @Description:内存分配器在这里创建了      */     public static final PooledByteBufAllocator DEFAULT =             new PooledByteBufAllocator(true);     //这就是每个线程私有的Map的入口，本身是一个FastThreadLocal     //给每个线程分配的PoolArena对象就会由此为入口，交给线程的私有Map     //并且PoolThreadLocalCache是PooledByteBufAllocator的一个内部类     //下面就会为大家详细展示     private final PoolThreadLocalCache threadCache;     //该类的构造方法在这里实现了     public PooledByteBufAllocator(boolean preferDirect,int nDirectArena, boolean useCacheForAllThreads){         //这里要把这个preferDirect传递到父类的构造函数中，是因为创建一个buffer时，调用的都是抽象父类中的方法，而这个属性就决定了         //是否可以创建堆外内存的buffer，否则只能创建堆内存的buffer。具体逻辑可以从父类中查看         //父类就是AbstractByteBufAllocator，这里我也就不再引入了，大家可以直接去第14版本代码中查看         super(preferDirect);                  //在这里创建了一个FastTreadLocal，其实就可以把这个属性当成得到每个线程私有Map的入口         threadCache = new PoolThreadLocalCache(useCacheForAllThreads);         //在这里初始化PoolArena数组，并且初始化的是包装了堆外内存的PoolArena数组         directArenas = newArenaArray(nDirectArena);         //为数组的每一个位置创建PoolArena对象         for (int i = 0; i < directArenas.length; i ++) {                 PoolArena arena = new PoolArena();                 directArenas[i] = arena;             }     } 	//PoolThreadLocalCache内部类     final class PoolThreadLocalCache extends FastThreadLocal<PoolThreadCache> {         private final boolean useCacheForAllThreads;         //useCacheForAllThreads的值为true，意味着给每个线程都创建私有Map         //不管该线程是否属于FastThreadLocalThread类型         PoolThreadLocalCache(boolean useCacheForAllThreads) {             this.useCacheForAllThreads = useCacheForAllThreads;         }         /**          * @Author: PP-jessica          * @Description:返回一个PoolThreadCache对象，而该对象是要存放到线程的Map中的，这个流程我就不再重复讲解了          */         @Override         protected synchronized PoolThreadCache initialValue() {             //寻找被使用次数最少的heapArena，当然，如果使用的是堆外内存，该方法会直接返回null             //因为heapArenas就没有被创建，本身就是null             final PoolArena<byte[]> heapArena = leastUsedArena(heapArenas);             //寻找被使用次数最少的directArena，然后把这个对象交给一个线程的私有Map             final PoolArena<ByteBuffer> directArena = leastUsedArena(directArenas);             //获得执行当前方法的线程             final Thread current = Thread.currentThread();             if (useCacheForAllThreads || current instanceof FastThreadLocalThread) {                 //创建PoolThreadCache对象，可以看到，这里就把directArena交给PoolThreadCache对象了                 final PoolThreadCache cache = new PoolThreadCache(heapArena,directArena);                 return cache;             }             //这里和if分支中创建的对象一致，是因为我简化了代码，我为大家提供的第14版本代码并不是这样的             //可以去那个代码中学习源码的逻辑             return new PoolThreadCache(heapArena,directArena);         }         /**          * @Author: PP-jessica          * @Description:寻找被使用次数最少的Arena          */         private <T> PoolArena<T> leastUsedArena(PoolArena<T>[] arenas) {             if (arenas == null || arenas.length == 0) {                 return null;             }             //下面就是把PoolArena数组中的每一个PoolArena对象取出来，一个个做对比             //看看哪个对象的numThreadCaches值最小，谁最小就优先把谁分配给线程             PoolArena<T> minArena = arenas[0];             for (int i = 1; i < arenas.length; i++) {                 PoolArena<T> arena = arenas[i];                 if (arena.numThreadCaches.get() < minArena.numThreadCaches.get()) {                     minArena = arena;                 }             }             return minArena;         }     }               //下面就又回到PooledByteBufAllocator类中了     //下面这两个就是要实现的父类的抽象方法     @Override     protected ByteBuf newHeapBuffer(int initialCapacity, int maxCapacity) {         //我们的文章并不涉及堆内存的分配，所以这个方法就做一个空实现好了         return null;     }     /**      * @Author: PP-jessica      * @Description:创建一个直接内存的ByteBuf，现在就该真正实现这个方法了      */     @Override     protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) {         //先获得PoolThreadCache对象，该对象是执行当前方法的线程私有的，并且         //该对象中持有者分配给该线程的PoolArena对象的引用         PoolThreadCache cache = threadCache.get();         //获得线程持有的PoolArena对象         PoolArena<ByteBuffer> directArena = cache.directArena;         //从PoolArena对象中开始分配内存         ByteBuf buf = directArena.allocate(initialCapacity, maxCapacity);         return buf;     } }`

到此为止，我的内存池的分配系统的内容又丰富了很多，和内存分配起点相关的核心知识，基本上讲解得差不多了。当然，最核心的知识仍然没有讲解。但还是让我们先顺着逻辑简单梳理一下，也算是再补充一个小知识点。当程序从 PooledByteBufAllocator 类的 newDirectBuffer 方法真正开始分配内存时，马上就回来到 PoplArena 对象中，执行该对象的 allocate 方法。但是，刚才我已经为大家分析过了，一个 PoolArena 对象很可能分配给多个线程，这个并发问题显然是无法回避了，所以在分配内存的时候，就不得不使用同步锁来保证内存分配的安全性。知道这一点对理解我们的内存分配系统还是很重要的。好了，到此为止，内存分配的整体流程就已经彻底为大家讲解完了。接下来，就要具体去剖析每一个细节了。

**从内存碎片分析内存分配的规格**

我想大家应该还记得，在第 21 章的时候，我向大家简单解释了一下什么是内存碎片。以此来告诉大家，内存分配也是有限制的，并不是说到手了一块 16 MB 的堆外内存，就可以随心所欲地分配这块内存了。本来是第 21 章讲解的知识，为什么现在又要提起呢？因为现在我们的程序其实只差最后一步了，就是在 PoolChunk 中把内存分配出来。所以，剩下的所有知识都应该围绕着这个功能的实现来讲解了。那么，要想把内存分配出来，就应该知道，内存是按照什么样的方式，或者说什么样的规格进行分配的。所以，我们就很有必要回顾第 21 章的这个知识，其实称它为知识，倒不如称它为问题，因为我们并没有解决它。当然，距离我提出这个问题已经过去两章了，所以，我有必要在这里再简单解释一下这个问题是什么。请看下面的一幅简图。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/12cf3393b403413e9fa3685c2bd22dcc~tplv-k3u1fbpfcp-jj-mark:1890:0:0:0:q75.awebp#?w=1692&h=458&s=37947&e=jpg&b=fefefe)

简单来说，就是我得到了上面简图中的 16 个字节大小的内存，现在想分配这块内存，让程序使用。如果第一次有消息要写入，希望使用 4 个字节，于是分配了 4 个字节；第二次希望使用 3 个字节，于是使用了 3 个字节，第三次希望使用 1 个字节，第四次希望使用 5 个字节，第 五次希望使用 3 个字节。按照上面简图中的分配方式，把内存分五次分配出去了。过了一会，内存得到了释放，但是没有完全释放，分别是第三次使用的那 1 个字节，以及最后一次使用的 3 个字节，这两块内存被释放了，这就意味着在这 16 个字节中，有 4 个字节是可用的了。恰好，现在有一个 int 整数要放到内存中了，正好使用 4 个字节。那么是不是直接把这空闲的 4 个字节分配出去就行了？显然是不行的，地址连续的 4 个字节才能存放一个 int 整数，但现在的这 4 个字节地址显然并不连续。这就导致了一种尴尬的情况，明明剩余的字节足够存放一个 int 整数，可内存偏偏分配不出去。我们常常把地址并不连续的那 3 个字节和另外的 1 个字节称为内存碎片，毫无规矩分配内存，就是导致内存碎片出现的原因。当然，如果说的切确一点，这个内存碎片其实可以称为外部内存碎片。由外部内存碎片就有内部内存碎片。但内部内存碎片的问题我们一会再说，现在请大家想一想，外部内存内存该怎么解决。

其实也没有什么特别好的方法，现在出现的问题是剩余内存明明有 4 个字节，但是内存并不连续，所以造成了无法分配出去。如果剩余的 4 个字节内存地址是连续的就好了，那怎么才能让这 4 个字节的内存地址是连续的呢？在分配前就设定好就可以了呀。现在有 16 个字节的内存，内存地址是连续的，如果程序需要申请内存，就给内存分配施加一个规定，硬性规定内存只能以 4 个字节的规格来分配，也就是把这 16 个字节均分成 4 个 4字节。比如说，第一次申请内存，需要 3 个字节，那就把 0 - 3 地址的内存分配出去。如果第二次需要 1 个字节，那就把 4 - 7 的地址分配出去。总之，只要申请的内存是小于 4 个字节的，就都按照 4 个字节来分配。这样释放内存也会一次释放 4 个字节，这样一来，如果申请 4 个字节的内存，并且这 16 个字节中有 4 个字节的空闲内存，那么就一定可以分配成功了。当然，在这种情况下，如果要申请 8 个字节的内存，显然就无法申请了，因为规定了内存只能以 4 字节的方式来分配。所以，申请 8 个字节的内存，显然无法得到足够的内存。当然，这时候我们只需要更改一下这 16 个字节的分配规格即可。比如，我们可以把这 16 个字节分成一个 8 字节，还有两个 4 字节。如果申请的字节大于 4 小于等于 8，那就直接分配 8 字节出去。如果申请的内存小于 4，那就直接分配一个 4 字节出去。通过这种分配方式，把申请的内存大小规整一下，然后再进行内存分配，就可以尽量减少外部内存碎片。这时候，肯定会有人指出，如果用户只申请 1 个字节，结果你分配出去了 4 个字节，这显然是一种浪费呀。是的，确实是这样，多出来的这 3 个字节，其实就是内部的内存碎片。也就是说，用户明明只需要 1 个字节，结果你分配出去了 4 个。多出来的 3 个也得不到利用，就这么稀里糊涂地分配出去了。这里我还要提一句，在 Netty 中其实也没有什么方法能解决内部的内存碎片。所以，我们姑且就把这当成是为了解决外部内存碎片作出的一种妥协，或者说是牺牲吧。

如果这个逻辑大家都领悟了，那么接下来，我就要为大家讲解一下 Netty 中是按照什么规格来分配内存的了。我们都知道，Netty 中申请到的堆外内存是包装在一个 PoolChunk 对象中的，而该对象持有的堆外内存是 16 MB，所以，Netty 分配内存的规格其实就是针对这 16 MB 来说的。这里我就不再为大家分析了，因为也没什么好分析的，我就直接为大家讲解一下 Netty 中内存分配的规格吧。

在 Netty 中，申请内存的基本单位肯定也是字节，一次申请 16 KB，或者一次申请 1 MB 的情况恐怕并不是很常见。首先 Netty 把内存大小分为了三个规格，由小到大分别是 16 - 496 字节，之所以从 16 开始，是因为申请的内存不足 16 字节，自动按照 16 字节分配；其次是 512 - 4 * 1024 字节，其实就是 512 字节到 4 KB大小；最后是 8 KB 到 16 MB。并且在 Netty 中还给这三种规格的内存分别定义了类型。由小到大分别是 Tiny，Small，Normal 这三种。具体的对应关系请看下面代码块。

java

复制代码

`Tiny：16字节-496字节 Small：512字节-4KB Normal：8KB-16MB`

用户申请的内存的规格不同，那么分配时采用的规格也不相等。具体的策略是这样的：如果申请的内存是小于 16 字节的，那么就直接分配给用户 16 个字节，如果用户申请的内存是大于 16 字节但是小于 496 字节的，就会先把 16 - 496 之间的内存按照 16 递增的规格切割，也就是划分成 16、32、48、64 ···这样依次向后排列，直到内存字节为 496 停止。如果用户申请的是 31 字节，那就返回 32 个字节，如果用户申请的是 33 字节，那就返回 48 个字节。16 - 496 之间的内存分配规格就是这样的了。接下来就是 512 - 4 KB 之间的内存分配规格了。这个区间的分配规格其实也很简单，就是按照乘以 2 的大小递增。如果用户申请的是 512 字节，那就返回 512 字节就可以了，但如果用户申请的是 513 字节，那么就分配 512 * 2 个字节，其实就是 1024 个字节。如果用户申请的是 1025 个字节，那就会分配 1024 * 2 个字节，也就是 2048 个字节。由此可见，这种分配方式其实还是会造成比较大的内部内存碎片。最后就是 8 KB - 16 MB 之间的分配规格了。在这个区间的内存分配也是按照乘以2 的大小递增的，和 512 - 4 KB 的一样。所以我就不再重复举例了。内存分配的规格还是很容易理解的，到此为止，关于这一块的知识就讲解完毕了。当然，这个知识肯定会对我的程序带来一点新的变动，程序需要简单重构一下。原因很简单，既然内存分配是有严格的规定的，肯定就不能用户申请多少，就分配多少呀。所以，我需要在自己的程序中添加一个规整内存的方法，把用户申请的内存传递到该方法中，将内存规整一下，比如说用户申请了 14 个字节，那么经过这个方法的规整，就会返回 16 个字节，然后再去 PoolChunk 中分配 16 个字节即可。

既然要定义这个规整内存的方法了，那么这个方法怎么就知道用户申请的内存要按什么规格来分配呢？毕竟我们刚刚介绍了 3 种内存分配的规格。申请 15 个字节时，肯定不能按照 512 - 4 KB 区间的规格来分配。这时候，其实就轮到刚才定义的三个类型登场了，Tiny、Small 和 Normal 其实是程序中的枚举对象，被定义在 PoolArena 类中，而刚才我为大家介绍的规整内存的方法，也定义在 PoolArena 类中。所以，接下来，我就简单地重构一下 PoolArena，请大家看看重构后的 PoolArena 和之前有什么不同。请看下面代码块。

java

复制代码

`abstract class PoolArena<T> {    //只展示部分代码     //定义内存规格的枚举类     enum SizeClass {         //Tiny的大小为16B到496B，按照16B的大小递增         Tiny,         //Small的大小为512B到4KB，按照乘以2的大小递增         Small,         //Normal的大小为8KB到16MB，按照乘以2的大小递增，大于16MB的为Huge，不会被缓存，这里的意思是不会被申请为Chunk         //实际上，在Netty的内存分配中，是先从内存中申请了一大块大内，然后再从这一大块内存中逐渐分配给各个线程使用的         //这一大块内存就为Chunk，值为16MB         Normal     }     /**      * @Author: PP-jessica      * @Description:分配内存的方法，这个是本次重构新增的方法。参数都是从PooledByteBufAllocator      * 类的newDirectBuffer方法中传过来的      */     PooledByteBuf<T> allocate(int reqCapacity, int maxCapacity) {         //得到一个池化的ByteBuf，这里就会和我们之前学的对象池连接起来了，因为newByteBuf该方法会         //调用到PooledDirectByteBuf的newInstance方法内，在该方法内就是从线程私有的对象池内获得一个ByteBuf对象         //也就是说，哪个线程正在执行该方法，就会从哪个线程的对象池中获得PooledDirectByteBuf对象         PooledByteBuf<T> buf = newByteBuf(maxCapacity);         //给ByteBuf分配内存，这里大家可以看到，我们分配的是直接内存，而该内存是被一个ByteBuf包装着的         allocate(buf, reqCapacity);         return buf;     }     //该方法也是新添加的，就是用来得到一个PooledDirectByteBuf对象     //并且是从PooledDirectByteBuf的对象池中得到的     protected PooledByteBuf<ByteBuffer> newByteBuf(int maxCapacity) {         return PooledDirectByteBuf.newInstance(maxCapacity);     }     //新引入的一个方法     private void allocate(PooledByteBuf<T> buf, final int reqCapacity) {         //这个方法就起到了规整要申请的内存的作用         //得到规整之后的内存，所以，这里大家也可以清楚了，并不是用户申请的多少内存就分配多少         //分配系统会自动补全要分配的内存，得到了normCapacity之后         //就会以normCapacity的大小去PoolChunk中真正分配内存         final int normCapacity = normalizeCapacity(reqCapacity);     	//使用同步锁，解决多线程分配内存可能带来的并发问题         synchronized (this) {             allocate(buf, reqCapacity, normCapacity);         }     }     //这个方法的参数发生了一些变化，并且，这里我把该方法的返回值去掉了     private void allocate(PooledByteBuf<T> buf, int reqCapacity,int normCapacity) {         //可以看到，PoolChunList的allocate方法也重构了         if (q050.allocate(buf，reqCapacity) || q025.allocate(buf，reqCapacity) || q000.allocate(buf，reqCapacity) || qInit.allocate(buf，reqCapacity) ||                 q075.allocate(buf，reqCapacity)) {             return;         }         //程序第一次申请内存时，肯定还没有创建ChunkPool，这时候要创建一个chunk内存块         //如果上面都没有分配成功，那就意味着所有的chunk中剩余可分配内存都不够了，这时候就要创建         //新的PoolChunk，让操作系统帮助申请16MB内存供程序内部使用，这里的CHUNK_SIZE就是该类的成员变量         //只不过没有列出来，是16MB         PoolChunk<T> c = new PoolChunk(new DirectByteBuffer(CHUNK_SIZE),CHUNK_SIZE);         //分配内存，PoolChunk的allocate方法的参数其实也要修改一下         c.allocate(buf，reqCapacity,normCapacity);         //接着把这个chunk内存块加入到init链表中         qInit.add(c);     }     //接下来就是规整内存的方法了     int normalizeCapacity(int reqCapacity) {         //判断要申请的内存必须是大于0的         checkPositiveOrZero(reqCapacity, "reqCapacity");         //这个是针对大于16MB的内存的的规整，我们暂时还不需要关注这里         //其实这里就是如果用户申请的是大于16MB，就会直接申请这个内存         if (reqCapacity >= chunkSize) {             return directMemoryCacheAlignment == 0 ? reqCapacity : alignCapacity(reqCapacity);         }         //判断申请的内存是否为Tiny大小的，不是Tiny就意味着是另外两种，而另外两种         //分配内存都是按照乘以2递增的，所以使用相同的算法         if (!isTiny(reqCapacity)) {             //这里进入分支，说明要申请的内存不是tiny类型的，得到要申请的内存             int normalizedCapacity = reqCapacity;             normalizedCapacity --;             normalizedCapacity |= normalizedCapacity >>>  1;             normalizedCapacity |= normalizedCapacity >>>  2;             normalizedCapacity |= normalizedCapacity >>>  4;             normalizedCapacity |= normalizedCapacity >>>  8;             normalizedCapacity |= normalizedCapacity >>> 16;             normalizedCapacity ++;             //判断normalizedCapacity是否溢出了，溢出就右移             if (normalizedCapacity < 0) {                 normalizedCapacity >>>= 1;             }             return normalizedCapacity;         }         //这里的逻辑就简单一些了，走到这里就意味着要申请的内存是tiny大小的         //tiny是按16B递增的，所以判断能够被16整除，可以整除就能直接返回         if ((reqCapacity & 15) == 0) {             return reqCapacity;         }         //这里也涉及到一个位运算，首先我们要弄清楚15取反的值         //～15的二进制  1111 1111 1111 1111 1111 1111 1111 0000         //如果reqCapacity小于16，那这个数的二进制的低五位肯定不是1，所以做与运算结果肯定为0         //所以，这里的意思就是如果分配的内存小于16B，那就直接返回16B         //而如果申请的内存是大于十六的，做了与运算后得到的就是个16的倍数，再加上16仍然是16的倍数，直接返回即可         return (reqCapacity & ~15) + 16;     }     /**      * @Author: PP-jessica      * @Description:判断要申请的内存是否小于512字节      */     static boolean isTiny(int normCapacity) {         //0xFFFFFE00是个十六进制的数，换算成二进制为 1111 1111 1111 1111 1111 1110 0000 0000         //496的二进制为                          0000 0000 0000 0000 0000 0001 1111 0000         //512的二进制为                          0000 0000 0000 0000 0000 0010 0000 0000         //这两个数做&运算的值         return (normCapacity & 0xFFFFFE00) == 0;     } }`

由于内存分配规格的引入，我们的程序又一次重构了。在上面的 PoolArena 类中，代码注释也非常详细，所以我也就不再重复解释什么了。当然，我们还是不急着往下讲。让我们思考一下，如果说现在的 PoolArena 类就是我的内存分配系统最终完善后的样子，那么请问，这个类设计成这样，足够让程序完美运行吗？说得再直白一点，请看下面代码块中的方法。

java

复制代码

 `//新引入的一个方法 private void allocate(PooledByteBuf<T> buf, final int reqCapacity) {     //这个方法就起到了规整要申请的内存的作用     //得到规整之后的内存，所以，这里大家也可以清楚了，并不是用户申请的多少内存就分配多少     //分配系统会自动补全要分配的内存，得到了normCapacity之后     //就会以normCapacity的大小去PoolChunk中真正分配内存     final int normCapacity = normalizeCapacity(reqCapacity); 	//使用同步锁，解决多线程分配内存可能带来的并发问题     synchronized (this) {         allocate(buf, reqCapacity, normCapacity);     } }`

上面代码块中的方法是重构后的 PoolArena 类新添加的。在这个方法中，首先对用户申请的内存做了一下规整，然后就开始在同步代码块中分配内存了。可以说这个方法把用户申请的内存规整了，同时也解决了并发问题。看起来好像没什么问题，但是根本经不起仔细推敲。比如说，既然我都已经给自己的程序设置了内存分配的规格，那么分配的时候是不是也应该按照设定的内存规格来分配呢？这句话可能有歧义，那我就换一种说法，现在大家肯定都清楚一个 PoolChunk 对象其实就管理着 16 MB 的堆外内存。假如用户现在要申请 4 个字节的堆外内存，就意味着要从 PoolChunk 对象管理的 16 MB 中分配 4 个字节出来交给用户使用。当然，用户申请的内存肯定要经过规整，成为 16 个字节。也就是说，最后肯定要从 PoolChunk 中分配出来 16 个字节交给用户使用。如果是这样来分配内存，大家有没有觉得哪里不太合适？

我只申请一个小小的 16 字节内存，就要兴师动众从 16 MB 中给我分配，打个比方，就像是我现在需要 5 毛钱，如果你有个 1 块钱，直接换成零钱给我 5 毛就行了。但我有个怪癖，见不得 100 块钱被破开，这会让我很难受。当然，坦诚一点的话，让我难受的不是 100 块钱被破开了，而是 100 块钱被破开了，可你只分了我 5 毛。如果你分我 50 或者 20、30 的，那我希望你把你身上的所有 100 块都破开。但你最后只是拿出 100 块，然后从这 100 里面给我分了 5 毛钱，这让我很难受。如果你手里有 1 块就好了，或者没有 1 块，你有个 5 块 10 块的，也比直接破开一个 100 的要好一点。可问题是，你身上只有一张百元大钞，那该怎么让我好受点呢？就是你先把这 100 块找人换成零钱，比如就换成一个 50 和两个 25，或者是 一个 25 和 15 个 5 块的。然后你就从一个 5 块里面给我分 5 毛就行了。

如果大家对上面这个例子的逻辑稍微理解一些了，那么接下来我就想直奔主题了，因为我们已经在内存分配这一块耗费了太多时间了。实际上，在 Netty 的内存分配系统中，会严格按照我讲解的三种内存规格来进行内存分配。并且也会将 PoolChunk 对象管理的内存进一步拆分。直截了当地说，一个 PoolChunk 对象管理的 16 MB 堆外内存最小的分配单位是 8 KB。也就是说，如果从 PoolChunk 对象中申请内存，一次最少会分配出去 8 KB，不会比这个再少了。这时候肯定就会有人指出，如果用户只申请 16 个字节，但是 PoolChunk 却要分配出去 8 KB，这不是太浪费了吗？所以啊，这就用到我刚刚举的例子了，我们就可以把这个 PoolChunk 当作 100 块，把最少分配出去的 8 KB 当作破开的一部分零钱，如果申请的是 16 字节的内存，就从这分配的 8 KB 内存中分配出去 16 字节给用户使用。如果这个逻辑大家也清楚了，那么接下来，我就想告诉大家，在 Netty 的内存分配系统中，确切地说是在这个 PoolArena 类中进行内存分配的时候，会根据规整后的内存进一步判断该内存是属于 Tiny、Small 还是 Normal 类型的，如果是 Tiny 或者 Small 类型的，那就要从 PoolChunk 中分裂出来的 8 KB 内存中分配内存，如果是 Normal 类型的，才会直接从 PoolChunk 对象中分配，因为 Normal 类型的内存规格最小也是 8 KB，随意就可以直接去 PoolChunk 中分配了。并且，在分配的过程中还会在 Tiny 或者 Small 类型中进一步细分。如果是 Tiny 类型的要怎么从 8 KB 中分配，如果是 Small 类型的要怎么从 8 KB 中细分。所以，在这个逻辑的指导下，刚才代码块中单独列出的 PoolArena 中的 allocate 方法，应该再次重构一下。当然，现在重构我只能使用伪代码稍微展示一下逻辑。具体的重构逻辑，在后面会详细讲解。请大家看下面的代码块。

java

复制代码

`//重构后的方法 private void allocate(PooledByteBuf<T> buf, final int reqCapacity) {     //规整内存     final int normCapacity = normalizeCapacity(reqCapacity); 	//判断要分配的内存是多大，是不是tiny或者small大小的     if (isTinyOrSmall(normCapacity)) {         //走到这里说明分配的内存是Tiny或者Small类型的         //所以还要进一步细分         if (tiny) {             //走到这里就是分配Tiny类型的内存         }else {             //走到这里就是分配Small类型的内存         }     } 	//走到这里说明分配的内存是属于Normal类型的     //所以直接去PoolChunk中分配即可，使用同步锁，解决多线程分配内存可能带来的并发问题     synchronized (this) {         //这里的allocate方法要被allocateNormal方法取代了，当然，仅仅是方法名变了，方法逻辑仍然没变         allocateNormal(buf, reqCapacity, normCapacity);     } } //为了使逻辑连贯，所以这里我就把allocateNormal方法也搬运过来，其实这个方法 //就是之前的 allocate(buf, reqCapacity, normCapacity)方法，只不过方法名称变了一下 private void allocateNormal(PooledByteBuf<T> buf, int reqCapacity,int normCapacity) {     //可以看到，PoolChunList的allocate方法也重构了     if (q050.allocate(buf，reqCapacity) || q025.allocate(buf，reqCapacity) || q000.allocate(buf，reqCapacity) || qInit.allocate(buf，reqCapacity) ||             q075.allocate(buf，reqCapacity)) {         return;     }     //程序第一次申请内存时，肯定还没有创建ChunkPool，这时候要创建一个chunk内存块     //如果上面都没有分配成功，那就意味着所有的chunk中剩余可分配内存都不够了，这时候就要创建     //新的PoolChunk，让操作系统帮助申请16MB内存供程序内部使用，这里的CHUNK_SIZE就是该类的成员变量     //只不过没有列出来，是16MB     PoolChunk<T> c = new PoolChunk(new DirectByteBuffer(CHUNK_SIZE),CHUNK_SIZE);     //分配内存，PoolChunk的allocate方法的参数其实也要修改一下     c.allocate(buf，reqCapacity,normCapacity);     //接着把这个chunk内存块加入到init链表中     qInit.add(c); }`

虽然讲了这么多，但是很遗憾，现在我们还不能直接剖析从 PoolChunk 中分配出来的 8 KB 内存该怎么包装，包装该内存的对象又定义在哪个类中，以及 Tiny 或者 Small 大小的内存究竟该怎么分配，具体过程是什么样的，这些我还都不能为大家剖析。路总得一步步走，要想剖析这些知识，首先得知道 8 KB 的内存是怎么从 PoolChunk 中分配出来的。所以，接下来，我们的重点就是顺着 allocateNormal 方法的执行链路，看看在 PoolChunk 中是怎么把一个 8 KB 的内存分配出来的。我们就假设现在用户创建了一个 ByteBuf 对象，希望申请 8 KB 的堆外内存交给这个 ByteBuf 来使用，那该怎么分配呢？这一章肯定也讲不完了，就放到下一章讲解吧。我们下一章见。

**总结**

这一章的篇幅比较长，但是总结下来，其实讲解的知识点并不算多。首先就是重构了一下各个组件中的 allocate 方法，接着就把 PooledByteBufAllocator 重构了一下，在重构 PooledByteBufAllocator 的过程中，我们明确了 PoolArena 数组的长度以及数组中 PoolArena 对象是怎么分配给线程的，同时还引入了一个 PoolThreadCache 类。最后我为大家分析了内存分配时按照什么规格分配的，以及怎么解决外部内存碎片问题，当然，内部内存碎片的问题无法避免。文中给出的代码也都是极简化了的，和我为大家提供的源码还有些差别，我也不建议大家现在就去看我提供的源码。等内存分配的章节全部学习完了，掌握了内存分配的整理流程和各个组件的功能以及使用方法，再去看源码就会事半功倍了。