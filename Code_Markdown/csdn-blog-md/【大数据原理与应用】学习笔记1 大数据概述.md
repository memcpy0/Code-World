	0 @[toc]

下面是我学习中国大学慕课的《大数据技术原理与应用》做的笔记。

# 一、前期准备
## 1. 教材、配套实验指导书和网络平台
关于书：
- 教材——厦门大学林子雨编著的 `《大数据技术原理与应用（第2版）》`；
- 配套的实验指导书——`《大数据基础编程、实验和案例教程》`；
- 教材和指导书的官网为：<a href="https://dblab.xmu.edu.cn/post/bigdatapractice/">https://dblab.xmu.edu.cn/post/bigdatapractice/</a>

关于平台：大数据课程公共服务平台——<a href="https://dblab.xmu.edu.cn/post/8197/">https://dblab.xmu.edu.cn/post/8197/</a>，提供讲义PPT、课后习题、学习指南（大数据软件安装和基础编程）、授课视频、技术资料等免费服务。

## 2. 大数据软件的安装和基础编程
大数据软件安装和基础编程指南访问地址：<a href="https://dblab.xmu.edu.cn/post/5663/">https://dblab.xmu.edu.cn/post/5663/</a>，根据上面的操作一步步来，可以顺利完成Linux系统和各种大数据软件的安装，开展基础编程实践。

## 3. 机房上机实验指南
在教材上面有上机实验课：
- 实验一：熟悉常用的Linux操作和Hadoop操作
- 实验二：熟悉常用的HDFS操作
- 实验三：熟悉常用的HBase操作
- 实验四：NoSQL和关系数据库的操作比较
- 实验五：MapReduce初级编程实践

可以用这里的机房上机实验指南——<a href="https://dblab.xmu.edu.cn/post/6131/">https://dblab.xmu.edu.cn/post/6131/</a>完成。


下面的是课程的学习笔记。
# 二、大数据概述

大数据时代：大数据的报道铺天盖地席卷而来的时候，也是2010年附近，脱离不了第三次信息化浪潮的背景——以大数据、云计算、物联网的普及为标志，三者共同促成了人类信息化发展史上的第三次信息化浪潮！
信息化浪潮的到来，需要技术支撑，技术支撑可以分为三个方面：存储(存储设备容量的不断增加、价格不断下降，有足够的空间后，人们往往倾向于保存尚不需要的数据，个人、企业数据越来越多，现在的存储技术可以达到什么样的水平？DVD光盘）
、计算（CPU处理能力大幅提升，2005年CPU的摩尔定律一直存在，后来多核处理器的使用，对数据的处理能力不断提升）和网络（全球范围类网络带宽不断扩张）中国计算机学会 发布的大数据报告
只有技术支撑，不足以引起大数据时代的到来，另一个重要的支撑，是数据产生方式的变革，这是至关重要的因素。再过去这些年中，数据产生方式经过了三个阶段：第一阶段是运营式系统阶段，第二阶段是用户原创内容阶段，但是这还不足以让大数据时代到来，感知式系统阶段，物联网的发展促进了大数据的到来，原因在于物联网的底层是感知层，如RFID、摄像头、探头、温度传感器等，数据每时每刻不断生成，...最终，由于物联网的兴起，我们才迎来了大数据时代。

大数据的发展历程：

。。。。。。。。。。。。。。。。。。。。。。。
大数据的概念和影响：
大数据的特性：
4V：Volume（大量化）l, Velocity,（快速化） Value（价值密度低）, Variety（多样化）
数据量大：大数据摩尔定律IDC做出的预测：数据每年都在以50%的速度在增长，人类在最近两年产生的数据量之和，相当于人类之前的全部历史产生的数据之和，2020年，全球将总共用于35ZB的数据量，相当于2010年，数据量增长30倍

Variety：大数据由结构化数据和非结构化数据组成，结构化数据只占10%，存储在关系数据库中非常规范的数据，非结构化数据占据90%，如图形图像、视频等等，类型众多

处理速度非常快：现在很多企业级应用需要秒级决策，从数据的生成到消耗，时间窗口非常小，可用于生成决策的时间非常少，1秒定律：这一点也是和传统的数据挖掘技术有着本质的不同。如谷歌公司开发的Dremel交互式查询产品，可以把成百上千台服务器调度起来做集群运算，在一两秒内，可以处理1PB的数据

价值密度低，商业价值高：大数据就是大数据，这么多数据实际上并不是都是很有价值的，很多数据都是没有任何价值的数据，比如监控摄像头，每时每刻生成大量的监控数据，如果不发生盗窃或者其他事件，这些数据就全然无用。

大数据的影响：
数据库专家Jim Gray博士，提出了事务机制，使得科学研究出现了第4种范式：
科学研究4种范式：第一种：实验，通过实验解决科学问题；理论：如牛顿三大定律，能量守恒等；计算：运用计算机的算力来求解问题，如四色定理的证明；以数据为驱动的全新研究时代：通过数据的驱动，分析发现问题，去解决问题。

维克托·迈尔·舍恩伯格《大数据时代》提出大数据时代对人类的思维方式产生了颠覆性的影响：完全颠覆了传统的思维方式：①全样而非抽样：在大数据时代之前，我们是没有办法去分析全样数据的，因为我们没有足够的存储空间去存储所有的数据，也没有足够的计算能力，去在我们人类可以接受的时间内计算出我们需要的答案，统计学只能去抽样，舍弃掉很多数据，抽样出一小部分数据去存储、计算和分析，现在我们有足够的空间、有集群的计算能力去完成数据处理，不需要像以前那样只做抽样

效率而非精确：在第一个颠覆的基础上，以前做抽样统计需要精确性，设计各种方式不断提高算法精确度，原因在于抽样计算的结果误差，放到全样上，会被放大而超出许可的范围，所以我们要追求精确度。而现在是全样分析，不存在误差被放大的问题，因此我们不用刻意追求精确度，而追求效率，非常关注时效性，很多时候数据的价值就在一瞬间，如果无法快速分析出结果，它的价值就消失了。

相关而非因果：更多追求事物之间的相关性，而非追求它们之间的因果关系。大数据只告诉你存在这样一种相关性，而不告诉你因果。

大数据的应用：
现在各行各业都已经融入了大数据的印记，如业务流程优化，监控身体状况，理解满足客户需求，金融交易，实时掌控交通情况、改善日常生活，研发智能医疗，研究智能汽车
 

大数据概念、影响、应用、关键技术
大数据的关键技术：
大数据的层次：
数据采集：
数据存储与管理：
数据处理与分析
数据隐私与安全
都有相应的大数据技术存在，最近十年来发展起来的大数据技术是二三层，代表了当前很多核心的大数据技术，归结起来为两大核心技术：分布式存储和分布式处理！

大数据技术解决的两大核心问题，就是怎么存储海量数据，单机无法存储，需要使用计算机集群，使用分布式存储。要对数据进行处理分析，单台计算机无法高效完成，我们也需要分布式的处理。

分布式存储和分布式处理，都主要以谷歌的技术为代表，最核心的是：分布式数据库BigTable，分布式文件系统GFS，分布式并行处理技术MapReduce。

关于大数据技术模式的问题：不同的企业应用场景属于不同的计算模式，需要使用不同的大数据技术，有些需要批处理，有些需要实时计算，有些需要交互式计算，所以我们需要对大数据技术的计算模式进行分类：
①	批处理计算：MapReduce是批处理计算模式的典型代表，它不是适合于做实时的交互式计算，无法做到秒级响应，显然不能满足时效性的要求；代表性的产品就是MapReduce，还包括2015年异军突起的Spark，虽然也是批处理，但是Spark的实时性更好，还解决了一些MapReduce的缺点：比如MapReduce无法高效执行迭代计算等
②	流计算：专门针对流数据的实时计算，比如日志流，需要实时响应和处理，否则分析结果就会失去商业价值，实现的秒级的针对数据流的实时处理；代表性产品是S4+Storm+Flume
③	图计算：高效地处理图结构数据的产品，比如社交网络和地理信息系统的数据等
④	查询分析计算：交互式查询，常用于分析系统，针对海量数据的实时分析，典型代表的产品是Google的Dremel、Hive、Cassandra等

 
大数据、云计算、物联网的关系：
云计算：解决两个核心问题：海量数据的分布式存储和分布式处理；云计算的典型特征：虚拟化和多用户，构成云计算的一个非常核心的层面：通过网络以服务的方式向用户提供非常廉价的IT资源。
企业用户不再需要自己构建IT基础设施，不用建机房、安装硬件设备和软件、负责系统维护，可以租用云端资源。
云的方式非常多：公有云(一些大型企业构建好云平台后，面向所有的社会公众提供服务)，私有云(企业内部构建和使用的云)和混合云
 
 
三种云服务：IaaS,Pass,Saas
IaaS——基础设施即服务，将基础设施(计算资源和存储)作为服务出租
PaaS——平台层：平台即服务。云计算时代的产品开发，个体没有能力搭建云平台环境开发云计算产品，像谷歌等大型企业则提供现成的云平台开发环境和接口，用它的资源开发各种运算产品，并部署到它的分布式服务器平台上。将平台作为服务卖给你。
SaaS——软件即服务，软件作为一种服务买给用户，典型的案例如云财务软件，现在有公司专门提供云财务软件，搭建集群机房，用户可以申请云软件服务，以服务的方式将财务软件卖给你。

除了分布式存储和处理外，还要实现多租户和虚拟化(Hadoop平台安装需要构建在Windows平台上时，需要Virtual虚拟机，安装Linux系统)

云计算的数据中心（云计算的温床），各种数据和应用并非在天上云端，而是位于数据中心里，由成千上万服务器构成，掌握了数据中心，就等于掌握了大数据时代的发展基础。

随着云时代的来临，大数据（Big data）也吸引了越来越多的关注。大数据（Big data）通常用来形容一个公司创造的大量非结构化数据和半结构化数据，这些数据在下载到传统的关系型数据库用于分析时会花费过多时间和金钱。大数据分析常和云计算联系到一起，因为实时的大型数据集分析需要像MapReduce一样的框架来向数十、数百或甚至数千的电脑分配工作。

大数据是什么？
大数据的定义
           
           至今没有公认的定义 
定义1 (Kusnetzky, Dan. What is "Big Data?") 
所涉及的数据量规模巨大到无法通过人工，在合理时间内达到截取、管理、处理、并整理成为人类所能解读的信息 。

 定义2 (维克托·迈尔-舍恩伯格、肯尼斯·库克耶.“大数据时代”) 
不用随机分析法（抽样调查）这样的捷径，而采用所有数据的方法 。

 定义3 (“大数据”（Big data）研究机构Gartner) 
“大数据”是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。
对于“大数据”（Big data）研究机构Gartner给出了这样的定义。“大数据”是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应海量、高增长率和多样化的信息资产。
大数据是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。
大数据就是“未来的新石油”。

何谓”大”数据
大数据的特征
容量（Volume）

数据的大小决定所考虑的数据的价值和潜在的信息
种类（Variety）
数据类型的多样性

速度（Velocity）
指获得数据的速度

价值（value）
合理运用大数据，以低成本创造高价值

复杂性（Complexity）
数据量巨大，来源多渠道

真实性（Veracity）
数据的质量

可变性（Variability）
妨碍了处理和有效地管理数据的过程

大数据就是互联网发展到现今阶段的一种表象或特征而已，没有
必要神化它或对它保持敬畏之心，在以云计算为代表的技术创新大幕的衬托下，这些原本看起来很难收集
和使用的数据开始容易被利用起来了，通过各行各业的不断创新，大数据会逐步为人类创造更多的价值。

价值密度低，商业价值高  
以视频为例，连续不间断监控过程中，可能有用的数据仅仅有一两秒，但是具有很高的商业价值。

大数据带来的思维变革
大数据带来的思维变化

在决策思维方式方面，大数据完全颠覆了传统的思维方式： 
全样而非抽样 ；相关而非因果；效率而非精确。
更多：不是随机样本
而是全部数据
更好
不是因果关系
而是相关关系
更杂
不是精确性
而是混杂性

大数据产业是指一切与支撑大数据组织管理和价值发现相关的企业经济活动那个的集合。

 


大数据处理架构Hadoop
Hadoop的发展历程、特性和应用现状：Apache基金下的软件，开源的分布式计算平台，屏蔽了大数据底层实现的细节，后台的所有工作全部由系统自己实现，更加简单得多。
功能组件

Hadoop是用Java语言开发的，但是这不意味着只能用Java语言去编写Hadoop程序。可以支持多种编程语言，具有很好的跨平台特性，并不是一个单一的技术，而是一系列大数据技术的集合体，是一整套解决方案的统称。对于Hadoop有两大核心，分布式文件系统和分布式并行框架MapReduce。分布式文件系统解决了如何用成百上千台甚至上万台服务器去存储海量数据的问题，MapReduce分布式并行框架解决了如何使用计算机集群处理海量数据、同时完成任务的分布式编程处理。这样可以大大提高任务处理效率。解决了大数据领域的两大核心问题，所以Hadoop在许多领域得到了广泛的应用，解决了很多企业的实际需求，在很多大型公司中都有应用，比如Facebook公司用于日志处理、推荐系统和数据仓库等方面。

Hadoop是一个对海量数据集进行分布式并行处理的软件框架，是一个高效的、可靠的、可伸缩的软件框架：
高可靠性：冗余副本机制
高效性：利用集群做运算，非常高效
高可扩展性：可以不断往集群中增加机器
成本非常低：整个机器集群可以有许多普通PC机，来构成一个集群
 
部署

分布式文件系统HDFS
1.	HDFS的由来
简介 
Hadoop Distributed File System Hadoop平台上的分布式文件系统
整个Hadoop平台上的两大核心组件之一。大数据技术，以及整个Hadoop平台，所要解决的最核心的两大问题，一个就是大数据分布式存储，另一个就是大数据的分布式处理。HDFS解决前者。最后通过简单实例，演示如何进行HDFS的编程实践。

计算机集群基本架构：机架之间使用光纤交换机

在这样一个集群结构中，分布式文件系统是将大的文件分布地存储到很多台机器上面去。集群中的机器有主从之分，有一个作为主节点，承担起数据目录（元数据）服务，从节点具体完成数据的存储任务，分布式文件系统结构：

 
HDFS是现在非常流行的分布性文件系统，因为它是Hadoop开源平台上的一个重要组件。HDFS在设计之初要实现如下几个目标：
兼容廉价的硬件设备，这是大数据时代一个非常基本的要求，大数据时代最重要的是能够让企业以可承担的成本去存储和处理数据，而不是像以前一样，使用高端机器如小型机。。。在大数据时代，很多技术诞生以后，只要非常廉价普通的PC机，就可以构建一个相关集群。整个分布式文件系统在设计的时候，底层的硬件就是这么低端。

实现流数据读写：HDFS和其他分布式文件系统、和传统的文件系统有非常大的区别的一个地方。传统的文件系统在进行文件读写的时候，以块数据为单位，每次读取指定的某一部分数据，而HDFS设计的目标就是对大量数据的读写，而非访问文件数据的子集，去访问一块一块的数据，而是为了满足大规模数据的批量处理需求。HDFS以这个需求为出发点点来设计的。

支持大数据集：HDFS可以支持大数据文件，一个HDFS文件，小的几百MB，大可以大到TB以上，它所管理的文件大的可以有几个T。

支持简单的文件模型：为了实现高效的数据读写，HDFS对文件模型进行了简化，牺牲了一些相关的性能，获取了批量处理的特性。HDFS只允许追加数据，绝对不允许修改数据。

强大的跨平台兼容性：Hadoop整个集群的组件基于Java语言开发，因此具有很好的跨平台性。

上述目标HDFS都实际实现了。HDFS在设计实现上述非常好的特性的同时，也不可避免有其自身的局限性：
不适合低延迟的数据访问：HDFS是面向大规模数据集的六十读写，设计上是为了批量读全部或者大部分数据，而不是非常精确读取某一条数据，因此实时性不高，不能满足实时的数据处理需求。那么什么组件可以满足实时处理需求呢？分布式数据库HBase，它具备随机读写特性，可以满足实时性处理需求。
二是无法高效存储大量小文件，HDFS实际上是通过元数据来指引客户端到哪个节点寻找相关的文件，因为一个文件会被切分并存储到不同节点。关于数据如何分布的元数据，都会被保持在HDFS的名称节点中，保存到内存中去。要到内存中检索，HDFS会建立一个索引数据结构。如果小文件太多，索引结构会非常庞大，搜索效率降低，小量的文件越多，搜索所耗的时间越多。

三是不支持多用户写入及任意修改文件。设计的时候就只允许追加，不允许修改数据。所以会导致这样的局限。


2.	相关概念
①	 快的概念：是整个HDFS中最核心的概念，其中之一就是快。和普通文件系统的块，有一定的联系，也有一定的区别。二者的联系在于：它也是为了分摊磁盘读写开销，也就是在大量数据间分摊磁盘寻址的开销；区别：HDFS中的块要比普通文件系统的块大很多，普通文件系统的一个块一般有几千个字节，而分布式文件系统HDFS的块大小默认为64MB，可以设置得更大。这样设计的考量在于：HDFS要支持面向大规模数据存储，另外也是为了降低分布式结点的寻址开销——访问HDFS文件，需要经过三级寻址——先去找它的元数据目录，再找到其数据结点，最后从数据结点中去取数据，若设计的块太小，会导致后面的寻址开销特别大。因此HDFS会把块设计得大一些。当然，也不是越大越好，HDFS最终确认块大小的时候，还会受到后续MapReduce设计的影响。如果块过大，会导致MapReduce就一两个任务在执行，那就完全牺牲了MapReduce的并行度，基本发挥不了分布式并行处理的效果。HDFS采用抽象的块的概念设计，到底会带来什么样的设计好处呢？
第一个明显好处就是：支持大规模文件存储，HDFS可以把一个大的文件进行切割，切成很多个小块，分布地、打乱地存储在不同的机器上面，可以突破单机存储容量的上限。二是：可以简化系统设计，方便元数据的设计和管理，因为块大小是固定的，一个文件除以块大小，可以很容易估计一个文件需要多少块，它的存储需求为多少等等。三是比较适合数据备份。整个HDFS中一个非常重要的特性，是对数据的冗余备份——一个块会被冗余地存储到多个不同的结点上面去。有了这种块的设计，以块为基础，就非常方便备份。
②	名称结点、数据结点：整个HDFS文件系统中，包含非常多的机器即结点，其中一个结点是主节点，为名称结点，相当于整个HDFS集群的管家，负责整个文件系统元数据的存储，当其他的客户端来访问具体数据时，如何找到分成快、分布地存放在不同机器上的数据呢？通过名称结点，它记录了这些信息，相当于一个数据目录；其他结点为从节点，或者说数据结点，负责具体存储实际数据。
元数据：一个HDFS中的名称结点要存储元数据——包括文件是什么、分成多少块、每块和文件如何映射、每个块被存储到哪个服务器上；数据结点中的数据最终要存储到磁盘中去，保存到数据结点本地的Linux文件系统中去。
③	名称结点保存元数据，非常重要：有几大非常关键的数据结构，如FsImage，一个非常核心的数据结构，用于保存系统文件树以及文件树中所有的文件和文件夹的元数据，通过FsImage可以知道整个文件系统目录是什么样子的。还有EditLog，它记录整个运行过程中，对数据进行的诸如创建、删除、重命名等操作。为什么要设计这么两个核心数据结构呢？首先看FsImage，存储文件的复制等级、修改和访问时间、访问权限、块大小及组成文件的块。要注意的是，FsImage不保存这些块具体存储到哪个数据结点中，这些信息单独在内存中的一个区域维护，FsImage只维护上述的信息。当数据结点加入到一个集群中，数据结点会向名称结点报告，自己的结点中都保存有哪些数据块，作为管家的名称结点，可以自己构建一个清单，知道这些数据块，具体分布到哪些结点中——通过运行过程中，名称结点和数据结点进行不断沟通，实时维护这些信息，这些信息都是保存在内存中。至于这两个数据结构到底是怎么用的，名称结点在启动的过程中到底是怎么处理这两大数据结构的？首先启动的时候，先将FsImage从磁盘加载到内存中去，和EditLog中的各项操作进行合并，FsImage保存的是历史元数据，经过操作后得到一个新的FsImage，然后删除旧的FsImage，并生成一个空的EditLog。以后，随着数据的不断添加删除，操作信息都保存在EditLog中。……
④	第二名称结点：名称结点的冷备份；对EditLog的处理，解决EditLog在运行过程中不断增大的问题。第二名称结点定时和第一名称结点进行通信，在一定的时刻告诉
⑤	数据结点：负责具体数据的存储。每个数据结点中的数据被保存到各自的Linux服务器的本地文件系统中。
3.	HDFS体系结构、存储原理、数据读写过程
HDFS采用主从架构，主节点为名称结点，作为管家，从节点是数据结点；客户端要访问数据，首先和名称结点打交道，获取元数据信息，从而获得数据块具体存储位置，然后从各个数据结点中实际读取数据；写操作也是一样，名称结点说明要将文件分为多少个块，各个块分别存储到哪一个数据结点中

命名空间管理：HDFS只有一个命名空间，包含目录、文件、块，和传统的分级文件系统一样，访问方式也是使用分级目录结构 /+目录名称。所有的HDFS通信协议构建在TCP/IP之中。客户端向名称结点发起TCP连接；集群中名称结点和数据结点的交互使用专门的数据结点协议实现；客户端读取数据和数据结点进行交互，通过远程调用RPC实现。



根据上述原理，HDFS存在局限性：这些在升级版本中都得到了改进。
1.	命名空间限制：名称结点保持在内存中，因此名称结点能够容纳的对象（文件、块）的个数会受到空间大小的限制
2.	性能的瓶颈：整个分布式文件的吞吐量，受限于单个名称结点的吞吐量
3.	隔离问题：由于集群中只有一个名称结点，只有一个命名空间，因此无法对不同应用程序进行隔离
4.	集群的可用性：一旦这个唯一的名称结点发生故障，会导致整个集群不可用

HDFS的存储原理：
冗余数据保存的问题：
	HDFS架构在底层非常廉价的机器集群上，最致命的缺陷时：会不断出故障（出故障是常态，必须有冗余数据机制）在HDFS中，每个数据以块为单位都会被冗余保存，冗余因子为3，即每块都会冗余保存3份；可以自行设置，但是不宜过大，否则会造成磁盘开销过大。用这样的机制，冗余存储的好处在于：1.加快数据传输速度。当多个客户端访问同样的数据块时，如果将数据块冗余存储到不同的机器上，就可以并行访问；2.容易检查数据错误，多次保存，容易对比数据发现错误；3.保证数据可靠性，一个数据副本发生故障，很容易用另一个副本代替；另外，如果一个冗余副本发生故障，会自动恢复到用户设定的冗余因子水平。

一个块如何进行分配存储到不同的机器上：将块复制多个副本；对于第一个副本：如果是集群内部提交的块，则第一个副本放在要上传的数据结点中；如果是集群外部某个结点提交的块，HDFS会随机挑选一台磁盘不太满、CPU不太忙的结点，并将第一个副本放在其中。
第二个副本，会放在不同的机架上的数据结点；第三个副本，会放在第一个副本相同机架上的不同数据结点中；
第4个、第5个副本或者更多：随机放置

数据读取:就近读取：HDFS提供一个API，确定一个数据结点所属的机架ID，客户端可以调用API获取自己所属的机架ID。

当客户端读取数据时，从名称结点获取数据库不同副本的存放位置列表，列表中包含了副本所在的数据结点，调用API来确定客户端和这些数据结点所属的机架ID，当发现某个数据块副本对应的机架ID，当发现某个数据库副本对应的机架ID和客户端对应的机架ID相同时优先读取该副本的数据；没有发现，就随机选择一个副本读取数据
 
数据保存策略问题：
数据恢复问题：（1.0版本）
HDFS构建在计算机集群上，一般来讲，比较标准的数据中心都可能有三四千个结点；出现问题时如何解决？
名称结点出错：名称结点保存了两大核心的数据结构——FsImage和EditLog；平时会做一个冷备份，当名称结点出错时，会暂停服务一段时间，然后从第二名称结点中备份过来。到了2.0版本时，可以马上使用热备份提供服务。

数据结点出错：数据结点负责具体存储数据；它会定期通过远程调用向名称结点发送心跳信息，表明数据结点没有故障；当名称结点探测到某个数据结点故障后，会在状态列表中将该数据结点标志为宕机，然后将故障机上的所有数据重新复制分发到其他正常可用的机器上。因为所有数据都是冗余备份的，故障机上的数据肯定都在其他机器上有备份，因此HDFS将正常机器上的那些数据复制一份即可。和其他分布式文件系统，HDFS最大的区别在于可以调整冗余数据的位置，不仅在发生故障时可以调整，还可以在负载不均衡时进行调整。



数据本身出错：数据块被存储到不同的服务器上，可能会遇到磁盘损坏或者其他情形，使得数据产生错误。校验码的机制是校验码，校验码是整个文件被创建的时候，为每个数据块生成，并保存到同一个文件目录中去。存取数据时会计算校验码，和上次生成的校验码比对，不一致时说明数据发生错误，会进行冗余复制，恢复数据。

HDFS的数据读写过程：
分布式文件系统下的数据读写和传统的数据读写到底有什么区别。
在Hadoop里面，有一个FileSystem通用文件系统的抽象基类；可被DistributedFileSystem继承。

4.	HDFS编程实践

分布式数据库HBase
• 4.1  概述
• 4.1.1  从BigTable说起
BigTable是一个分布式存储系统
BigTable起初用于解决典型的互联网搜索问题
• 建立互联网索引
1 爬虫持续不断地抓取新页面，这些页面每页一行地存储到BigTable里
2 MapReduce计算作业运行在整张表上，生成索引，为网络搜索应用做准备
• 搜索互联网
3 用户发起网络搜索请求
4 网络搜索应用查询建立好的索引，从BigTable得到网页
5 搜索结果提交给用户
网页在BigTable中的存储样例
•BigTable是一个分布式存储系统
•利用谷歌提出的MapReduce分布式并行计算模型来处理海量数据
•不是直接存储到底层磁盘上，而是使用谷歌分布式文件系统GFS作为底层数据存储
•采用Chubby提供协同服务管理
•可以扩展到PB级别的数据和上千台机器，具备广泛应用性、可扩展性、
高性能和高可用性等特点
•谷歌的许多项目都存储在BigTable中，包括搜索、地图、财经、打印、
社交网站Orkut、视频共享网站YouTube和博客网站Blogger等

• 4.1.2  HBase简介
HBase是一个高可靠、高性能、面向列、可伸缩的分布式数据库，是谷歌BigTable的
开源实现，主要用来存储非结构化和半结构化的松散数据。HBase的目标是处理非常
庞大的表，可以通过水平扩展的方式，利用廉价计算机集群处理由超过10亿行数据
和数百万列元素组成的数据表
 
 
• 4.1.3  HBase与传统关系数据库的对比分析
关系数据库已经流行很多年，并且Hadoop已经有了HDFS和MapReduce，为什么需
要HBase?
•Hadoop可以很好地解决大规模数据的离线批量处理问题，但是，受限于Hadoop
MapReduce编程框架的高延迟数据处理机制，使得Hadoop无法满足大规模数据实时
处理应用的需求
•HDFS面向批量访问模式，不是随机访问模式
•传统的通用关系型数据库无法应对在数据规模剧增时导致的系统扩展性和性能问题
（分库分表也不能很好解决）
•传统关系数据库在数据结构变化时一般需要停机维护；空列浪费存储空间
•因此，业界出现了一类面向半结构化数据存储和处理的高可扩展、低写入/查询延迟
的系统，例如，键值数据库、文档数据库和列族数据库（如BigTable和HBase等）
•HBase已经成功应用于互联网服务领域和传统行业的众多在线式数据分析处理系统
中
• HBase与传统的关系数据库的区别主要体现在以下几个方面：
• （1）数据类型：关系数据库采用关系模型，具有丰富的数据类型和存储方式，
HBase则采用了更加简单的数据模型，它把数据存储为未经解释的字符串
• （2）数据操作：关系数据库中包含了丰富的操作，其中会涉及复杂的多表连接。
HBase操作则不存在复杂的表与表之间的关系，只有简单的插入、查询、删除、
清空等，因为HBase在设计上就避免了复杂的表和表之间的关系
• （3）存储模式：关系数据库是基于行模式存储的。HBase是基于列存储的，每个
列族都由几个文件保存，不同列族的文件是分离的
（4）数据索引：关系数据库通常可以针对不同列构建复杂的多个索引，以提高数
据访问性能。HBase只有一个索引——行键，通过巧妙的设计，HBase中的所有访
问方法，或者通过行键访问，或者通过行键扫描，从而使得整个系统不会慢下来
• （5）数据维护：在关系数据库中，更新操作会用最新的当前值去替换记录中原来
的旧值，旧值被覆盖后就不会存在。而在HBase中执行更新操作时，并不会删除数
据旧的版本，而是生成一个新的版本，旧有的版本仍然保留
• （6）可伸缩性：关系数据库很难实现横向扩展，纵向扩展的空间也比较有限。相
反，HBase和BigTable这些分布式数据库就是为了实现灵活的水平扩展而开发的，
能够轻易地通过在集群中增加或者减少硬件数量来实现性能的伸缩

• 4.2 HBase 访问接口
 
• 4.3 HBase 数据模型
• 4.3.1  数据模型概述
• HBase是一个稀疏、多维度、排序的映射表，这张表的索引是行键、列族、列限
定符和时间戳
• 每个值是一个未经解释的字符串，没有数据类型
• 用户在表中存储数据，每一行都有一个可排序的行键和任意多的列
• 表在水平方向由一个或者多个列族组成，一个列族中可以包含任意多个列，同一
个列族里面的数据存储在一起
• 列族支持动态扩展，可以很轻松地添加一个列族或列，无需预先定义列的数量以
及类型，所有列均以字符串形式存储，用户需要自行进行数据类型转换
• HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，
旧有的版本仍然保留（这是和HDFS只允许追加不允许修改的特性相关的）

• 4.3.2  数据模型相关概念
表：HBase采用表来组织数据，表由行和列
组成，列划分为若干个列族
• 行：每个HBase表都由若干行组成，每个行
由行键（row key）来标识。
• 列族：一个HBase表被分组成许多“列族”
（Column Family）的集合，它是基本的访
问控制单元
• 列限定符：列族里的数据通过列限定符（或
列）来定位
• 单元格：在HBase表中，通过行、列族和列
限定符确定一个“单元格”（cell），单元
格中存储的数据没有数据类型，总被视为字
节数组byte[]
• 时间戳：每个单元格都保存着同一份数据的
多个版本，这些版本采用时间戳进行索引
 
• 4.3.3  数据坐标
HBase中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一
个“四维坐标”，即[行键, 列族, 列限定符, 时间戳]
 
• 4.3.4  概念视图
• 4.3.5  物理视图
• 4.3.6  面向列的存储

• 4.4 HBase 的实现原理
• 4.5 HBase 运行机制
• 4.6 HBase 应用方案
• 4.7 HBase编程实践


NoSQL数据库

云数据库

