# 1. 详细说说你的项目吧
从以下几个方面进行项目介绍：
1. 项目的背景，包括：是自研还是外包、什么业务、服务的客户群是谁、谁去运营等问题。
2. 项目的业务流程（核心流程）
3. 项目的功能模块
4. 项目的技术架构
5. 个人工作职责
6. **个人负责模块的详细说明**，包括模块的**设计**，所用到的技术，**技术的实现方案**等。

一个例子：
1. 我最近参与的项目是我们公司自研的专门针对成人职业技能教育的网络课堂系统（[[../项目/学成在线/项目说明0. 项目架构、环境配置、数据库设计]]），网站提供了成人职业技能培训的相关课程，如：软件开发培训、职业资格证书培训、成人学历教育培训等课程。
2. 项目基于B2B2C的业务模式，培训机构可以在平台入驻、发布课程，我们公司作为运营方由专门的人员对发布的课程进行审核，审核通过后课程才可以发布成功，课程包括免费和收费两种形式，对于免费课程普通用户可以直接选课学习，对于收费课程在选课后需要支付成功才可以继续学习。
3. 本项目包括三个端：用户端(学生端)、机构端、运营端。核心模块包括：内容管理、媒资管理、课程搜索、订单支付、选课管理、认证授权等。
4. ==本项目采用前后端分离架构，后端采用SpringBoot、SpringCloud技术栈开发，数据库使用了MySQL，还使用的Redis、消息队列、分布式文件系统、Elasticsearch等中间件系统==。
	划分的微服务包括：内容管理服务、媒资管理服务、搜索服务、订单支付服务、 学习中心服务、系统管理服务、认证授权服务、网关服务、注册中心服务、配置中心服务等。
5. 我在这个项目中负责了内容管理、媒资管理、订单支付模块的设计与开发。
	- 内容管理模块，是对平台上的课程进行管理，课程的相关信息比较多。这里在数据库设计了课程基本信息表、课程营销表、课程计划、课程师资表进行存储。
	- 培训机构要发布一门课程，需要填写课程基本信息、课程营销信息、课程计划信息、课程师资信息，填写完毕后需要提交审核，由运营人员进行课程信息的审核，整个审核过程是程序自动审核加人工确认的方式，通常24小时审核完成。
	- 课程审核通过即可发布课程，课程的相关信息会聚合到课程发布表中，这里不仅要将课程信息写到课程发布表，还要将课程信息写到索引库、分布式文件系统中，所以这里存在分布式事务的问题，项目使用本地消息表加任务调度的方式去解决这里的分布式事务，保存数据的最终一致性。


1、Git代码冲突怎么处理？

我们在使用Git时难免会出现代码冲突的问题，出现冲突的原因是因为当本地文件的版本与目标分支中文件的版本不一致时当存在同一行的内容不同时在进行合并时会出现冲突。

代码冲突一般发生在以下情况：

1、多个分支向主分支合并时

2、同一个分支下pull或push操作时。

发生了冲突需要手动合并代码，选择最终的版本，可以通过图形界面，如下：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303291956020.png)
点击Merge
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303291957165.png)

选择版本后，点击Apply，提交代码并push到远程仓库。

不通过图形化界面处理冲突，当出现冲突后在代码中自动添加了版本标识，如下：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303291958157.png)
手动修改代码如下：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303292316409.png)


将文件添加到暂存区，提交文件，push到远程仓库即可。

2、你是在哪个分支开发？


我们不是直接在主分支开发，由技术经理创建独立的开发分支，我们是在独立的开发分支中进行开发，最后由技术经理将开发分支合并到主分支。


3、maven依赖版本冲突怎么处理？

maven依赖版本冲突一般是由于间接依赖导致一个jar包即有多个不同的版本，比如：A依赖了B的1.0版本，C依赖了B的2.0版本，项目依赖A和C从而间接依赖了B的1.0和2.0版本，此时B有两个版本引入到了项目中，当存在版本冲突时可能会出现ClassNotFoundException、NoSuchMethodError等错误。

处理版本冲突可以使用以下方法：

1、使用exclusions 排除依赖

比如：我们只依赖B的1.0版本，此时可以在依赖C时排除对B的依赖。

2、使用dependencyManagement锁定版本号。

通常在父工程对依赖的版本统一管理。

比如：我们只依赖B的1.0版本，此时可以在父工程中限定B的版本为1.0。



4、maven的常用命令

mvn clean //清除target目录中的生成结果

mvn compile //编译源代码

mvn test //执行单元测试

mvn package  //打包

mvn install //打包并把打好的包保存到本地仓库

mvn deploy //打包并把打好的包上传到远程仓库

## 2.5面试

1、Mybatis分页插件的原理？

首先分页参数放到ThreadLocal中，拦截执行的sql，根据数据库类型添加对应的分页语句重写sql，例如：(select * from table where a) 转换为 (select count(*) from table where a)和(select * from table where a limit ,)

计算出了total总条数、pageNum当前第几页、pageSize每页大小和当前页的数据，是否为首页，是否为尾页，总页数等。

## MySQL常见的存储引擎及区别？
一、InnoDB
1、**支持事务**。
2、**使用的锁粒度默认为行级锁，可以支持更高的并发**；也支持**表锁**。
3、支持外键约束；外键约束其实降低了表的查询速度，增加了表之间的耦合度。
二、MyISAM
1、**不提供事务支持**
2、**只支持表级锁**
3、**不支持外键**
三、memory
数据存储在内存中

总结：
- MyISAM管理非事务表，提供高速存储和检索以及全文搜索能力，如果在应用中执行大量select操作，应该选择MyISAM
- InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量insert和update操作，应该选择InnoDB

## MySQL建表时注意什么？
MySQL建表的经验有很多，下边列举一些： 
1、注意选择存储引擎，**如果要支持事务需要选择InnoDB**。
2、注意字段类型的选择：
	- 对于日期类型**如果要记录时分秒建议使用datetime**，只记录年月日使用date类型，对于字符类型的选择，
	- **固定长度字段选择char**，不固定长度的字段选择varchar，varchar比char节省空间但速度没有char快；
	- 对于内容介绍类的长广文本字段，使用text或longtext类型；
	- **如果存储图片等二进制数据，使用blob或longblob类型**；
	- ==对金额字段建议使用DECIMAL==；
	- 对于数值类型的字段，在确保取值范围足够的前提下，尽量使用占用空间较小的类型，
3、**主键字段建议使用自然主键，不要有业务意义**，建议使用int unsigned类型，**特殊场景使用bigint类型**。
4、如果要存储text、blob字段建议单独建一张表，使用外键关联。
5、**尽量不要定义外键**，保证表的独立性，**可以存在外键意义的字段**。
6、设置字段默认值，比如：状态、创建时间等。
7、==每个字段写清楚注释==。
8、==注意字段的约束==，比如：非空、唯一、主键等。



前端校验、后端也要校验！可以绕过前端（前端防君子，后端防老6）！



1、树型表的标记字段是什么？如何查询MySQL树型表？

树型表的标记字段是parentid即父结点的id。

查询一个树型表的方法：

1）当层级固定时可以用表的自链接进行查询。

2）如果想灵活查询每个层级可以使用mysql递归方法，使用with RECURSIVE 实现。



2、MyBatis的ResultType和ResultMap的区别？

ResultType：指定映射类型，只要查询的字段名和类型的属性名匹配可以自动映射。

ResultMap：自定义映射规则，当查询的字段名和映射类型的属性不匹配时可以通过ResultMap自定义映射规则，也可以实现一对多、一对一映射。



3、#{} 和 ${} 有什么区别？

\#{}是标记一个占位符，可以防止sql注入。

${} 用于在动态 sql中拼接字符串，可能导致sql注入。


### 4.6.4 面试

1、系统如何处理异常？

我们自定义一个统一的异常处理器去捕获并处理异常。

使用控制器增加注解@ControllerAdvice和异常处理注解@ExceptionHandler来实现。

1) 处理自定义异常

程序在编写代码时根据校验结果主动抛出自定义异常类对象，抛出异常时指定详细的异常信息，异常处理器捕获异常信息记录异常日志并响应给用户。

2) 处理未知异常

接口执行过程中的一些运行时异常也会由异常处理器统一捕获，记录异常日志，统一响应给用户500错误。

在异常处理器中还可以针对某个异常类型进行单独处理。


### 4.7.5 面试

1、请求参数的合法性校验如何做？ 

使用基于JSR303的校验框架实现，SpringBoot提供了JSR-303的支持，它就是spring-boot-starter-validation，它包括了很多校验规则，只需要在模型类中通过注解指定校验规则，在controller方法上开启校验。


7.7 面试
1、xxl-job的工作原理是什么？xxl-job是什么怎么工作？
XXL-JOB分布式任务调度服务由调用中心和执行器组成，调用中心负责按任务调度策略向执行器下发任务，执行器负责接收任务执行任务。
1）首先部署并启动xxl-job调度中心。(一个java工程)
2）首先在微服务添加xxl-job依赖，在微服务中配置执行器
3）启动微服务，执行器向调度中心上报自己。
4）在微服务中写一个任务方法并用xxl-job的注解去标记执行任务的方法名称。
5) 在调度中心配置任务调度策略，调度策略就是每隔多长时间执行还是在每天或每月的固定时间去执行，比如每天0点执行，或每隔1小时执行一次等。
6）在调度中心启动任务。
7）调度中心根据任务调度策略，到达时间就开始下发任务给执行器。
8）执行器收到任务就开始执行任务。


2、如何保证任务不重复执行?
1)调度中心按分片广播的方式去下发任务
2）执行器收到作业分片广播的参数：分片总数和分片序号，计算 任务id 除以 分片总数得到一个余数，如果余数等于分片序号这时就去执行这个任务，这里保证了不同的执行器执行不同的任务。
3）配置调度过期策略为“忽略”，避免同一个执行器多次重复执行同一个任务
4）配置任务阻塞处理策略为“丢弃后续调度”，注意：丢弃也没事下一次调度就又可以执行了
5）另外还要保证任务处理的幂等性，执行过的任务可以打一个状态标记已完成，下次再调度执行该任务判断该任务已完成就不再执行








3、任务幂等性如何保证？
它描述了一次和多次请求某一个资源对于资源本身应该具有同样的结果。
幂等性是为了解决重复提交问题，比如：恶意刷单，重复支付等。
解决幂等性常用的方案：
1）数据库约束，比如：唯一索引，主键。同一个主键不可能两次都插入成功。
2）乐观锁，常用于数据库，更新数据时根据乐观锁状态去更新。
3）唯一序列号，请求前生成唯一的序列号，携带序列号去请求，执行时在redis记录该序列号表示以该序列号的请求执行过了，如果相同的序列号再次来执行说明是重复执行。
这里我们在数据库视频处理表中添加处理状态字段，视频处理完成更新状态为完成，执行视频处理前判断状态是否完成，如果完成则不再处理。



2.6 面试 
2.6.1 为什么要用Freemarker静态化?如何做的？
什么是页面静态化？
页面静态化是指使用模板引擎技术将一个动态网页生成html静态页面。
满足下边的条件可以考虑使用静态化：
1、该页面被访问频率高，比如：商品信息展示、专家介绍页面等。
2、页面上的数据变化频率低，比如：商品发布后对商品信息的修改频率低，专家介绍信息修改频率低
静态化的技术很多，Freemarker是一个成熟的开源的模板引擎工具，简单易用，功能强大。
本项目使用Freemarker将课程信息静态化：
1）使用Freemarker的标签编写课程信息的模板
2）调用接口获取模板上需要的模型数据
3）调用Freemarker的API生成静态页面。
4）生成的静态页面最终会上传到文件系统方便访问。



4.6 面试 
4.6.1 说说对分布式事务的理解
什么是分布式事务？
由多个服务通过网络完成一个事务叫分布式事务。
比如：课程发布操作不仅要在本地数据库插入课程信息，而且还要请求索引服务将课程信息添加到索引库，还要请求MinIO将课程静态化并上传静态页面，这里就存在分布式事务。
分布式事务控制的方案有哪些？
首先根据CAP原理决定我们的需求，是要实现CP、还是要实现AP。
实现CP就是要实现强一致性，可以使用Seata框架基于AT、TCC模式去实现。
我们项目中大部分实现的是AP，使用本地消息表加任务调度完成分布式事务最终数据一致性。
如何使用本地消息表加任务调度完成分布式事务控制？
以发布课程为例进行说明，发布课程需要在内容管理数据库中写课程发布表记录，同时将课程信息同步到redis、ES、MinIO，这里存在分布式事务。
1）点击发布课程使用本地事务向发布表写一个课程信息，同时向消息表写一个消息记录（标记了发布了哪门课程）
2）xxl-job的调度中心使用分片广播模式向执行器下发任务，开始扫描消息表，查询到了待处理的消息。
3）根据消息的内容将课程信息同步到redis、ES、MinIO
4) 任务完成删除消息表记录。整个分布式事务完成，最终保证了一致性。

5.6.1 Elasticsearch是怎么使用的？
本项目使用Elasticsearch开发搜索服务，步骤如下：
1）首先创建索引（相当于mysql的表），将课程信息添加到索引库，对课程信息进行分词，存储到索引库。
2）开发一个搜索服务，编写课程搜索接口，调用Elasticsearch的rest接口根据关键字、课程分类等信息进行搜索。
如何保证索引同步？
我们项目是使用本地任务表加xxl-job任务调度进行索引同步，具体的作法如下：
1）添加或修改或删除课程的同时向任务表插入一条记录，这条记录就记录了是添加还是修改还是删除了哪个课程。
2）任务调度定时扫描任务表，根据任务表的内容对课程信息进行同步，如果添加了课程将课程添加到索引库，如果修改了课程就修改索引库的课程，如果是删除了课程将课程信息从索引库删除。
关于索引同步的技术还可以使用Logstash和Canal去实现。



**4.6 面试**

**未支付订单如何处理？**

基于RabbitMQ延迟队列处理未支付订单

1）创建订单的同时向MQ发送一条消息给一个队列并设置消息的TTL（过期时间），比如：设置30分钟，由于该队列设置了死信交换机，30分钟后消息将投递到死信交换机。

2）当消息过期，消息发到了死信交换机，同时发给了死信队列（死信队列绑定了死信交换机）

3）程序监听了死信队列，收到了过期的订单。

4）程序收到消息判断如果订单未支付则取消订单。如果说已支付不用处理。

**如何保证RabbitMQ的消息可靠性?**

1、设置消息持久化

首先设置交换机支持持久化（定义交换机时设置持久化为true）

其次设置队列支持持久化（定义队列时设置持久化为true）

发送消息时设置消息要持久化

2、消费者收到消息处理完成要确认

设置 消费者确认模式为自动确认 acknowledge-mode=auto ，当程序处理正常没有异常会发送ack，抛出异常则发送nack

也可以设置为手动确认，在程序处理完成的代码处手动发送ack。

3、消费失败重试

消费失败后在消费者本地进行重试，达到最大重试次数会将失败消息投递到指定交换机，交换机绑定一个异常消息队列，程序监听这个队列收到异常消息后放在数据库中单独处理，或由人工处理。

**如何避免消息重复消费？**

重复投递的原因：等待超时后需要重试。

避免重复投递：消息生产时，生产者发送的消息携带一个`Message ID`（全局唯一ID），

作为去重和幂等的依据，避免重复的消息进入队列

重复消费的原因：消费者接收消息后，在确认之前断开了连接或者取消订阅，

消息会被重新分发给下一个订阅的消费者。

避免重复消费：消息消费时，要求消息体中必须要有一个全局唯一ID，作为去重和幂等的依据，避免同一条消息被重复消费。



**4.5 面试**

**项目使用redis缓存了哪些数据?**

redis缓存的是白名单接口（无需认证即可访问）所需要的数据，缓存了普通用户所要查询的数据（我的订单、我的选课），缓存热点数据（最新发布的课程信息、推荐课程信息等）。

每类信息有不同的缓存过期时间，为了避免缓存雪崩缓存时间加了随机数。

验证码  

30秒    字符串

课程发布信息

7天   hash

课程视频信息

7天   hash

我的课程

3分钟   hash

我的订单

3分钟   hash

**如何保证Redis缓存一致性？**

缓存一致性是数据库和缓存保持一致，当修改了数据库的信息缓存的数据也要同时更新和数据库保持一致。

去查询数据时先查询缓存，如果缓存有就返回，如果没有就查询数据库，如果查不到则缓存一个null字符串（过期时间设置的小一些），如果查询到了，缓存到redis具体的信息。
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202304042205376.png)


当修改数据时常用的方案：

![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202304042205210.png)


1、先删除缓存，再更新数据库

如果删除了缓存更新数据库的操作没有成功，此时查询数据的请求会把旧数据存储到缓存中。

2、先更新数据库，再删除缓存。

如果更新了数据库，删除缓存的操作失败了，此时查询数据的请求查到的数据仍然是旧数据。

3、延迟双删，先删除缓存、再更新数据库，再延迟一定的时间去删除缓存。

为什么要两次删除缓存，因为有可能第一次删除缓存后其它查询请求将旧数据存储到了缓存。

为什么要延迟一定的时间去删除缓存，为了给mysql主向从同步的时间，如果立即删除缓存很可能其它请求读到的数据还是旧数据。

延迟的时间不好确定，延迟双删仍然可能导致脏数据。

所以结论：以上方案当存在高并发时都无法解决数据库和缓存强一致性的问题。

如何做缓存一致性？

需要根据需求来定：

1、实现强一致性 需要使用分布式锁控制，修改数据和向缓存存储数据使用同一个分布式锁。

2、实现最终一致性，缓存数据要加过期时间，即使出现数据不致性当过期时间一到缓存失效又会从数据库查询最新的数据存入缓存。

3、对于实时性要求强的，要实现数据强一致性要尽量避免使用缓存，可以直接操作数据库。

使用工具对数据进行同步方案如下：

1、使用任务表加任务调度的方案进行同步。

2、使用Canal基于MySQL的binlog进行同步。

**redis内存回收机制是什么？**

1、过期删除策略

当redis中的key的生命时间到了，不会立即删除，使用下边的过期删除策略进行删除

定时删除：一个key设置一个定时器去，当key过期就删除，如果key比较多则设置的定时器也比较多，耗费cpu，或者一次随机扫描多个过期的key进行删除。

惰性删除：当去get查询key时如果过期再删除，优点是节省cpu但是浪费内存，因为如果一直不get则过期key将一直存在。

2、内存淘汰策略

两种算法：

LRU 全称为：Least Recently Used。即：最近最长时间未被使用。这个主要针对的是使用时间。

LFU 全称为：Least Frequently Used。即：最近最少频率使用，这个主要针对的是使用频率。
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202304042205326.png)


设置方法
```
Plain Text  
获取当前内存淘汰策略：  
127.0.0.1:6379> config get maxmemory-policy  
通过配置文件设置淘汰策略（修改redis.conf文件）  
maxmemory-policy allkeys-lru  
  
通过命令修改淘汰策略：  
127.0.0.1:6379> config set maxmemory-policy allkeys-lru
```

配置maxmemory_samples选取固定数目的key，然后比较它们的lru访问时间，然后淘汰最近最久没有访问的key

样本的范围大小决定了性能，

• 范围越大：越精确，性能越差；

• 范围越小：越不精确，性能越好。

maxmemory-samples 5 # 保持默认

**面对高并发是如何对缓存进行处理的**

首先使用redis集群。

其次使用分布式锁进行控制避免缓存击穿，通过分布式锁控制只有一个线程去查询数据库，查完数据库后存入缓存。

我们使用redisson实现分布锁。

redisson实现Lock接口，基于此接口使用，具体方法是获取锁调用lock()方法，用完释放锁调用unlock()。

当线程还没有执行完时会有看门狗对锁进行续期，保证线程在执行过程中不会让锁过期。

缓存雪崩问题。

缓存穿透问题。

缓存一致性问题。