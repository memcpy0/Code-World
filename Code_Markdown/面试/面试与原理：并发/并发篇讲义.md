 
 
## 3. wait vs sleep
**要求**
* 能够说出二者区别

**一个共同点，三个不同点**
共同点
* wait() ，wait(long) 和 sleep(long) 的效果都是**让当前线程暂时放弃 CPU 的使用权，进入阻塞状态**

不同点
* 方法归属不同
  * sleep(long) 是 **Thread 的静态方法**
  * 而 wait()，wait(long) 都是 **Object 的成员方法，每个对象都有**
* 醒来时机不同
  * 执行 sleep(long) 和 wait(long) 的线程都会在**等待相应毫秒后醒来**
  * wait(long) 和 wait() **还可以被 notify 唤醒**，wait() 如果不唤醒就一直等下去
  * **它们都可以被打断唤醒**（并没有睡足五秒，就被打断了）
  ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241240346.png)

* 锁特性不同（重点）
  * **wait 方法的调用必须先获取 wait 对象的锁**，而 sleep 则无此限制
  * **wait 方法执行后会释放对象锁**，允许其它线程获得该对象锁（我放弃 cpu，但你们还可以用）
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241238743.png)
  * 而 **sleep 如果在 synchronized 代码块中执行，并不会释放对象锁**（我放弃 cpu，你们也用不了）	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241237369.png)

---
## 4. lock vs synchronized
**要求**
* 掌握 lock 与 synchronized 的区别
* 理解 ReentrantLock 的公平、非公平锁
* 理解 ReentrantLock 中的条件变量

synchronized的wait/notify只对应一个条件变量、一个等待队列
**三个层面**
不同点
* 语法层面
  * **synchronized 是关键字，源码在 jvm 中，用 c++ 语言实现**
  * **Lock 是接口，源码由 jdk 提供，用 java 语言实现**
  * 使用 synchronized 时，**退出同步代码块锁会自动释放**，而使用 Lock 时，需要**手动调用 unlock 方法释放锁**（在finally方法中调用unlock释放锁）
* 功能层面
  * 二者均属于悲观锁、都具备基本的互斥（只有一个线程能获得锁）、同步（多个线程同时运行，一个线程运行到某个状态需要其他线程的结果，就需要等待，synchron用wait/notify，Lock锁用条件变量的await方法）、**锁重入**（持锁线程能否重复加锁）功能
  * **Lock 提供了许多 synchronized 不具备的功能**，例如获取等待状态（知道哪些线程被阻塞了）、公平锁（既支持非公平也支持公平）、可打断、可超时、多条件变量（多个等待队列意思就是按照条件来划分等待锁的线程）
  * Lock 是个接口，有适合不同场景的实现，如 ReentrantLock， ReentrantReadWriteLock
* 性能层面
  * 在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖
  * 在竞争激烈时，Lock 的实现通常会提供更好的性能

**公平锁**
* 公平锁的公平体现
  * ==**已经处在阻塞队列**中的线程（不考虑超时）始终都是公平的，先进先出==
  * 公平锁是指**未处于阻塞队列**中的线程来争抢锁，如果队列不为空，则老实到队尾等待
  * 非公平锁是指**未处于阻塞队列**中的线程来争抢锁，与队列头唤醒的线程去竞争，谁抢到算谁的
* 公平锁会降低吞吐量，一般不用

**条件变量**
* ReentrantLock 中的条件变量功能类似于普通 synchronized 的 wait，notify，用在当线程获得锁后，发现条件不满足时，临时等待的链表结构
* 与 synchronized 的等待集合不同之处在于，**ReentrantLock 中的条件变量可以有多个，可以实现更精细的等待、唤醒控制**

> ***代码说明***
> * day02.TestReentrantLock 用较为形象的方式演示 ReentrantLock 的内部结构

![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241300209.png)

blocking queue底层是双向链表，waiting queue底层是单向链表，对应条件变量：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241311980.png)
0是占位结点，不是线程：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241312488.png)

现在t2线程持有锁，它又加了一把锁，state变为2，解锁得解两道：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241314650.png)
现在持锁的是t3：state 1 -> state 0 -> state 1（按照入队顺序一个个唤醒阻塞线程）
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241316776.png)

ReentryLock非公平性演示：为了预料线程顺序，都先Sleep；线程代码都一样：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241318067.png)
如果t1,t2,t3都跑完了，才有其他线程获得锁，说明它是公平的，遵从了先进先出的公平规则：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241419314.png)

下面一看，不是t2先获得了锁：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241420535.png)
把MyReentrantLock(true)改为false：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241421501.png)

![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241425450.png)

### 条件变量演示
TestReentrantLock：先是t1持有锁，然后调用c1.await（要进入c1的队列里去）：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241428345.png)

现在t1进入了c1的等待队列，锁释放开了，阻塞队列里的t2持有锁：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241429127.png)
要唤醒t1，可调用c1.signal，t1从c1进入到阻塞队列尾部，因为owner(t2)占用着锁，且还有t3,t4等待：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241431219.png)

如果t2发现自己需要等待，则调用c2.await()：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241432722.png)
...
现在调用c2.signalAll按顺序唤醒等待队列c2的所有线程：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241438544.png)
结果如下：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241439104.png)


---
## 5. volatile
**要求**
* 掌握线程安全要考虑的三个问题
* 掌握 volatile 能解决哪些问题

面试题：volatile能否保证线程安全？线程安全有几个方面：
- 原子性，可见性，有序性
- 可见性：**一个线程对共享变量修改，另一个线程能看到最新的结果**
- 有序性：**一个线程内代码按编写顺序执行**
- 原子性：**一个线程内多行代码以一个整体运行，期间不能有其他线程代码插队**，避免造成意料之外的结果
- volatile能保证共享变量的可见性与有序性，但不能保证原子性

① 原子性举例：balance+=5, balance-=5; ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241459270.png)

![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241501894.png)
多行指令间出现指令交错（一个线程还没执行完，就被切换到其他线程）：不保证原子性的情况下，两个getStatic可能会获得相同的值，都是10，最后写会结果可能是15或者5，下面最后结果是15
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241504629.png)
volatile保证了可见性，就是一个线程修改了这个共享变量的值，另一个线程立马可以知道，即使线程2读取到的是10，也会作废，去内存中重新读取（程序计数器是当前线程私有的xd）==那这样岂不是每次切换线程完成后 都需要重新读值, 但凡重新切换了 就相当于要重新从头运行一次了吗==

解决方法是要么这条指令是原子的，交错了也无所谓，要么把这些指令作为一个整体。保证原子性很多做法：synchronized，Lock，ReentryLock。
Debug时一条代码多条指令还是被认为一条，需要手动模拟多条指令：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241513980.png)
然后手动切换线程（计算完没来得及赋值就切换线程能达到同样的效果）：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241515516.png)
然后切换到thread0，它并没有意识到其他线程将b加了5，这里还是对10进行减5，因此结果是5
> 但这里还是用volatile修饰balance了？为什么还是错误？——**volatile只是让每个线程读取其修饰的公共变量时，保证它是最新的**，但这里t0已经读取了balance=10，所以不是可见性问题。每个线程的内部的内存空间是独立的。volatile，保证可见性的前提是内存地址变化？

② 可见性举例：0.1秒后另一线程0将stop改为true，让主线程的循环结束：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241519228.png)
现在没有停止。整个程序不断循环。
> ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241525010.png)
> JMM规定==每个线程不能直接操作主存的值，必须复制到他们自己的本地去操作然后刷新回到主存== 每个线程的缓存是私有的，其他线程不可见，其实就是**因为他们一直拿到的就是拷贝到本地的，他们认为没有必要重新读取**
> 
> 那在上面的基础上，晚一点，用另一个线程读取共享变量：
> ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241529324.png)
> 这说明**线程0改为true以后，把值同步到了内存**，不然线程1无法读到1。于是上面那张CSDN的图的说法有问题，**CPU1修改了某个变量会刷新回主存，已修改的值不只存在于副本中**！CPU0还是读不到变量值？
> 
> 应该这样来说，==是会刷新到主存中去的，但是另一个线程并不会将主存中的变量最新值读取到自己的工作内存中，还是用的以前保存的值==，而~~volatile可以强制使其他线程的本地变量失效而去重新读取、强制线程将主存中的值刷新至工作线程中，volatile修改数据相当于volatile写线程向某个读线程发送了修改共享变量的信息~~
> 
> CPU0执行线程代码！CPU0不断从物理内存读取stop，都是同样的一个false
> ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241706442.png)
> 而JIT看不下去了（它负责代码的优化，包括缓存热点代码，不会一直解释执行字节码，这里由于循环次数过多超出JIT阈值，它就要优化，减少CPU到内存的读取操作。于是做了一个大胆的优化），假定其读到的就是false，并将原来的字节码替换成了编译后的机器码并缓存起来：在修改为true的时间前已经运行几十万次，期间也频繁的访问物理内存，jit为了提高效率就将代码固化，不再去访问内存
> ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241708564.png)
> 其他线程没被优化，就能读到！
> 证明：-Xint 虚拟机参数，只用解释执行的字节码：
> ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241709296.png)
> ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241710949.png)
> 或者去掉-Xint、sleep更短时间、从而减少循环次数！因为没等循环多少次，新建的线程就修改掉了stop的值，从而使得主线程退出了循环
>  ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241713857.png)
> 但最好的优化是用volatile修饰stop，JIT发现变量用volatile修饰了，就算到了循环阈值、我也不优化了！（禁用JIT就能可见是因为缓存一致性协议？）摆烂volatile：有序性：我就这顺序执行，你爱咋咋地。可见性：你可别管我咧，我慢慢来哎，不着急

③ 有序性举例：用jcstress-core多线程压测！@Actor修饰的方法会反复创建线程来执行！actor1先执行、actor2后执行，就是1,1 ；x,y初始值都是0，因此还可能都是0,0；或者多线程下线程切换、指令交错，先x=1; r.r1 = y; r.r2 = x; y = 1; --> 0, 1；
还可能多线程下重排：y=1; r.r1 = y; r.r2 = x; x = 1 --> 也会是 1, 0 ；如果 r.r2 = x; x = 1; y = 1; r.r1 = y; ---> 1, 0
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241720975.png)
最终结果：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241728210.png)

下面用volatile修饰y变量：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241729016.png)
现在每秒吞吐量下降了！结果没有错误！说明没有指令重排！没有出现1,0！
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241730887.png)
在x上volatile修饰，不能组织指令重排！
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241733575.png)


**原子性**
* 起因：多线程下，不同线程的**指令发生了交错**导致的共享变量的读写混乱
* 解决：用悲观锁或乐观锁解决，**volatile 并不能解决原子性**

**可见性**
* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致的对共享变量所做的修改，另外的线程看不到
* 解决：**用 volatile 修饰共享变量，能够防止编译器等优化发生**，让一个线程对共享变量的修改对另一个线程可见

**有序性**
* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**，导致指令的实际执行顺序与编写顺序不一致
* 解决：用 volatile 修饰共享变量会在读、写共享变量时加入不同的屏障，阻止其他读写操作越过屏障，从而达到阻止重排序的效果
* 注意：
  * **volatile 变量写**加的屏障，是阻止上方其它写操作越过屏障排到 **volatile 变量写**之下
  * **volatile 变量读**加的屏障，是阻止下方其它读操作越过屏障排到 **volatile 变量读**之上
  * ==volatile 读写加入的屏障，只能防止同一线程内的指令重排==
  * 写屏障是在volitile修饰的变量前加，防止屏障前的代码跑到变量后面去，读屏障是在volitile修饰的变量后加，防止屏障前面的代码跑到变量后面去
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241737365.png)
	加在x上就是：
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241739821.png)
	写volatile变量一定要放在最后写，读变量一定要放在最前读，不然无法解决可见性！
	
> ***代码说明***
> * day02.threadsafe.AddAndSubtract 演示原子性
> * day02.threadsafe.ForeverLoop 演示可见性
>   * 注意：本例经实践检验是编译器优化导致的可见性问题
> * day02.threadsafe.Reordering 演示有序性
>   * 需要打成 jar 包后测试
> * 请同时参考视频讲解

---
## 6. 悲观锁 vs 乐观锁
**要求**
* 掌握悲观锁和乐观锁的区别

**对比悲观锁与乐观锁**
* 悲观锁的代表是 synchronized 和 Lock 锁
  * 其核心思想是【==线程只有占有了锁，才能去操作共享变量，每次只有一个线程占锁成功，获取锁失败的线程，都得停下来等待==】
  * 线程从运行到阻塞（把线程当前运行状态记录下来）、再从阻塞到唤醒（再把线程运行状态恢复，这就是线程上下文切换！），涉及**线程上下文切换**，如果频繁发生，影响性能
  * 实际上，线程在获取 synchronized 和 Lock 锁时，**如果锁已被占用，都会做几次重试操作，减少阻塞的机会**

* 乐观锁的代表是 AtomicInteger，使用 cas 来保证原子性
  * 其核心思想是【==无需加锁，每次只有一个线程能成功修改共享变量，其它失败的线程不需要停止，不断重试直至成功==】不怕失败的乐观精神！
  * **由于线程一直运行，不需要阻塞，因此不涉及线程上下文切换**
  * 它需要多核 cpu 支持（修改失败的线程不停止，就得有CPU来执行），且线程数不应超过 cpu 核数

> ***代码说明***
> * day02.SyncVsCas 演示了分别使用乐观锁和悲观锁解决原子赋值
> * 请同时参考视频讲解

修改前，将共享变量的旧值 `o = account.balance` 与共享变量的值比较，如果没变说明没有其他线程修改；否则说明有其他线程修改了，这里的修改就会失败！
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241812789.png)
由于没有别的线程，返回true，打印的account.balance=15。假设用Debug模拟另一个线程来修改：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241813574.png)
这次修改就失败了：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241814933.png)

为了保证修改成功，我反复读取account.balance，并CAS看能否修改成功，能则break，不能则继续读取account.balance的新值，再进行修改并CAS
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241816722.png)

原子性那集是因为多线程造成了指令交错问题，也就是线程不安全。说的可以用乐观锁或悲观锁解决。这集讲的就是乐观锁的原理。

悲观锁解决多线程下指令交错问题，互斥方式让修饰的一段代码成为一个整体：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241820579.png)

> 别再说自旋了，这跟自旋一毛关系没有，想了解自旋的去看这个老师的另一个专门讲并发编程的视频

乐观锁解决指令交错问题：线程2先执行完加5，没有其他线程干扰，操作成功；线程1之前读了10，在10的基础上减5，但旧值10与现在balance的新值15不等，它就识别出有其他线程修改了balance，那就执行下次读取-Compare-Set：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241830152.png)
注意，这里的加、减无影响，但乘除有优先级问题！

---
## 7. Hashtable vs ConcurrentHashMap
**要求**
* 掌握 Hashtable 与 ConcurrentHashMap 的区别
* 掌握 ConcurrentHashMap 在不同版本的实现区别

> 更形象的演示，见资料中的 hash-demo.jar，运行需要 jdk14 以上环境，进入 jar 包目录，执行下面命令
>
> ```
> java -jar --add-exports java.base/jdk.internal.misc=ALL-UNNAMED hash-demo.jar
> ```

**Hashtable 对比 ConcurrentHashMap**
* Hashtable 与 ConcurrentHashMap 都是**线程安全的 Map 集合**
* Hashtable 并发度低，**整个 Hashtable 对应一把锁，同一时刻，只能有一个线程操作它**
* ConcurrentHashMap 并发度高，**整个 ConcurrentHashMap 对应多把锁，只要线程访问的是不同锁，那么不会冲突**
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241836949.png)

hashtable：扩容（原容量x2+1）；容量一般都是质数，hashcode的计算不需要经过2次hash！
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241902836.png)

**ConcurrentHashMap 1.7**
容量除以并发度clevel，就是小数组的容量：
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241905473.png)
* 数据结构：`Segment(大数组) + HashEntry(小数组) + 链表`，**每个 Segment 对应一把锁，如果多个线程访问不同的 Segment，则不会冲突**
* 并发度：Segment 数组大小即并发度，决定了同一时刻最多能有多少个线程并发访问。**Segment 数组不能扩容**，意味着并发度在 ConcurrentHashMap 创建时就固定了
* 索引计算
	* 假设大数组长度是 $2^m$（就要二次哈希），key 在大数组内的索引是 key 的二次 hash 值的高 m 位
	* 假设**当前小数组**长度是 $2^n$，key 在小数组内的索引是 key 的二次 hash 值的低 n 位
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241908731.png)
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303241930896.png)

* 扩容：每个小数组的扩容相对独立，**小数组在超过扩容因子时会触发扩容**，每次扩容翻倍
* `Segment[0]` 原型：（饿汉式，初始化方法一调用，Segment数组和 `Segment[0]` 就被创建了），Segment数组创建时，唯独 `Segment[0]` 中创建了小数组。**首次创建其它小数组时，会以此原型为依据，数组长度，扩容因子都会以原型为准**
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242002185.png)

**ConcurrentHashMap 1.8**
* 数据结构：`Node 数组 + 链表或红黑树`，**数组的每个头节点作为锁，如果多个线程访问的头节点不同，则不会冲突**。==首次生成头节点时如果发生竞争，利用 cas 而非 syncronized，进一步提升性能==
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242047009.png)
* 并发度：**Node 数组有多大，并发度就有多大**，与 1.7 不同，**Node 数组可以扩容**
* 扩容条件：**Node 数组满 3/4 时就会扩容**（不仅是超过）下面再添加一个d，就会触发扩容
	**& (capacity – 1) 得到索引** 97 % 16 = 97 % (16-1) 如果链表长度超过 1，则需要对节点进行复制（创建新节点），怕的是节点迁移后 next 指针改变
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242029241.png)
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242135952.png)
* **与 1.7 相比是懒惰初始化**
* capacity 代表预估的元素个数，capacity / factor 来计算出**初始数组大小**（这里的capacity一开始是预计要放进去的元素个数，数组长度看着办，但数组长16不能放下，就要翻倍，32x3/4=24，16没有超过24可以放下；==2^n* factor > capacity，求n==），需要贴近 $2^n$ （下面数组长度必须到32才能符合factor）
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242032474.png)
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242033890.png)
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242038653.png)
* **loadFactor 扩容因子只在计算初始数组大小时被使用，之后扩容固定为 3/4**
* 扩容单位：**以链表为单位、从后向前迁移链表**，迁移完成的、将旧数组头节点替换为 ForwardingNode
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242134483.png)

* 扩容时并发 get（根本不会阻塞）
	* 根据是否为 ForwardingNode 来决定是在新数组查找**还是在旧数组查找**，**不会阻塞**
	* 迁移的过程中要重新计算索引。**如果链表长度超过 1，则需要对节点进行复制（创建新节点），怕的是节点迁移后 next 指针改变**。下面扩容时很多情况都要重新创建链表，对里面的元素重新创建。
	  如下面，查找2，由于不是ForwardingNode，就要在旧数组中找这个2，那前面这个结点1和前后的结点1能是同一个结点吗？因为新来查询的线程要查询这个数据，1的下面是2才能找到，迁移过程中1的next可能会改变，例子中1的next已经改变为了null。如果上下两个1是相同的对象，查找的线程找到1后能找到2吗，找不到了。
	 ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242226543.png)
	* 链表里节点的迁移顺序是从后往前。如果链表最后几个元素扩容后索引不变，则节点无需复制（意思**node的下个节点不变，就不创建新node**），如5,6就不必创建新node，1,2,3,4都得创建新结点。
* 扩容时并发 put
	* ==**如果 put 的线程与扩容线程（加锁！）操作的链表是同一个（即看是否是同一个数组头结点），put 线程会阻塞**==（如数组结点10）
	* 如果 put 的线程操作的链表**还未迁移**，即头节点不是 ForwardingNode，则可以并发执行（如前面的1,2,3,4,5数组结点）
	* 如果 put 的线程操作的链表**已经迁移完成**，即头结点是 ForwardingNode，则可以**协助扩容**（这种情况下不能去新的表中put，新的表得等到全部迁移完成后才能put，但不会闲着；每个线程一次可迁移16个链表，比如扩容线程先迁移0-16这些链表，新来的put线程）
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242241678.png)

* 超过树化阈值时的扩容问题，**如果容量已经是 64，直接树化**，否则在原来容量基础上做 3 轮扩容

---
## 8. ThreadLocal
**要求**
* 掌握 ThreadLocal 的作用与原理
* 掌握 ThreadLocal 的内存释放时机

**作用**
* **ThreadLocal 可以实现【资源对象】的线程隔离，让每个线程各用各的【资源对象】，避免争用引发的线程安全问题**
* ThreadLocal 同时实现了**线程内的资源共享**（只要是同一个线程）

> 和Session的使用场景差不多, 只不过Session是在前端与后端之间传值, 而ThreadLocal是在后端的各个地方之间传值

![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242256720.png)

**原理**
==每个线程都对应一个JVM虚拟机栈，内有一个 ThreadLocalMap 类型的成员变量，用来存储资源对象，本质就是一个Map用ThreadLocal对象作为KEY==
* 调用 set 方法，就是以 ThreadLocal 自己作为 key，资源对象作为 value，放入当前线程的 ThreadLocalMap 集合中
* 调用 get 方法，就是以 ThreadLocal 自己作为 key，到当前线程中查找关联的资源值
* 调用 remove 方法，就是以 ThreadLocal 自己作为 key，移除当前线程关联的资源值

![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303242305060.png)

![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303250009684.png)

ThreadLocalMap 的一些特点
* key 的 hash 值统一分配
* **初始容量 16，扩容因子 2/3，扩容容量翻倍**，并重新计算索引
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303250010690.png)
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303250011349.png)
* key 索引冲突后用开放寻址法解决冲突（其他的HashMap，ConcurrentHashMap，HashTable拉链法）

**弱引用 key**
ThreadLocalMap 中的 **key 被设计为弱引用**，原因如下
* Thread 可能需要长时间运行（如线程池中的线程），**如果 key 不再使用，需要在内存不足（GC）时释放其占用的内存**，于是key就变成了null（引用关系：强软弱虚：遇强则软遇弱则虚（谦虚））
	![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202303250017600.png)

**内存释放时机**
* 被动 GC 释放 key
	* **仅是让 key 的内存释放，关联的 value 的内存和entry的内存并不会释放**
* 懒惰被动释放 value
	* get key 时，**发现是 null key，则释放其 value 内存**
	* set key 时，**会使用启发式扫描，清除临近的 null key 的 value 内存**，启发次数与元素个数，是否发现 null key 有关（之所以这样做是因为开放寻址可能导致想找的key在后面，所以碰到null要往后看？）
* 主动 remove 释放 key，value
  * **会同时释放 key，value 的内存**（？这里只是把引用断了，具体值回不回收还得看有没有被别的地方引用吧？如果别的地方强引用了value呢？），也会**清除临近的 null key 的 value 内存**
  * 推荐使用它，因为==一般使用 ThreadLocal 时都把它作为静态变量（即强引用），因此无法被动依靠 GC 回收==（因为它根本不可能是null key；应该指的是threadlocal不会被回收，但是key还是会被回收的）（ThreadLocal在Map中是弱引用）
