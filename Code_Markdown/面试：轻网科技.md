这个问题的答案比较复杂。个人体会来说，C++和Java有各自的优势和劣势，取决于编写代码的方式、用途、计时规则等多方面的因素。在LeetCode上面做题时就经常能发现，Java实现的代码经常能到0ms，而C++同样逻辑实现的代码却比不过。一方面可能是LeetCode给不同语言设置的测试数据不同，一方面可能是LeetCode给Java和C++计时的规则不同。

一般来说，C++代码执行更快，因为它是一种编译型的语言，可以直接编译为机器语言，而不需要像Java那样先编译为字节码、再通过类加载子系统加载字节码到运行时数据区、再使用执行引擎中的解释器进行解释 和执行。C++还提供了对指针和内存的直接控制，因此在大量数据的处理和高性能计算上非常优秀；C++还提供了更好的硬件控制，可以更好地利用计算机的硬件，提升执行速度。

但是Java也有自己的优势，Java目前在Hotspot等虚拟机的实现中，采用了JIT即时编译器，能将热点代码编译为机器语言，直接执行，因此Java在完成JVM的启动和预热（这需要一段不短的时间）后，能在许多热点代码的执行性能上媲美C++的速度。而且，Java还提供了很多高级特性，如内存管理和自动垃圾回收等，垃圾回收带来的STW，会暂停所有线程，也是降低执行速度的一个地方，但Java现在默认采用的G1垃圾回收器，将STW带来的影响降到很低。

当然，代码速度的优化个人感觉是永无止境的。C++还可以直接嵌套C、甚至内嵌汇编代码来提高执行速度，更厉害的还可以上SIMD优化，并行处理提高速度。Java也可以编写本地方法，通过使用C和C++来提高速度。

总体来说，目前Java的执行速度是不如C++的，但Java在很多方面进行了改善，性能也得到了不小的提升。

22

true
false
false
true

Java中，对象在内存中的位置通常分为新生代和老年代，新生代又分为Eden区和两个Survivor区from，to。当一个对象被分配在Eden区时，如果Eden区的空间不足，就会触发Minor GC，将Eden区（以及from区）没有被引用的对象清除，并将还被引用的对象移到to区中，增加存活对象的年龄，并交换Survivor from和Survivor to的名称。

因此一个对象会出现在老年代中，可能是：
1. 对象大小超出了Eden区可用大小，就被直接分配在老年代中；
2. 对象在Eden区中经历了多次Minor GC后，仍然存活并被移动到Survivor区中。当这些对象的存活时间超过一定限制，就会晋升到老年代中。
3. 大对象会被直接分配在老年代中，比如开辟的大数组等。

首先需要指出的是，本题代码中有一些错误，比如executor.submit(() -> {})后面要加分号，而且try-catch后面的System.out.println(Thread.currentThread().getName() + ":" + i);中的i是从lambda表达式中引用的本地变量，必须是最终变量，或实际上的最终变量。

修改以后，运行发现（多线程输出的结果是变化的）：
thread-1，thread-2，thread-3，thread-4，thread-5这五个线程分别在 : 号后输出了0到8的数字。然后触发了异常RejectedExecutionException。下面是可能的结果之一：


为什么会有这种输出？其实原因是，核心线程数为2，最大线程数是5，阻塞队列大小为4，一开始进入的两个任务看到核心线程数没满，就创建核心线程来执行任务。后面进来的4个任务发现核心线程满了，就进入阻塞队列。再进来的任务，会发现核心线程满了、阻塞队列也满了，但最大线程数没满，就创建救急线程来执行阻塞队列中的任务。这样，五个线程（2个核心线程和3个救急线程）能执行五个任务，阻塞队列中最多放4个任务，最后一个任务进来时发现最大核心线程数、阻塞队列、最大线程数都满了，就触发了拒绝策略，默认的拒绝策略是 AbortPolicy，会抛出一个RejectedExecutionException。


为了应对突发的高峰流量和恶意攻击，一般在项目的QPS比较高时需要采用限流算法。常规来说，会先进行压测，检测平时系统可以承受的最大QPS，在此基础上定制限流速率。下面是我知道的限流手段：
① Nginx限流：使用Nginx可以进行限流。其中可以用漏桶算法控制请求速率，以固定速率处理请求；还可控制并发连接的数目，限制每个IP能发起的连接数。
② 还可使用网关限流，如在Spring Cloud Gateway中使用令牌桶算法来进行过滤。
不难发现这些手段都用到了一些算法，下面是我知道的限流算法：
① 漏桶算法：这是一个基于队列实现的算法，它将来的请求放入一个固定容量的队列（作为桶）中，每个请求会以固定的速率出队并被处理，未被处理的请求则会被抛弃。漏桶算法的优点是可以平滑处理请求，保持较为稳定的流量，缺点是应对突发流量可能造成请求被拒绝；适用于可以稳定预估请求量、但要保持平滑响应时间的场景。
② 令牌桶算法：一种基于令牌的算法，每次请求的处理都要消耗一个令牌。令牌桶以固定速率生成令牌，当令牌桶为空时则无法处理请求。它的优点是，可以应对一定的突发流量，但实现较为复杂，响应时间会有一定波动。
③ 固定窗口算法：简单的限流算法，将时间分为若干个固定的窗口，每个时间窗口内最多只能有一定数量的请求通过。它的优点是简单易懂，实现容易；缺点是难以应对突发流量，可能导致短时间内过多请求被拒绝。
④ 滑动窗口算法：改进的固定窗口，比固定窗口算法更加灵活，能够应对突发流量，但实现较为复杂，适用于对请求量有较为稳定的预估但对响应时间要求较高的情景。


① 使用的数据库连接池是HikariPool，一个高性能的数据库连接池，是SpringBoot默认的连接池。
② daemon，prio分别指定了是否守护线程，线程优先级。tid和nid分别说明了是线程ID和本地线程ID，通过tid可以查找和分析Java虚拟机中线程的堆栈信息，通过nid可以分析和查找线程的系统信息，如CPU占用率和内存使用等。
③ waiting on condition说明在等待状态，而且是TIMED_WAITING
④ 下面是报错的栈帧。错误是从线程的run方法中爆出的，然后是线程池的Worker.run、runWorker（使用worker执行任务），getTask（获取任务），再是可调度的线程池ScheduledThreadPoolExecutor使用的DelayedWorkQueue（可以延时处理任务）的take阻塞方法
⑤ 最后是抽象队列同步器框架中的 ConditionObject 。
其他的暂时看不出来。


幂等性就是多次调用方法或接口，不会改变业务状态，保证重复调用的结果与单次调用的结果一致，常见于分布式服务的接口设计。

在设计RESTful API时，常用的HTTP Method有几种：
1. GET：用于获取资源的信息，不会对资源进行修改或删除，是幂等的。
2. POST：用于创建资源，可能会对资源进行修改或删除。不是幂等的。
3. PUT：用于更新资源。如果用来新增数据，是幂等的。
4. DELETE：用于删除资源，是幂等的。

常用的HTTP Status Code如下：
1. 200 OK：表示请求成功
2. 201 Created：表示资源创建成功
3. 204 No Content：表示请求成功，但没有返回任何内容。
4. 400 Bad Request：表示请求格式有误，服务器无法解析。
5. 403 Forbidden：表示无权访问资源
6. 404 Not Found：表示请求的资源不存在。
7. 500 Internal Server Error：表示服务器内部错误 


在关系数据库上使用Redis来缓存用户信息是很常见的做法，我在个人项目中使用过这种方法。缓存加载策略：
1. 系统启动时，先在数据库中保存用户信息，等用户登录后，就从数据库中查询用户信息，并缓存到Redis中。
2. 用户在不同页面间跳转时，都需要显示用户信息，此时就会从Redis缓存中加载该用户的信息；如果缓存中不存在了，就再从数据库中加载。
3. 当Redis缓存中的用户信息被清空或过期后，还是要重新加载最新的用户信息。
4. 为了避免缓存穿透，在缓存加载时，可以使用布隆过滤器，先查询对应ID是否存在，存在则访问Redis甚至访问数据库，否则就不让其访问，避免使用不存在的ID来攻击。
5. 为了避免缓存击穿，在缓存加载时，一方面可以对不同的用户信息设置基础的过期时间+随机时间，避免这些热点信息同时过期；还可以设置定时任务，定时更新用户信息的过期时间或定时重新加载用户信息；还可组合多级缓存，提高查询速率。
6. 为了避免缓存雪崩，可以使用Redis的集群模式，以及给缓存业务添加降低和限流策略。

这样一来，在缓存加载上的考虑就比较全面了。

在更新缓存时：
1. 用户修改了自己的信息时，就需要更新Redis中缓存的用户信息，以保证缓存中的数据与数据库中的数据一致。
2. 如果一致性的要求较高，可以先删除缓存中的信息，再修改数据库，然后延时（给Redis主从复制的时间）再删除一次缓存，避免脏数据的出现；但延时难以确定，可改为使用Redis提供的分布式锁，避免多个更新操作同时进行造成的数据不一致。
3. 如果一致性的要求较低，可以使用MQ中间件，将更新消息放入消息队列中，由后台任务异步执行，更新数据后删除缓存。或者利用Canal中间件，作为MySQL的一个从节点，通过监听binlog数据来更新缓存，不用修改业务代码。

通过合理的缓存加载和更新策略，以及缓存过期策略（这里的淘汰策略可以使用volatile_lfu，这种短时高频访问的场景比较适合），可以有效提高系统的响应速度和并发能力，减少关系数据库的负载压力，提高系统的性能和可靠性。我个人使用JMeter做过压力测试，合理使用Redis+多级缓存，可以提高10倍左右的处理能力。