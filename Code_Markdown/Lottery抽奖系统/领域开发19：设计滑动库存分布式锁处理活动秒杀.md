-   分支：[211120_xfg_redis](https://gitcode.net/KnowledgePlanet/Lottery/-/tree/211120_xfg_redis)
-   描述：引入 Redis 到抽奖系统，设计颗粒度更细的滑动库存编号分布式锁，处理活动秒杀流程

## 一、开发日志

-   由于本章节需要用到 Redis 所以我们在云服务器搭建 Redis 服务，这样可以更加方便的使用。_如果你暂时还没有云服务器，那么在本地搭建 Redis 也可以，只是少了一些云环境的配置练习_ [云服务器地址](https://www.aliyun.com/minisite/goods?taskPkg=1111ydsrwb&pkgSid=11388&recordId=1033318&userCode=is4kfbdt)
-   在抽奖系统中引入 Redis 模块，**优化用户参与抽奖活动**。因为只要有大量的用户参与抽奖，那么这个就属于秒杀场景。所以需要使用 Redis 分布式锁的方式来处理集中化库存扣减的问题，否则在 TPS 达到1k-2k，就会把数据库拖垮。
-   **在设计秒杀流程时，优化锁的颗粒度力度，不要把锁直接放到活动编号上，这样在极端临界情况下会出现秒杀解锁失败，导致库存有剩余但不能下单的情况**。所以需要增加锁的颗粒度，以滑动库存剩余编号的方式进行加锁，例如 100001_1、100001_2、100001_3，以此类推，具体看代码实现。
-   增加缓存扣减库存后，发送 MQ 消息进行异步更新数据库中活动库存，做最终数据一致性处理。_这一部分如果你的系统并发体量较大，还需要把 MQ 的数据不要直接对库更新，而是更新到缓存中，再由任务最阶段同步，以此减少对数据库表的操作_

## 二、扣减流程
-   优化活动领域，**活动参与流程中的库存扣减操作**，这部分我们原来是使用**数据库行级锁**🔐 处理的库存扣减，但因为**会存在并发问题**所以这里优化为 Redis 分布式锁进行处理。
-   活动领取完成后，其实这个时候只是把缓存的库存扣掉了，但数据库中的库存并没有扣减，所以我们需要发送一个 MQ 消息，来对数据库中的库存进行处理。因为 MQ 可以消峰因此在降低 MQ 分片的情况下，消费效率有所下降，并不会对数据库造成压力，保证最终数据一致性即可。_但也有例外，所以我们提到可以使用**定时任务来更新数据库库存**_

## 三、配置Redis云服务环境
-   本章节我们把需要用到的 Redis 配置到云服务上，这样也比较方便我们自己测试使用，否则总是需要在自己机器进行处理。
 
操作步骤：
1.  在宝塔的软件商店中搜索 Redis 进行安装，这个安装过程是傻瓜式的，你也可以使用 Docker 或者直接用命令安装，都不复杂。
2.  安装完毕后需要进行一些必要的配置才能让我们本地访问到 Redis 服务，否则使用时会报错 `Unable to connect to 39.96.*.*:6379`
3.  终端执行，防火墙放行：`firewall-cmd --zone=public --add-port=6379/tcp --permanent`
4.  终端执行，防火墙重启：`firewall-cmd --reload`
5.  **redis.conf **注释掉 `bind 127.0.0.1`
6.  **redis.conf** `protected-mode yes` 改为 `protected-mode no`
7.  现在重启 Redis，这些操作可以直接在我们安装的 Redis 里进行设置。

## [](https://gitcode.net/KnowledgePlanet/Lottery/-/wikis/%E7%AC%AC-2-%E9%83%A8%E5%88%86-%E9%A2%86%E5%9F%9F%E5%BC%80%E5%8F%91//%E7%AC%AC19%E8%8A%82%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%BB%91%E5%8A%A8%E5%BA%93%E5%AD%98%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A4%84%E7%90%86%E6%B4%BB%E5%8A%A8%E7%A7%92%E6%9D%80#%E5%9B%9B%E5%8A%9F%E8%83%BD%E5%BC%80%E5%8F%91)四、功能开发

### [](https://gitcode.net/KnowledgePlanet/Lottery/-/wikis/%E7%AC%AC-2-%E9%83%A8%E5%88%86-%E9%A2%86%E5%9F%9F%E5%BC%80%E5%8F%91//%E7%AC%AC19%E8%8A%82%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%BB%91%E5%8A%A8%E5%BA%93%E5%AD%98%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A4%84%E7%90%86%E6%B4%BB%E5%8A%A8%E7%A7%92%E6%9D%80#1-%E6%BB%91%E5%9D%97%E5%BA%93%E5%AD%98%E9%94%81%E8%AE%BE%E8%AE%A1)1. 滑块库存锁设计

[![](https://gitcode.net/KnowledgePlanet/Lottery/-/raw/master/doc/assets/img/Part-2/19-03.png)](https://gitcode.net/KnowledgePlanet/Lottery/-/raw/master/doc/assets/img/Part-2/19-03.png)

-   如图所示，即使是使用 Redis 分布式锁，我们也不希望把锁的颗粒度放的太粗，否则还是会出现活动有库存但不能秒杀，提示“活动过于火爆”
-   那么我们就需要按照活动编号把库存锁的颗粒度缩小，实际操作也并不复杂，只是把`活动ID+库存扣减后的值`一起作为分布式锁的Key，这样就缩小了锁的颗粒度。

### [](https://gitcode.net/KnowledgePlanet/Lottery/-/wikis/%E7%AC%AC-2-%E9%83%A8%E5%88%86-%E9%A2%86%E5%9F%9F%E5%BC%80%E5%8F%91//%E7%AC%AC19%E8%8A%82%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%BB%91%E5%8A%A8%E5%BA%93%E5%AD%98%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A4%84%E7%90%86%E6%B4%BB%E5%8A%A8%E7%A7%92%E6%9D%80#2-%E6%BB%91%E5%9D%97%E5%BA%93%E5%AD%98%E9%94%81%E5%AE%9E%E7%8E%B0)2. 滑块库存锁实现

在活动领域层的领取活动抽象类 `BaseActivityPartake` 添加方法 subtractionActivityStockByRedis、recoverActivityCacheStockByRedis，分别用户 Redis 库存扣减和加锁 Key 的处理。

#### [](https://gitcode.net/KnowledgePlanet/Lottery/-/wikis/%E7%AC%AC-2-%E9%83%A8%E5%88%86-%E9%A2%86%E5%9F%9F%E5%BC%80%E5%8F%91//%E7%AC%AC19%E8%8A%82%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%BB%91%E5%8A%A8%E5%BA%93%E5%AD%98%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A4%84%E7%90%86%E6%B4%BB%E5%8A%A8%E7%A7%92%E6%9D%80#21-%E5%BA%93%E5%AD%98%E6%89%A3%E5%87%8F%E6%93%8D%E4%BD%9C)2.1 库存扣减操作

**ActivityRepository#subtractionActivityStockByRedis**

```
@Override
public StockResult subtractionActivityStockByRedis(String uId, Long activityId, Integer stockCount) {

    //  1. 获取抽奖活动库存 Key
    String stockKey = Constants.RedisKey.KEY_LOTTERY_ACTIVITY_STOCK_COUNT(activityId);
    
    // 2. 扣减库存，目前占用库存数
    Integer stockUsedCount = (int) redisUtil.incr(stockKey, 1);
    
    // 3. 超出库存判断，进行恢复原始库存
    if (stockUsedCount > stockCount) {
        redisUtil.decr(stockKey, 1);
        return new StockResult(Constants.ResponseCode.UN_ERROR.getCode(), Constants.ResponseCode.UN_ERROR.getInfo());
    }
    
    // 4. 以活动库存占用编号，生成对应加锁Key，细化锁的颗粒度
    String stockTokenKey = Constants.RedisKey.KEY_LOTTERY_ACTIVITY_STOCK_COUNT_TOKEN(activityId, stockUsedCount);
    
    // 5. 使用 Redis.setNx 加一个分布式锁
    boolean lockToken = redisUtil.setNx(stockTokenKey, 350L);
    if (!lockToken) {
        logger.info("抽奖活动{}用户秒杀{}扣减库存，分布式锁失败：{}", activityId, uId, stockTokenKey);
        return new StockResult(Constants.ResponseCode.UN_ERROR.getCode(), Constants.ResponseCode.UN_ERROR.getInfo());
    }
    return new StockResult(Constants.ResponseCode.SUCCESS.getCode(), Constants.ResponseCode.SUCCESS.getInfo(), stockTokenKey, stockCount - stockUsedCount);
}
```
-   代码中的注释就是整个操作流程，创建 Key、占用库存、判断库存、**以占用库存的编号做为加锁key**、调用 setNx 加一个分布式锁，最终完成整个秒杀扣减库存的动作。
-   这里还有一些其他的实现方式，例如：`lua脚本`、zk、jvm层，都可以处理，但经过验证 lua脚本会有一定的耗时，并发较高时会有问题。
-   秒杀的设计原则是保证不超卖，但不一定保证100个库存完全消耗掉，因为可能会有一些锁失败的情况。不过在库存数据最终一致性任务处理下，基本保证`3个9`到`4个9`的可用率还是没问题的。
-   如果说你的库存秒杀tps已经到10级以上，**_一般单key在10万以下是可靠的_，那么这个时候就需要进行库存分片，把路由是思想用到 Redis 使用上，不同的用户进入 Redis 进行秒杀处理时，把他的库存操作路由到属于他的分组上进行处理，那么这样就可以横向扩展了**。

#### [](https://gitcode.net/KnowledgePlanet/Lottery/-/wikis/%E7%AC%AC-2-%E9%83%A8%E5%88%86-%E9%A2%86%E5%9F%9F%E5%BC%80%E5%8F%91//%E7%AC%AC19%E8%8A%82%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%BB%91%E5%8A%A8%E5%BA%93%E5%AD%98%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A4%84%E7%90%86%E6%B4%BB%E5%8A%A8%E7%A7%92%E6%9D%80#22-%E5%B9%B6%E5%8F%91%E9%94%81%E5%88%A0%E9%99%A4%E5%A4%84%E7%90%86)2.2 并发锁删除处理

**ActivityRepository#recoverActivityCacheStockByRedis**

```
@Override
public void recoverActivityCacheStockByRedis(Long activityId, String tokenKey, String code) {
    // 删除分布式锁 Key
    redisUtil.del(tokenKey);
}
```

-   秒杀完毕后，接下来的流程是用户记录落库，但可能这个时候会发生失败的情况，因为需要在失败时恢复缓存的库存。不过这个情况不是事务性的，因此可能会恢复失败，也就是保证不超卖，但不能保证一定完全消耗库存。_当然这个部分具体看你希望的是什么，比如你可以牺牲掉一些性能，考虑 lua 脚本和给整个流程分布式事务锁。_
-   **如果最后的操作是成功的，那么正常删除掉这个加锁的 Key 就可以了，因为下一个用户获取的到的库存滑块又是新的了**，旧 Key 已经没有用了。

### [](https://gitcode.net/KnowledgePlanet/Lottery/-/wikis/%E7%AC%AC-2-%E9%83%A8%E5%88%86-%E9%A2%86%E5%9F%9F%E5%BC%80%E5%8F%91//%E7%AC%AC19%E8%8A%82%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%BB%91%E5%8A%A8%E5%BA%93%E5%AD%98%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A4%84%E7%90%86%E6%B4%BB%E5%8A%A8%E7%A7%92%E6%9D%80#3-%E6%B4%BB%E5%8A%A8%E7%A7%92%E6%9D%80%E6%B5%81%E7%A8%8B%E5%A4%84%E7%90%86)3. 活动秒杀流程处理

**BaseActivityPartake#doPartake**

[![](https://gitcode.net/KnowledgePlanet/Lottery/-/raw/master/doc/assets/img/Part-2/19-04.png)](https://gitcode.net/KnowledgePlanet/Lottery/-/raw/master/doc/assets/img/Part-2/19-04.png)

-   在领取活动的模板方法中，优化掉原来直接使用数据库行级锁的流程，把 Redis 库存的扣减添加到这里。
-   扣减库存后，在各个以下的流程节点中，如果有流程失败则进行缓存库存的恢复操作。

### [](https://gitcode.net/KnowledgePlanet/Lottery/-/wikis/%E7%AC%AC-2-%E9%83%A8%E5%88%86-%E9%A2%86%E5%9F%9F%E5%BC%80%E5%8F%91//%E7%AC%AC19%E8%8A%82%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%BB%91%E5%8A%A8%E5%BA%93%E5%AD%98%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A4%84%E7%90%86%E6%B4%BB%E5%8A%A8%E7%A7%92%E6%9D%80#4-%E5%8F%91%E9%80%81mq%E6%B6%88%E6%81%AF%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7)4. 发送MQ消息，处理数据一致性

由于我们使用 Redis 代替数据库库存，那么在缓存的库存处理后，还需要把数据库中的库存处理为和缓存一致，这样在后续运营这部分数据时才能保证一定的运营可靠性。

**ActivityProcessImpl#doDrawProcess**

[![](https://gitcode.net/KnowledgePlanet/Lottery/-/raw/master/doc/assets/img/Part-2/19-05.png)](https://gitcode.net/KnowledgePlanet/Lottery/-/raw/master/doc/assets/img/Part-2/19-05.png)

-   申请新的 MQ Topic：`bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic lottery_activity_partake`
-   这里需要注意，MQ 的发送，只发生在用户首次领取活动时，如果是已经领取活动但因为抽奖等流程失败，二次进入此流程，则不会发送 MQ 消息。

### [](https://gitcode.net/KnowledgePlanet/Lottery/-/wikis/%E7%AC%AC-2-%E9%83%A8%E5%88%86-%E9%A2%86%E5%9F%9F%E5%BC%80%E5%8F%91//%E7%AC%AC19%E8%8A%82%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%BB%91%E5%8A%A8%E5%BA%93%E5%AD%98%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A4%84%E7%90%86%E6%B4%BB%E5%8A%A8%E7%A7%92%E6%9D%80#5-%E6%B4%BB%E5%8A%A8%E9%A2%86%E5%8F%96%E8%AE%B0%E5%BD%95-mq-%E6%B6%88%E8%B4%B9)5. 活动领取记录 MQ 消费

**LotteryActivityPartakeRecordListener**

```
@KafkaListener(topics = "lottery_activity_partake", groupId = "lottery")
public void onMessage(ConsumerRecord<?, ?> record, Acknowledgment ack, @Header(KafkaHeaders.RECEIVED_TOPIC) String topic) {
    Optional<?> message = Optional.ofNullable(record.value());
    // 1. 判断消息是否存在
    if (!message.isPresent()) {
        return;
    }
    // 2. 转化对象（或者你也可以重写Serializer<T>）
    ActivityPartakeRecordVO activityPartakeRecordVO = JSON.parseObject((String) message.get(), ActivityPartakeRecordVO.class);
    logger.info("消费MQ消息，异步扣减活动库存 message：{}", message.get());
    
    // 3. 更新数据库库存
    activityPartake.updateActivityStock(activityPartakeRecordVO);
}
```

-   消费 MQ 消息的流程就比较简单了，接收到 MQ 进行更新数据库处理即可。不过我们这里更新数据库并不是直接对数据库进行库存扣减操作，而是把从缓存拿到的库存最新镜像更新到数据库中。它的 SQL = `UPDATE activity SET stock_surplus_count = #{stockSurplusCount} WHERE activity_id = #{activityId} AND stock_surplus_count > #{stockSurplusCount}`
-   更新数据库库存【实际场景业务体量较大，可能也会由于MQ消费引起并发，对数据库产生压力，所以如果并发量较大，可以把库存记录缓存中，并使用定时任务进行处理缓存和数据库库存同步，减少对数据库的操作次数】

## [](https://gitcode.net/KnowledgePlanet/Lottery/-/wikis/%E7%AC%AC-2-%E9%83%A8%E5%88%86-%E9%A2%86%E5%9F%9F%E5%BC%80%E5%8F%91//%E7%AC%AC19%E8%8A%82%EF%BC%9A%E8%AE%BE%E8%AE%A1%E6%BB%91%E5%8A%A8%E5%BA%93%E5%AD%98%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%A4%84%E7%90%86%E6%B4%BB%E5%8A%A8%E7%A7%92%E6%9D%80#%E4%BA%94%E5%8A%9F%E8%83%BD%E6%B5%8B%E8%AF%95)五、功能测试

-   确保：kafka 开启、xxl-job 开启、redis 服务开启
-   确保：活动状态可用、活动库存充足、活动时间有效

**单元测试**

**ActivityProcessTest#test_doDrawProcess**

```
@Test
public void test_doDrawProcess() {
    DrawProcessReq req = new DrawProcessReq();
    req.setuId("xiaofuge");
    req.setActivityId(100001L);
    DrawProcessResult drawProcessResult = activityProcess.doDrawProcess(req);
    logger.info("请求入参：{}", JSON.toJSONString(req));
    logger.info("测试结果：{}", JSON.toJSONString(drawProcessResult));
}
```

-   这里你需要保证测试的用户 ID 还有剩余参与活动的次数，否则不能正常参与抽奖活动。

**测试结果**

```
17:31:11.517  INFO 40204 --- [a.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: o1MyIgKrQ2eCeiUrFRD88A
17:31:11.542  INFO 40204 --- [vityPartakeRecordListener : 消费MQ消息，异步扣减活动库存 message：{"activityId":100001,"stockCount":100,"stockSurplusCount":95,"uId":"xiaofuge"}
17:31:11.573  INFO 40204 --- [w.impl.DrawExecImpl       : 执行抽奖策略 strategyId：10001，无库存排除奖品列表ID集合 awardList：["1"]
17:31:11.587  INFO 40204 --- [ce.draw.AbstractDrawBase  : 执行策略抽奖完成【已中奖】，用户：xiaofuge 策略ID：10001 奖品ID：4 奖品名称：AirPods
17:31:11.611  INFO 40204 --- [ucer.KafkaProducer        : 发送MQ消息(中奖发货单) topic：lottery_invoice bizId：xiaofuge message：{"awardContent":"Code","awardId":"4","awardName":"AirPods","awardType":1,"orderId":1461960297911812096,"uId":"xiaofuge"}
17:31:11.618  INFO 40204 --- [tion.ActivityProcessTest  : 请求入参：{"activityId":100001,"uId":"xiaofuge"}
17:31:11.650  INFO 40204 --- [tion.ActivityProcessTest  : 测试结果：{"code":"0000","drawAwardVO":{"awardContent":"Code","awardId":"4","awardName":"AirPods","awardType":1,"grantType":1,"strategyMode":2,"uId":"xiaofuge"},"info":"成功"}
```

-   从测试结果已经可以看到，异步扣减库存的流程已经生效，同时你可以去检查数据库中活动库存是否已经异步更新。_因为我们有一个更新条件判断是否更新数据比剩余库存数据最新，否则不会更新_

---

1.  学习 Redis 云服务环境配置，至少可以知道需要配置哪些内容，才可以让你的本地环境访问到 Redis 云服务
2.  熟知分布式锁的颗粒度可以细化的设计，这在你以后的使用流程中，都可以作为参考
3.  对数据最终一致性有一个基本概念，它是不是强流程、什么时候更新、怎么用 MQ 进行消峰，以避免拖垮数据库
4.  学习整个设计以及对流程的把握，一点合理的设计，在将来的代码维护中，都将发挥巨大的价值