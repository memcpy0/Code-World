@[toc]
引言

最短路径问题

最小耗费生成树
 
Kruskal算法

Prim算法

文件压缩



---
# 1. 贪心法概述
顾名思义，贪心算法 `Greedy algorithms` 是在对问题求解时，总是做出在当前看来是最好的选择。即**贪心算法并不从整体最优考虑**，它所作出的选择**只是在某种意义上的局部最优选择**。

我们总是希望找到整体最优解，那么贪心法就没有价值吗？也不其然，**在某些求解问题中，满足一定的条件时，这些局部最优解可以转变成整体最优解**。所以贪心法的困难部分在于，**需要证明**设计的算法确实是整体最优解或求解了它要解决的问题。虽然贪心算法不能对所有问题都得到整体最优解，但对许多问题它能产生整体最优解。如单源最短路径问题、最小生成树问题等。

此外在一些情况下，即使贪心算法不能得到整体最优解，其最终结果却是最优解的很好近似。

## 1. 从数学角度看贪心法
求解问题时，问题往往直接给出/可以分析出某些**约束条件**，满足约束条件的问题解称为**可行解**。另外问题中直接给出/可以分析出衡量可行解好坏的**目标函数**，使得目标函数取最大值或最小值的可行解称为**最优解**。

例如，求解一个带权无向图 `G` 中从顶点 `i` 到顶点 `j, i ≠ j` 的最短路径，`G` 的边集为 `E` ，顶点集合为 `V` 。**可以分析出这样的最短路径一定是简单路径**，所以：
- **约束条件**是求解的路径为： 
$$\displaystyle \{(i, i_1), (i_1, i_2), \dots, (i_m, j)\ |\ (i, i_1), (i_1, i_2), \dots, (i_m, j) \in E \cap i_k(1≤k≤m)均不相同\}$$
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200921165232444.png#pic_center)
- **目标函数**要让这样的路径最短，即 $$\displaystyle \text{MIN}_{pathlength}  \{(i, i_1), (i_1, i_2), \dots, (i_m, j)\ |\ \text{pathlength}=w(i, i_1) + w(i_1, i_2) + \dots + w(i_m, j),\ w(i,k)表示(i,k)的权值 \}$$ 

贪心法是求解这类问题的常用算法，它从问题的某一个初始解 $\{\}$ 出发，采用**逐步构造最优解**的方法向给定的目标前进，每一步决策产生 $n$ 元组解 $(x_0, x_1, \dots, x_{n-1})$ 的一个分量。**贪心法每一步上用作决策依据的选择准则被称为最优量度标准（或贪心准则）**，也就是说，在选择解分量的过程中，添加新的解分量 $x_k$ 后，形成的部分解 $(x_0, x_1, \dots, x_k)$ 不违反可行解约束条件。**每一次贪心选择都将所求问题简化为规模更小的子问题**，并期望通过每次所做的局部最优选择产生出一个全局最优解。

## 1.2 贪心法求解的问题应具有的性质
### (1) 贪心选择性质
所谓**贪心选择性质**是指所求问题的**整体最优解**可以通过一系列**局部最优**的选择，即贪心选择来达到。也就是说，贪心法仅在当前状态下做出最好选择，即局部最优选择，然后再去求解**做出这个选择后产生的相应子问题的解**。 

### (2) 最优子结构性质
如果一个问题的最优解包含其子问题的最优解，则称此问题具有**最优子结构性质**。问题的最优子结构性质是该问题可用动态规划算法或贪心法求解的关键特征。

## 1.3 贪心法的一般求解过程
贪心法求解问题的基本思路如下：
- 建立数学模型来描述问题；
- 把求解的问题分解为若干个子问题；
- 对每个子问题求解，得到子问题的局部最优解；
- 把子问题的局部最优解合成原来解问题的一个解。

贪心法求解问题的算法框架如下：
```cpp
//假设解向量(x0,x1,…,xn-1)类型为SolutionType，其分量为SType类型
SolutionType Greedy(SType a[], int n) {  
	SolutionType x = {};	  			//初始时，解向量不包含任何分量
    for (int i = 0; i < n; ++i) { 		//执行n步操作  
    	SType xi = Select(a);			//遵循最优度量标准从输入a中选择一个当前最好的分量xi
      	if (Feasiable(xi))	  			//判断加入新分量xi后部分解是否可行
		 	solution = Union(x, xi);	//将xi分量与原部分解合并形成新的部分解 
   	}
   	return x;			  				//返回生成的最优解
}
```

与动态规划算法比较:

贪心算法通常用来于求解最优化问题，即量的最大化或最小化。

然而，贪心算法不像动态规划算法，它通常包含一个用以寻找局部最优解的迭代过程。在某些实例中，这些局部最优解转变成了全局最优解，而在另外一些情况下，则无法找到最优解。

基本思想
贪心算法在少量计算的基础上做出正确猜想而不急于考虑以后的情况。
它一步步地来构筑解。
每一步均是建立在局部最优解的基础之上，而每一步又都扩大了部分解的规模。
做出的选择产生最大的直接收益而又保持可行性。
因为每一步的工作很少且基于少量信息，所得算法特别有效。

例子: 分数背包问题

     问题描述: 
给出n个大小为s1, s2,... , sn,值为v1 ,v2,...,vn的项目，并设背包容量为C,要找到非负实数x1,x2,…xn使和$$\sum_{i = 1}^{n} X_iV_i$$



在约束$$\sum_{i=1}^n X_iS_i \leq C$$


下最大。

n=3, C=20, (v1,v2,v3)=(25,24,15),
			(s1,s2,s3)=(18,15,10)
可行方案:
	    (x1,x2,x3)		$\sum_{i=1}^n X_iS_i$ 	$\sum_{i = 1}^{n} X_iV_i$
	(1)(1/2,1/3,1/4)		16.5		24.5   
	(2)(1,2/15,0)		20		28.2
	(3)(0,2/3,1)			20		31
	(4)(0,1,1/2)			20		31.5

选择策略-1
从剩下的物品中选择最大价值的物品装入背包，得到：

方案(2)(1,2/15,0)	20	28.2 (非最优)

原因：虽然价值很大，但是容量的消耗太快

选择策略-2
从剩下的物品中选择最小尺寸的物品装入背包。

方案(3) (0,2/3,1)	20	31 (非最优)

原因：虽然容量损耗较少，但是价值增长速度太慢

从剩下的物品中选择最小尺寸的物品装入背包。

方案(3) (0,2/3,1)	20	31 (非最优)

原因：虽然容量损耗较少，但是价值增长速度太慢

从剩下的物品中选择最大vi/si比率的物品装入背包。

Solution (4) (0,1,1/2)	20	31.5 (最优)选择策略-3

Greedy algorithm to solve Knapsack

Step 1:
每项计算yi=vi/si，即该项值和大小的比

Step 2: 
再按比值的降序来排序，从第一项开始装背包，然后是第二项，依次类推，尽可能地多放，直至装满背包。

算法Greedy-KNAPSACK
输入: 按照v(i)/s(i)比率降序排列的 n个物品的容量数组s[1..n]和物品价值数组v[1..n]; 背包的总容量C, 物品的数量n
输出: 最优贪心算法结果x[1..n]  

```vbnet
for i ← 0 to n     {初始化x[i] }
	 x[i] ← 0
end for
cu ← C
for i ← 0 to n    {物品按次序装入背包 }
	 if s[i] > cu then 
		exit 
	end if
      x(i)← 1
      cu ←cu-s(i)   {剩余背包容量}
end for
if i ≤n then x(i) ←cu/s(i) end if {最后剩余背包容量中装入物品i的比率}
return x
```
贪心算法架构
```vbnet
Algorithm GREEDY(A,n)
	solution ← Ø
	for i←1 to n do
		x←SELECT(A)
		if FEASIBLE(solution,x)
			then solution←UNION(solution,x)
		end if
	end for
return (solution)
```

贪心算法特点


算法由一个简单的迭代过程构成，在维持可行性的前提下它选择能产生最大直接利益的项。


贪心算法产生全局最优解的最重要因素是选择策略。

贪心算法基本要素

对于一个具体的问题，怎么知道是否可用贪心算法解此问题，以及能否得到问题的最优解呢?这个问题很难给予肯定的回答。

 但是，从许多可用贪心算法求解的问题中我们看到这类问题一般具有2个重要的性质：贪心选择性质和最优子结构性质。 

贪心选择性质

所谓贪心选择性质是指所求问题的整体最优解可以通过一系列局部最优的选择，即贪心选择来达到。这是贪心算法可行的第一个基本要素，也是贪心算法与动态规划算法的主要区别。
动态规划算法通常以自底向上的方式解各子问题，而贪心算法则通常以自顶向下的方式进行，以迭代的方式作出相继的贪心选择，每作一次贪心选择就将所求问题简化为规模更小的子问题。 
对于一个具体问题，要确定它是否具有贪心选择性质，必须证明每一步所作的贪心选择最终导致问题的整体最优解。

最优子结构性质
当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构性质。问题的最优子结构性质是该问题可用动态规划算法或贪心算法求解的关键特征。
贪心算法和动态规划算法都要求问题具有最优子结构性质，这是2类算法的一个共同点。但是，对于具有最优子结构的问题应该选用贪心算法还是动态规划算法求解? 是否能用动态规划算法求解的问题也能用贪心算法求解?

## 8.2 最短路径问题

       问题描述:

设G = (V, E)是一个每条边有非负长度的有向图，有一个特异顶点s称为源。

单源最短路径问题，或者简称为最短路径问题，是要确定从s到V中每一个其他顶点的距离，这里从顶点s到顶点x的距离定义为从s到x的最短路径的长度。
Dijkstra算法基本思想

贪心技术: Select the path in nonincreasing order.
为简便起见，我们假设V={1,2,…,n}, s=1.

初始时，将顶点分为两个集合X = {1} 和 Y = {2,3,...,n}。这样做的目的是让X包含这样的顶点集合:从源点到这些顶点的距离已经确定。

在每一步中，我们选定源点到它的距离己经获得的一个顶点y ∈ Y ，并将这个顶点移到X中。

与Y中的每个顶点y联系的是标记 $\lambda[y]$ ，它是只经过X中顶点的最短路径的长度，一旦顶点y $\in$ Y移到X中，与y相邻的每个顶点 w $\in$ Y的标记就被更新，这表示找到了经过y到w的更短路径。 

算法8.1 DIJKSTRA 

输入:含权有向图G=(V,E), where V={1,2,…,n}.
输出: G中顶点1到其他顶点的距离。
```vbnet
1. X={1};  Y ← V-{1}; λ[1] ← 0
2. for y ← 2 to n
3. 	  if y 相邻于 1 then λ[y] ← length[1,y]
4.	  else λ[y] ←  ∞
5.	  end if
6.end for
7.for j ← 1 to n-1
8. 	令y ∈Y 使得λ[y] 最小
9.		X ← X ∪{y}              {将顶点y 加入X}
10.	  Y ← Y- {y}            {将顶点y 从 Y中删除}
11.	  for 每条边(y,w)
12.		  if w ∈Y and λ[y]+length[y,w]< λ[w] then
13.			  λ[w] ←  λ[y]+length[y,w]
14.	  end for
15. end for	
```
第1步: Θ(n) 时间. 

第3步 和第4步: 分别为Θ(n) 和O(n)

第8步: Θ(n2). 

第9步和第 10步:每次迭代花费时间Θ(1) ，共用了Θ(n) 时间. 

第11步和第12步共需要时间Θ(m). 这里m=|E|.

例子
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200316185623883.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L215UmVhbGl6YXRpb24=,size_16,color_FFFFFF,t_70)


X
{1}
{1,2}
{1,2,4}
{1,2,4,3}
{1,2,4,3,5}
{1,2,4,3,5,6}
Y
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200316185010776.png)![在这里插入图片描述](https://img-blog.csdnimg.cn/20200316185447942.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200316185453246.png)![在这里插入图片描述](https://img-blog.csdnimg.cn/20200316185508849.png)![在这里插入图片描述](https://img-blog.csdnimg.cn/202003161855142.png)####  正确性
引理8.1:
在算法DIJKSTRA中，当顶点y在第8步中被选中，如果标记λ[y] 是有限的，那么、 λ[y] = δ[y]。(δ[y] 表示从源点x到y的距离）
证明：
对顶点离开集合Y并进入X的次序做归纳。
第1个离开的顶点是1，我们有λ[1]=δ[1]=0。假设引理中的结论对于所有在y前离开Y的顶点都成立。
因为λ[y]是有限的，则必存在从1到y的路径，它的长是λ[y]。设π=1,…,x,w,…,y是从1到y的最短路径，其中x是在y前最迟离开Y的顶点。我们有λ[y] ≤ λ[w] ≤ λ[x]+length(x,w)=δ[x]+length(x,w)= δ[w] ≤ δ[y]. 
上述的证明基于这样一个假设，即所有的边长都是非负的。
p149


第1步: Θ(n) 时间. 
第3步 和第4步: 分别为Θ(n) 和O(n)
第8步: Θ(n2). 
第9步和第 10步:每次迭代花费时间Θ(1) ，共用了Θ(n) 时间. 
第11步和第12步共需要时间Θ(m). 这里m=|E|.

根据以上得出算法的时间复杂性是Θ(m+n2) = Θ(n2).
p149

算法分析 
第1步: Θ(n) 时间. 
第3步 和第4步: 分别为Θ(n) 和O(n)
第8步: Θ(n2). 
第9步和第 10步:每次迭代花费时间Θ(1) ，共用了Θ(n) 时间. 
第11步和第12步共需要时间Θ(m). 这里m=|E|.

根据以上得出算法的时间复杂性是Θ(m+n2) = Θ(n2).
p149

  定理 8.1 
给出一个边具有非负权的有向图G和源顶点s ，算法DIJKSTRA在时间Θ (n2)内找出从s到其他每一顶点距离的长度

8.2.1 稠图的线性时间算法
基本思想: 
用最小堆数据结构来保持集合Y中的顶点，使Y组中离V-Y最近的顶点y可以在O(log n)时间内被选出

与每个顶点v相关的键就是它的标记[v]. 

最后的算法如算法SHORTESTPATH所示
算法8.2 SHORTESTPATH

输入:含权有向图G=(V,E), where V={1,2,..,n}.
输出: G中顶点1到其他顶点的距离。假设已有一个空堆H。
```
1.Y ← V-{1}; λ[1] ← 0;   key(1) ←  λ[1]
2.for  y ← 2  to  n
3.	if  y  邻接于1  then
4.	     λ[y]=length[1,y]
5.	      key(y) ←  λ[y]
6.	      INSERT(H,y)
7.	else
8.	     λ[y] ←  ∞
9.      	      key[y]← λ[y]
10.	end if  
11. end for 
12. for j←1 to n-1
13.	y←DELETEMIN(H)
14.	Y←Y-{y}     {将顶点y从Y删除}
15.	 for每个邻接于y的顶点w ∈Y
16.	    if λ[y]+length[y,w]< λ[w] then
17.	 	λ[w]← λ[y]+length[y,w]
18.		key(w)← λ[w]
19.	    end if
20.	    if w    H then INSERT(H,w)
21.	    else SIFTUP(H,H-1(w))  {H-1(w)返回w在H中的位置}
22.	    end if
23.	end for
24. end for 
```

需要强调的:输入算法的是邻接表，如果用邻接矩阵，我们最终会得到一个Θ(n2)时间的算法。

运行时间主要取决于堆运算。
这里共有n -1个DELETEMIN运算，n-1 个INSERT 运算，最多m-n+1 个SHIFTUP 运算。每个堆运算用O(logn)时间，得到总共需要 O(mlog n) 的时间。 

定理8.2
给出具有非负权重的边和源顶点s的图G，算法SHORTESTPATH可在O(m logn)时间内找出从s到其他每一个顶点的距离。如果图是稠密的，即对于某个ε>0 ，m $\geq$ n1+ε，那么它可以被改善为在时间time O(m/ε)内运行。
P151


8.3 最小耗费生成树 (Kruskal算法)
   定义8.1:
设G = (V, E)是一个具有含权边的连通无向图。G的一裸生成树(V, T)是G的作为树的子图。
如给G加权并且T的各边的权的和为最小值，那么(V,T)就称为最小耗费生成树或简称为最小生成树

问题描述

假设G为连通的，怎么找到最小生成树 (MST)?


工作原理：维护由许多生成树组成的一个森林，这些生成树逐步合并直到最终森林只由一棵树组成，这棵树就是最小耗费生成树。

Step 1:此算法先从对权以非降序排列着手。

Step 2:接着从由图的顶点组成而不包含边的森林(V, T)开始，重复下面的这一步，直到(V, T)被变换成一棵树：
设(V,T)是到现在为止构建的森林， e∈E-T为当前考虑的边，如果把e加到T中不生成一个回路，那么将e加入进T，否则丢弃。
这个处理在恰好加完n-1条边后结束。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200316190934685.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L215UmVhbGl6YXRpb24=,size_16,color_FFFFFF,t_70)![在这里插入图片描述](https://img-blog.csdnimg.cn/20200316191028727.png)!构成回路, 这条边被丢弃.

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020031619095038.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L215UmVhbGl6YXRpb24=,size_16,color_FFFFFF,t_70)Kruskal算法的执行
数据结构来表示森林:
为有效地实现此算法，我们需要某种机制来检测加入边后是否构成回路。让它在算法的每个时刻来表示森林，并且在向T中添加边时动态检测是否有回路生成。
这种数据结构的一个合适选择是4.3节讨论过的不相交集表示法
开始时，图的每个顶点由一棵包含一个顶点的树表示
在算法的执行过程中，森林中的每个连通分量由一棵树来表示。

算法8.3 KRUSKAL
输入:包含n个顶点的含权连通无向图G=(V,E)。
输出:由G生成的最小耗费生成树T组成的边的集合。
```
1. 按非降序权重将E中的边排序
2.for 每条边v∈V
3.	MAKESET{v}
4.end for
5.T={}
6.while |T|<n-1
7.	令 (x,y)为E中的下一条边.
8.	if FIND(x) ← FIND(y) then {检查x，y是否在同一颗树中}
9.  		将(x,y) 加入 T
10   		 UNION(x,y)
11	end if
12. end while
```
第1步和第2步分别花费O(mlogm) 和Θ(n), 这里 m = |E|. 
第7步执行n-1次总共要Θ(n)时间。合并运算执行n-1次，查找运算最多2m次.
第5步花费Θ(1)，再加上第9步最多执行m次，它的总花费是O(m)。
由定理4.3，这两个运算的总花费是O(mlog*n)。

正确性
引理8.2: 在含权无向图中，算法KRUSKAL正确地找出最小生成树。
反证法：假设KRUSKAL生成的不是最小生成树
1).设KRUSKAL生成的树为G0
2).假设存在Gmin使得cost(Gmin)<cost(G0)   则在Gmin中存在<u,v>不属于G0
3).将<u,v>加入G0中可得一个环，且<u,v>不是该环的最长边(这是因为<u,v>∈Gmin)
4).这与KRUSKAL每次生成最短边矛盾
5).故假设不成立，命题得证.
Proof  P241(or P153)

算法分析
第1步和第2步分别花费O(mlogm) 和Θ(n), 这里 m = |E|. 
第7步好执行n-1次总共要Θ(n)时间。合并运算执行n-1次，查找运算最多2m次.
第5步花费Θ(1)，再加上第9步最多执行m次，它的总花费是O(m)。由定理4.3，这两个运算的总花费是O(mlog*n)。
这样算法总的运行时间取决于排序步，也就是O(mlogm) 
p153

8.4  最小耗费生成树 (Prim算法)
基本思想
设G=(V,E)，为了简便起见，V取整数集合 {1,2,…,n}. 

算法从建立两个顶点集合开始: X={1}和Y={2,…,n} 。接着生长一棵生成树，每次一条边。

在每一步，它找出一条权重最小的边(x,y) ，这里x∈X，y ∈Y并且把y从Y移到X。重复这一步直到Y为空。

此算法概况如下：
```
T←{};  X←{1};  Y←V-{1}
while Y ← {}
      设(x,y)是最小权重的边，其中x∈X and y∈Y
      X←X∪{y}
      Y←Y-{y}
      T←T∪{(x,y)}
end while 
```
  
算法 8.4 PRIM      p154
输入:含权连通无向图G=(V,E), 其中 V={1,2,..,n}.
输出:由G生成的最小耗费生成树T组成的边的集合。

```
1.T←{};   X←{1};    Y←V-{1}
2.for y←2 to n
3.	if y 邻接于1 then
4.		N[y]←1
5.		C[y]←c[1,y]
6.	else C[y] ← ∞
7.	end if 
8.end for      
9. for j ←1 to n-1   {寻找n-1 条边}
10.    令y∈Y  使得 C[y] 最小
11.	    T ← T∪{y,N[y]}               {将边(y,N[y]) 加入 T}
12.		X ← X∪{y}                      {将顶点y 加入 X}
13.     Y ← Y-{y}                        {从Y删除顶点}
14.     for 每个邻接于y的顶点 w ∈Y
15.    	   if    c[y,w]<C[w]      then
16.            N[w] ← y
17.            C[w] ← c[y,w]
18.		   end if
19.     end for
20. end for  
                                             
```
第1步耗费 Θ(n)时间. 

第2步的for循环需要时间Θ(n) .

第3步到第6步需要时间O(n). 
算法分析

第1步耗费 Θ(n)时间. 
第2步的for循环需要时间Θ(n) .第3步到第6步需要时间O(n). 
第10步搜索离X最近的顶点y，每迭代一次需要花费时间Θ(n) ，而这一步执行了n-1次，所以第10步一共花费时间Θ(n2)
第11步、第12步和第13步，每迭代一次花费时间Θ(1) 总共花费时间Θ(n) 。
第14步的for循环执行了2m次，第14步一共需要的时间是Θ(m)
…P156
这就得到了算法的时间复杂性是Θ(m+n2) 

算法分析
基本思想
现在要改进算法PRIM，就像曾经对算法DIJKSTRA所做的那样，目标是把m= o(n2)的那类图的时间复杂性从(n2)减少到O(mlogn) 。以后还要进一步改进它，使在稠图情况下，可以在对边数的线性时间内运行。

就像在算法SHORTESTPATH中那样，基本思想是用最小堆数据结构(见4.2节)来保持边界顶点集，使得可以在O(logn)时间内取得Y集中的顶点y，这个y和V-Y集中一个顶点连接的边的耗费是最小的。修改后的算法在算法MST中给出。

算法 8.5 MST

输入:含权连通无向图G=(V,E), where V={1,2,..,n}.
输出:由G生成的最小耗费生成树T组成的边的集合。假设我们已有一个空堆H.
```
1.	T ←  {};   Y ← V-{1}
2.	for y ← 2 to n
3.    if y 邻接于1 then
4.		N[y] ← 1
5.		key(y) ← c[1,y]
6.		INSERT(H,y)
7.     else key(y) ← ∞
8.	    end if
9. end for      
10. for j ← 1 to n-1                     {查找n-1 条边}
11.      y ← DELETEMIN(H)
12.      T ← T∪{(y,N|y|)}             {添加边(y,N|y|)到T}
13.      Y ← Y-{y}                         {从Y删除顶点y}
14.      for  每个邻接于y的顶点w∈ Y
15.           if c[y,w]<key(w)  then
16.               N[w] ← y
17.	    key(w) ← c[y,w]
18.	end if
19.	if w not in H then INSERT(H,w)
20.	else SIFTUP(H,H-1(w))
21.        end for
22. end for 
```

算法分析
 定理8.5

给出一个含权无向图G，算法MST在O(mlogn)时间内找出最小耗费生成树。如果图是稠密的，即如果时于某个ε>0, m  $\geq \  n^{1+ε}$，那么它可以被进一步改进为在O(m/ε) 时间内运行。


8.5 文件压缩
问题描述: 
假设有一个字符串文件，我们希望用这样一种方法尽可能多地压缩文件，但源文件能够很容易地被重建。 

设文件中的字符集是C = {c1,c2,...,cn}，又设f(ci),1 ≤ i≤ n，是文件中字符ci的频度，即文件中ci出现的次数。用定长比特数表示每个字符，称为字符的编码，文件的大小取决于文件中的字符数。

变长编码
然而由于有些字符的频度可能远大于另外一些字符的频度，所以用变长的编码是有道理的。从直观上说，那些频度大的字符将被赋予短的编码，而长的编码可以赋给那些频度小的字符。当编码在长度上变化时，我们规定一个字符的编码必须不能是另一个字符编码的前缀(即词头)，这种码称为前缀码。

例如，如果我们把编码10和101赋予字符“a”和“b”就会存在二义性，不清楚10究竟是“a”的编码还是字符“b”编码的前缀。

Huffman 编码
一旦满足前缀约束，编码就变得没有二义性了，就可以扫描比特序列直到找到某个字符的编码。

对给定比特序列进行分析的一种方法是用一棵满二叉树，它的每一个内部节点都恰好有两个分支，标记为0和1，这棵树中的叶子对应于字符，从根到叶的每一条路径上的0和1的序列对应于一个字符的编码。

Huffman 编码：
这个算法由Huffman提出。由算法构造的编码满足前缀约束，并且最小化压缩文件的大小。
例子
文件由字母a，b，c，d和e组成,  频度为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200316192211410.png)![在这里插入图片描述](https://img-blog.csdnimg.cn/20200316192225725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L215UmVhbGl6YXRpb24=,size_16,color_FFFFFF,t_70)算法8.6 HUFFMAN

输入:  n个字符的集合C={c1,c2,…,cn}和它们的频度{f(c1),f(c2),…,f(cn)}.
输出:  C的Huffman 树(V,T)
```
1.根据频度将所有字符插入最小堆H
2. V ← C; T={}
3. for j ←1 to n-1
4.	c ← DELETEMIN(H)
5.	c’ ← DELETEMIN(H)
6.	f(v) ← f(c)+f(c’)        {v 是一个新节点}
7.	INSERT(H,v)
8.	V=V ∪{v}    {添加v 到 V}
9.	T=T ∪{(v,c),(v,c’)}    {使c和c’成为T中v的孩子}
10. end for
```


把所有字符插人堆中需要时间$\Theta(n)$见定理4.1)。
从堆中删除两个元素和加一个新元素需要的时间是O(log n) 。
因为这被重复n-1次，for循环需要的所有时间是O(nlogn) ，

就得到算法的时间复杂性是O(nlogn)



