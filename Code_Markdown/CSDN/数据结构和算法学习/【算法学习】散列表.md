> 参考算导第11章 散列表
![在这里插入图片描述](https://img-blog.csdnimg.cn/2a4c6b6bb42942f18da5a4df3bd6577f.png)

许多应用都需要一种动态集合结构，它至少要支持 `INSERT, SEARCH, DELETE` 字典操作。例如，用于程序语言编译的编译器维护了一个符号表，其中元素的关键字为任意字符串，它与程序中的标识符相对应。**散列表** `hash tabl` 是实现字典操作的一种有效数据结构。尽管最坏情况下，散列表中查找一个元素的时间与链表中查找的时间相同，达到了 $\Theta(n)$ 。然而在实际应用中，散列查找的性能是极好的。在一些合理的假设下，在散列表中查找一个元素的平均时间是 $O(1)$ 。

散列表是普通数组概念的推广。由于对普通数组可以直接寻址，使得能在 $O(1)$ 时间内访问数组中的任意位置。（算导11.1节）更详细地讨论直接寻址。如果存储空间允许，我们可以提供一个数组，为每个可能的关键字保留一个位置，以利用直接寻址技术的优势。

当能实际存储的关键字数目比全部的可能关键字总数要小时，采用散列表就成为直接数组寻址的一种有效替代，因为散列表使用一个长度与实际存储的关键字数目成比例的数组来存储。在散列表中，不是直接把关键字作为数组的下标，而是根据关键字**计算**出相应的下标。
- （算导11.2节）介绍这种技术的主要思想，着重介绍通过“链接” `chaining` 方法解决“冲突” `collision` ——所谓冲突，就是指多个关键字映射到数组的同一个下标。
- （算导11.3节）介绍如何利用散列函数，根据关键字计算出数组的下标。另外，还将介绍和分析散列技术的几种变形。
- （算导11.4节）介绍“开放寻址法” `open addressing` ，它是处理冲突的另一种方法。
- 散列是一种极其有效和实用的技术：基本的字典操作平均只需要 $O(1)$ 的时间。（算导11.5节）介绍当关键字集合是静态存储（即关键字集合一旦存入后就不再改变）时，“完全散列” `perfect hashing` 如何能够在 $O(1)$ 的**最坏情况时间**内完成关键字查找。


---
# 1. 直接寻址表
当关键字的全域 $U$ 比较小时，直接寻址是一种简单而有效的技术。假设某应用要用到一个动态集合，其中每个元素都是取自全域 $U = \{0,1,\dots, m-1\}$ 中的一个关键字，**这里 $m$ 不是一个很大的数**。另外，**假设没有两个元素具有相同的关键字**。

为表示动态集合，我们用一个数组，或称为**直接寻址表** `direct-address table` ，记为 $T[0 \dots m - 1]$ 。其中每个位置或称为**槽** `slot` ，对应全域 $U$ 中的一个关键字。槽 $k$ 指向集合中一个关键字为 $k$ 的元素。如果该集合中没有关键字为 $k$ 的元素，则 `T[k] = NULL` 。图11-1描述了该方法。
![在这里插入图片描述](https://img-blog.csdnimg.cn/04134261a063495d836627deaec49f73.png)

几个字典操作实现起来比较简单，且每个操作都只需 $O(1)$ 时间：
```cpp
DIRECT-ADDRESS-SEARCH(T, k)
	return T[k]
DIRECT-ADDRESS-INSERT(T, x)
	T[x.key] = x
DIRECT-ADDRESS-DELETE(T, x)
	T[x.key] = NULL
```
对于某些应用，直接寻址表本身就可以存放动态集合中的元素。也就是说，并不把每个元素的关键字及其辅助数据、都放在直接寻址表外部的一个对象中，再由表中某个槽的指针指向该对象，而是直接把该对象存放在表的槽中，从而节省了空间。我们使用对象内的一个特殊关键字来表明该槽为空。而且，通常不必存储该对象的关键字属性，因为如果知道一个对象在表中的下标，就可以得到它的关键字。
> 然而，如果不存储关键字，我们就必须有某种方法来确定某个槽是否为空。（？无用的废话）

---
# 2. 散列表
直接寻址技术的缺点是非常明显的：如果全域 $U$ 很大，则在一台标准的计算机可用内存容量中，要存储大小为 $|U|$ 的一张表 $T$ 也许不太实际，甚至是不可能的。还有，**实际存储**的关键字集合 $K$ 相对于 $U$ 来说可能很小，使得分配给 $T$ 的大部分空间都将浪费掉。

当存储在字典中的关键字集合 $K$ 比所有可能的关键字的全域 $U$ 要小许多时，散列表需要的存储空间要比直接寻址表少得多。特别地，我们能将散列表的存储需求降至 $\Theta( |K|)$ ，同时散列表中查找一个元素的优势仍得到保持，只需要 $O(1)$ 的时间。问题是这个界是针对**平均情况时间**的，而对直接寻址来说，它是适用于**最坏情况时间**的。

在直接寻址方向下，具有关键字 $k$ 的元素被存放在槽 $k$ 中。在散列方式下，该元素存放在槽 $h(k)$ 中；即利用**散列函数** `hash function` $h$ ，由关键字 $k$ 计算出槽的位置。这里函数 $h$ 将关键字的全域 $U$ 映射到**散列表** `hash table` $T[0 \dots m - 1]$ 的槽位上：
$$h : U \to \{ 0,\ 1,\ \dots ,\ m - 1\}$$

这里散列表的大小 $m$ 一般要比 $| U|$ 小得多。我们可以说，一个具有关键字 $k$ 的元素被散列到槽 $h(k)$ 上，也可以是 $h(k)$ 是关键字 $k$ 的**散列值**。==散列函数缩小了数组下标的范围，即减少了数组的大小，使其由 $|U|$ 减少为 $m$== 。图11-2描述了这个基本方法。
![在这里插入图片描述](https://img-blog.csdnimg.cn/347326bd3cfd4122b50ba751a4a0c048.png)
这里存在一个问题：两个关键字可能映射到同一个槽中，我们称这种情形为**冲突** `collision` 。幸运的是，我们能找到有效的方法来解决冲突。

当然，理想的解决方法是避免所有的冲突，我们可以试图选择一个合适的散列函数 $h$ 来做到这一点。一个想法就是使 $h$ 尽可能地“随机”，从而避免冲突、或者使冲突的次数最小化。实际上，术语“散列”本意就是随机混杂和拼凑，就体现了这种思想（当然，一个散列函数 $h$ 必须是确定的，因为某个给定的输入 $k$ 应始终产生相同的结果 $h(k)$ ）。但是，由于 $|U| > m$ ，故至少有两个关键字的散列值相同，所以要想完全避免冲突是不可能的。因此，我们一方面可以通过「精心设计的散列函数」来尽量避免冲突的次数，另一方面仍需要有解决可能出现冲突的方法。

本节余下的部分要介绍一种最简单的冲突解决方法，称为**链接法** `chaining` 。（算导11.4节）还要介绍另一种冲突解决的方法，称为**开放寻址法** `open addressing` 。

## 2.1 通过链接法解决冲突
在链接法中，把散列到同一个槽的所有元素都放在一个链表中，如图11-3所示。槽 $j$ 中有一个指针，它指向存储所有散列到 $j$ 的元素的链表的表头；如果不存在这样的元素，则槽 $j$ 中为 `NULL` 。

在采用链接法解决冲突后，散列表 $T$ 上的字典操作就很容易实现。
```cpp
CHAINED-HASH-INSERT(T, x)
	insert x at the head of list T[h(x.key)]

CHAINED-HASH-SEARCH(T, k)
	search for an element with key k in list T[h(k)]

CHAINED-HASH-DELETE(T, x)
	delete x from the list T[h(x.key)]
```
插入操作的最坏情况运行时间为 $O(1)$ 。插入过程在某种程度上要快一些，因为假设待插入的元素 $x$ 没有出现在表中；如果需要，可以在插入前执行一个搜索来检查这个假设（需付出额外代价）。查找操作的最坏情况运行时间与表的长度成正比。下面还将对此操作进行更详细的分析。

如图11-3所示，如果散列表中的链表是双向链接的，则删除一个元素 $x$ 的操作可以在 $O(1)$ 时间内完成。注意到，`CHAINED-HASH-DELETE` 以元素 $x$ 而非它的关键字 $k$ 作为输入，所以无需先搜索 `x` （？即这里的元素 $x$ 应该是其指针或引用）。**如果散列表支持删除操作，则为了能够更快地删除某一元素，应该将其链表设计为双向链接的**（如果表是单链接的，则为了删除元素 $x$ ，我们首先必须在表 `T[h(x.key)]` 中找到元素 $x$ ，然后通过更改 $x$ 前驱元素的 `next` 属性，把 `x` 从链表中删除。在单链表情况下，删除和查找操作的渐近运行时间相同）。
![在这里插入图片描述](https://img-blog.csdnimg.cn/db037dc8ae09458297b2341c91e9b700.png)
## 2.2 链接法散列的分析
采用链接法后，散列的性能怎么样呢？特别地，要查找一个具有给定关键字的元素，需要多长时间呢？

给定一个能存放 $n$ 个元素的、具有 $m$ 个槽位的散列表 $T$ ，定义 $T$ 的**装载因子** `load factor` $\alpha = n / m$ ，即一个链的平均存储元素数。我们的分析将借助 $\alpha$ 来说明，$\alpha$ 可以大于、等于或小于 $1$ 。

用链接法散列的最坏情况性能很差：所有的 $n$ 个关键字都散列到同一个槽中，从而产生出一个长度为 $n$ 的链表。这时，最坏情况下查找的时间为 $\Theta(n)$ ，再加上计算散列函数的时间，如此就和用一个链表来链接所有的元素差不多了。显然，我们并不会因为散列表的最坏情况性能差，就不使用它（算导11.5节介绍的完全散列，能够在关键字集合为静态时，提供比较好的最坏情况性能）。

散列方法的平均性能，依赖于所选取的散列函数 $h$ 、将所有关键字的集合分布在 $m$ 个槽位上的均匀程度。（算导11.3节将讨论这些问题）现在先假定，**任何一个给定元素等可能地散列到 $m$ 个槽中的任何一个，且与其他元素被散列到什么位置上无关**。我们称这个假设为**简单均匀散列** `simple uniform hashing` 。

对于 $j = 0,1, \dots, m - 1$ ，列表 $T[j]$ 的长度用 $n_j$ 表示，于是有：$$n = n_0 + n_1 +\dots + n_{m - 1} \tag{11.1}$$ 并且 $n_j$ 的期望值为 $E[ n_j ] = \alpha = n  /m$ 。

假定可以在 $O(1)$ 时间内计算出散列值 $h(k)$ ，从而「查找关键字为 $k$ 的元素的时间」线性地依赖于表 $T[h(k) ]$ 的长度 $n_{ h( k)}$ 。先不考虑计算散列函数和访问槽 $h(k)$ 的 $O(1)$ 时间，我们来看看**查找算法查找元素的期望数**，即为比较元素的关键字是否为 $k$ 而检查的表 $T[ h(k) ]$ 中的元素数。分两种情况来考虑。在第一种情况中，查找不成功：表中没有一个元素的关键字为 $k$ 。在第二种情况中，成功地查找到关键字为 $k$ 的元素。

**定理11.1** 在简单均匀散列的假设下，对于用链接法解决冲突的散列表，一次不成功查找的**平均时间**为 $\Theta(1 + \alpha)$ 。
**证明**：在简单均匀散列的假设下，任何「尚未被存储在表中的关键字 $k$ 」都等可能地被散列到 $m$ 个槽中的任何一个。因而，当查找一个关键字 $k$ 时，==在不成功的情况下，查找的期望时间就是查找至链表 $T [ h(k) ]$ 末尾的期望时间，这一时间的期望长度为 $E[ n_{ h(k) } ] = \alpha$== 。于是，一次不成功的查找平均要检查 $\alpha$ 个元素，并且所需要的总时间（包括计算 $h(k)$ 的时间）为 $\Theta(1 + \alpha)$ 。$\blacksquare$

对于成功的查找来说，情况略有不同，这是因为每个链表并不是等可能地被查找到的（？）。替代的是，某个链表被查找到的概率与它所包含的元素数成正比。然而，期望的查找时间仍然是 $\Theta(1 + \alpha)$ 。

**定理11.2** 在简单均匀散列的假设下，对于用链接法解决冲突的散列表，一次成功查找所需的**平均时间**为 $\Theta( 1 + \alpha)$ 。
**证明**：假定要查找的元素是表中存放的 $n$ 个元素中任何一个，且是等可能的。在对元素 $x$ 的一次成功查找中，所检查的元素数就是 $x$ 所在的链表中 $x$ 前面的元素数多 $1$ 。在该链表中，因为新的元素都是在表头插入的，所以出现在 $x$ 之前的元素都是在 $x$ 之后插入的。为了确定所检查的元素的期望数目，对 $x$ 所在的链表，在 $x$ 之后插入到表中的期望元素数加 $1$ ，再对表中的 $n$ 个元素 $x$ 取平均（？）。

设 $x_i$ 表示插入到表中的第 $i$ 个元素（ $i = 1, 2, \dots, n$ ），并设 $k_i = x_i.key$ 。对关键字 $k_i, k_j$ ，定义指示器随机变量 $X_{ij} = I ( h(k_i) =h(k_j) )$ 。在简单均匀散列的假设下，有 $Pr( h(k_i)= h(k_j)) = 1 / m$ ，从而根据**引理5.1**，有 $E[X_{ij} ] = 1/m$ 。于是在一次成功的查找中，所检查元素的期望数目为：
$$\begin{aligned}
E \bigg [ \dfrac{1}{n} \sum^n_{i=1} \bigg( 1 + \sum^n_{j = i +1} X_{ij} \bigg) \bigg] &= \dfrac{1}{n} \sum^n_{i =1} \bigg ( 1 + \sum^n_{j=i+1} E[X_{ij} ] \bigg) \quad &期望的线性性 \\
&= \dfrac{1}{n} \sum^n_{i=1}  \bigg( 1 + \sum^n_{j=i+1} \dfrac{1}{m} \bigg) = 1 + \dfrac{1}{nm} \sum^n_{i=1} (n - i) \\
&= 1 + \dfrac{1}{nm} \bigg ( \sum^n_{i=1} n - \sum^n_{i=1} i \bigg) = 1 + \dfrac{1}{nm} \bigg (n ^2 - \dfrac{n(n+1)}{2} \bigg) \quad &由等式(A.1) \\
&= 1 + \dfrac{n-1}{2m} = 1 + \dfrac{ \alpha}{2} - \dfrac{ \alpha}{2n} \end{aligned}$$

因此，一次成功的查找所需要的全部时间（包括计算散列函数的时间）为 $\Theta(1+ \alpha / 2 - \alpha / 2n) = \Theta(1 + \alpha)$ 。$\blacksquare$ 

上面的分析意味着什么呢？如果散列表中槽数至少与表中的元素数成正比，则有 $n = O(m)$ ，从而 $\alpha = n / m = O(m) / m = O(1)$ 。所以，查找操作平均需要常数时间。当链表采用双向链表时，插入操作在最坏情况下需要 $O(1)$ 时间，删除操作最坏情况下也需要 $O(1)$ 时间，因而全部的字典操作平均情况下、都可以在 $O(1)$ 时间内完成。


---
# 3. 散列函数
这里将讨论一些关于「如何设计好的散列函数」的问题，并介绍三种具体方法。其中的两种方法（用除法进行散列和用乘法进行散列）本质上属于启发式方法，而第三种方法（全域散列）则利用了随机技术来提供可证明的良好性能。
## 3.1 好的散列函数的特点
一个好的散列函数应（近似地）满足简单均匀散列假设：每个关键字都被等可能地散列到 $m$ 个槽位中的任何一个，并与其他关键字已散列到哪个槽位无关。遗憾的是，**一般无法检查这一条件是否成立**，因为很少能知道关键字散列所满足的概率分布，而且各关键字可能并不是完全独立的。

有时，我们知道关键字的概率分布。例如，如果各关键字都是随机的实数 $k$ ，它们独立均匀地分布在 $0 \le k < 1$ 范围中，那么散列函数：$$h(k) = \lfloor km \rfloor$$ 就能满足简单均匀散列的假设条件。

在实际应用中，常常可以运用启发式方法来构造性能好的散列函数。设计过程中，可以利用关键字分布的有用信息。例如，在一个编译器的符号表中，关键字都是字符串，表示程序中的标识符。一些很相近的符号经常会出现在同一个程序中，如 `pt` 和 `pts` 。好的散列函数应能将这些相近符号散列到相同槽中的可能性最小化。

一种好的方法导出的散列值，在某种程度上应独立于数据可能存在的任何模式。例如，“除法散列”（算导11.3.1节）用一个特定的素数来除所给的关键字，所得的余数即为该关键字的散列值。假定所选择的素数与关键字分布中的任何模式都是无关的，这种方法常常可以给出好的结果。

最后，注意到散列函数的某些应用可能会要求比简单均匀散列更强的性质。例如，可能希望某些很近似的关键字具有截然不同的散列值（使用算导11.4节定义的线性探查技术时，这一性质特别有用）。（算导11.3.3节将介绍的）全域散列 `universal hashing` 通常能够提供这些性质。

## 将关键字转换为自然数
多数散列函数都假定**关键字的全域为自然数集** $\N = \{ 0, 1, 2, \dots \}$ 。因此，如果所给的关键字不是自然数，就需要找到一种方法来将它们转换为自然数。例如，一个字符串可以被转换为按适当的基数符号表示的整数。这样，就可以将标识符 `pt` 转换为十进制整数对 $(112, 116)$ （在ASCII字符集中，$p = 112, t = 116$ ）。然后，以 $128$ 为基数来表示，`pt` 即为 $(112 \times 128) +116 = 14 452$ 。在特定的应用场合，通常还能设计出其他类似的方法，将每个关键字转换为一个（可能是很大的）自然数。在后面的内容中，假定所给的关键字都是自然数。

## 11.3.1 除法散列法
在用来设计散列函数的除法散列法中，通过取 $k$ 除以 $m$ 的余数，将关键字 $k$ 映射到 $m$ 个槽中的某一个上，即散列函数为：$$h(k) = k \bmod m$$ 例如，如果散列表的大小为 $m =12$ ，所给关键字 $k = 100$ ，则 $h(k) = 4$ 。由于只需做一次除法操作，所以除法散列法是非常快的。

**当应用除法散列法时，要避免选择 $m$ 的某些值**。例如，$m$ 不应为 $2$ 的幂，因为如果 $m = 2^p$ ，则 $h(k)$ 就是 $k$ 的 $p$ 个最低位数字。除非已知各种最低 $p$ 位的排列形式为等可能的，否则在设计散列函数时，最好考虑关键字的所有位。（算导练习11.3-3要求证明）当 $k$ 是一个按基数 $2^p$ 表示的字符串时，选 $m = 2^p - 1$ 可能是一个糟糕的选择，因为排列 $k$ 的各字符并不会改变其散列值。

**一个不太接近 $2$ 的整数幂的素数，常常是 $m$ 的一个较好的选择**。例如，假定我们要分配一张散列表、并用链接法解决冲突，表中大约要存放 $n = 2000$ 个字符串，其中每个字符有 $8$ 位。如果我们不介意一次不成功的查找需要平均检查 $3$ 个元素，这样分配散列表的大小为 $m = 701$ 。选择 $701$ 这个数的原因是，它是一个接近 $2000 / 3$ 但又不接近 $2$ 的任何次幂的素数。把每个关键字 $k$ 视为一个整数，则散列函数如下：$$h(k) = k \bmod 701$$

## 3.2 乘法散列法
构造散列法的乘法散列法包含两个步骤。第一步，用关键字 $k$ 乘上常数 $A\ (0 < A < 1)$ ，并提取 $kA$ 的小数部分。第二步，用 $m$ 乘以这个值，再向下取整。总之，散列函数为：$$h(k) = \lfloor m (kA \bmod 1) \rfloor$$ 这里用 $kA \bmod 1$ 表示取 $kA$ 的小数部分，即 $kA - \lfloor kA \rfloor$ 。

==乘法散列法的一个优点是，对 $m$ 的选择不是特别关键，一般选择它为 $2$ 的某个幂次（ $m = 2^p$ ，$p$ 为某个整数）==，这是因为我们可以在大多数计算机上、按下面所示方法较容易地实现散列函数。假设某计算机的字长为 $w$ 位，而 $k$ 正好可用一个单字表示。限制 $A$ 为形如 $s / 2^w$ 的一个分数，其中 $s$ 是一个取自 $0 < s < 2^w$ 的整数。参见图11-4，先用 $w$ 位整数 $s = A \cdot 2^w$ 乘上 $k$ ，其结果是一个 $2w$ 位的值 $r_1 2^w + r_0$ ，这里 $r_1$ 为乘积的高位字，$r_0$ 为乘积的低位字。所求的 $p$ 位散列值中，包含了 $r_0$ 的 $p$ 个最高有效位。
![](https://img-blog.csdnimg.cn/9bee28b8dbdc4bd0855bafe4789160f6.png)

虽然这个方法对任何的 $A$ 值都适用，但对某些值效果更好。最佳的选择与待散列的数据的特征有关。*Knuth* 认为：$$A \approx ( \sqrt{5} - 1) / 2 = 0.618\ 033\ 998\ 7\dots \tag{11.2}$$ 是个比较理想的值。

作为一个例子，假设 $k = 123\ 456, p = 14, m = 2^{14} = 16\ 384$ ，且 $w = 32$ 。依据 *Knuth* 的建议，取 $A$ 为形如 $s / 2^{32}$ 的分数，为了让它与 $(\sqrt{5} - 1) / 2$ 最为接近，则 $A = \dfrac{ 2^{31} \times ( \sqrt{5} - 1) }{ 2^{32} } = \dfrac{2\ 654\ 435\ 769} {2^{32}}$ 。那么 $k \times s = 327\ 706\ 022\ 297\ 664 = (76\ 300 \times 2^{32} ) + 17\ 612\ 864$ ，从而有 $r_1 = 76\ 300, r_0 = 17\ 612\ 864$ 。$r_0$ 的 $14$ 个最高有效位产生了散列值 $h(k) = 67$ 。

## 3.3 全域散列法
如果让一个恶意的对手来针对某个特定的散列函数、选择要散列的关键字，那么她会将 $n$ 个关键字全部散列到同一个槽中，使得平均的检索时间为 $\Theta(n)$ 。任何一个特定的散列函数，都可能出现这种令人恐怖的最坏情况。唯一有效的改进方法是，**随机地选择散列函数，使其独立于要存储的关键字**。这种方法称为**全域散列** `universal hashing` ，不管对手选择了怎么样的关键字，其平均性能都很好。

全域散列法在执行开始时，就从一组精心设计的函数中，随机地选择一个作为散列函数。就像在快速排序中一样，随机化保证了**没有哪一种输入会始终导致最坏情况性能**。因为随机地选择散列函数，算法在每一次执行时都会有所不同，甚至对于相同的输入都会如此。这样就可以确保，对于任何输入、算法都具有较好的平均情况性能。再回到编译器的符号表的例子，在全域散列方法中，可以发现程序员对标识符的选择、就不会总是导致较差的散列性能了。仅当编译器选择了一个随机的散列函数，使得标识符的散列效果较差时，才会出现较差的性能。但出现这种情况的概率很小，并且这一概率对于任何相同大小的标识符集来说都是一样的。

设 $H$ 为一组有限散列函数，它将给定的关键字全域 $U$ 映射到 $\{ 0, 1, \dots, m - 1\}$ 中。这样的一个函数组称为**全域的** `universal` ，若对每一对不同的关键字 $k, l \in U$ ，则满足 $h(k) = h(l)$ 的散列函数 $h \in H$ 的个数至多为 $|H| / m$ 。换句话说，**如果从 $H$ 中随机地选择一个散列函数，当关键字 $k \ne l$ 时，两者发生冲突的概率不大于 $1 / m$** ，这也正好是从集合 $\{ 0, 1, \dots m - 1\}$ 中独立地随机选择 $h(k)$ 和 $h(l)$ 时（？）发生冲突的概率。

 
![在这里插入图片描述](https://img-blog.csdnimg.cn/5555215cef9043659521290fef5927e2.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/8ec191d3cc4647caa3a10568f334ddab.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/acec82b41f24461490642e97119d933b.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/1dff02d3a790496da67d149e7c293d0e.png)
当模 $m$ 进行归约时，$s$ 与 $r$ 发生冲突的概率至多为 $( (p - 1) / m) / (p - 1) = 1/ m$ 。

所以，对于任何不同的数对 $k, l \in \Z_p$ ，有
$$Pr( h_{ab}(k) = h_{ab} (l) ) \le 1 / m$$ 于是，$H_{pm}$ 的确是全域的。$\blacksquare$  



---
# 4. 开放寻址法
在**开放寻址法** `open addressing`







![在这里插入图片描述](https://img-blog.csdnimg.cn/93f4204557b34034bf986afa6020448e.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/bc8dc73685c54fd1b97a3a298358b673.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/c18084e47efc494797a9efa974d064e3.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/97860792e2cc46269fe1237f76a13afb.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/014ec17845b848aaa5be1126bc37f90b.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/f842a3a480d14c82a347a032212894be.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/391ae841a6944accb12c24311d3febe4.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/0d005d3023f14da68a27ec543068e1e9.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/f9d98dc7868045a0bc6ee662966c50a7.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/afa1455b3dd440ceba1a6549fba03e43.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/49fcdf2f098640a7bdbc0f9677129fc9.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/992dc8bf5e2f4f3e9d2d4654a70b4b5f.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/bab072d7fbae43c08ab8b706691f06d4.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/466a7d1c439b498bb2fdd1b8901fb177.png)

