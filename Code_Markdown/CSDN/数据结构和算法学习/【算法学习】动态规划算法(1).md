
> 参考算法导论第三版第15章 动态规划算法
> ![](https://img-blog.csdnimg.cn/61269b22836f4e5bae45be122d272dc4.png)

@[toc]

**动态规划** `dynamic programming` 与分治方法相似，都是通过组合子问题的解来求解原问题（在这里，`programming` 指的是一种表格法、并非编写计算机程序）。（如算导第2、4章所述）分治方法将问题划分为互不相交的子问题、递归地求解子问题、再将它们的解组合起来求出原问题的解。与之相反，动态规划应用于子问题重叠的情况，即不同的子问题具有公共的子子问题（子问题的求解是递归进行的，将其划分为更小的子子问题）。在这种情况下，分治算法会做许多不必要的工作，它会反复求解那些公共子子问题；而动态规划对每个子子问题只求解一次，将其解保存在一个表格中，从而无需每次求解一个子子问题时都重新计算，避免了这种不必要的计算工作。

动态规划通常用来求解**最优化问题** `optimization problem` ，这类问题可以有很多可行解，每个解都有一个值，我们希望寻找具有最优值（最小值或最大值）的解。我们称这样的解为问题的一个**最优解** `an optimal solutioin` ，而不是**最优解** `the optimal solution` ，因为可能有多个解都达到最优值。

我们通常按如下四个步骤来设计一个动态规划算法。
1. 刻画一个最优解的结构特征。
2. 递归地定义最优解的值。
3. 计算最优解的值，通常采用自底向上的方法。
4. 利用计算出的信息，构造一个最优解。

步骤 $1 \sim 3$ 是动态规划算法求解问题的基础。如果我们仅仅需要一个最优解的值、而非解本身，可以忽略步骤 $4$ 。**如果确实要做步骤 $4$ ，有时就需要在执行步骤 $3$ 的过程中维护一些额外信息，以便用来构造一个最优解**。

下面将展示，如何用动态规划来求解一些最优化问题。
- （算导15.1节）研究如何将长钢条切割成短钢条，使得总价值最高。
- （算导15.2节）解决如何用最少的标量乘法操作、完成一个矩阵链相乘的运算。
- 基于这些动态规划求解问题的例子，（算导15.3节）讨论「适合用动态规划求解的问题」应该具备的两个关键特征。
- 接下来（算导15.4节）展示，如何用动态规划找到两个序列的最长公共子序列。
- 最后（算导15.5节）用动态规划，解决在已知关键字分布的前提下，如何构造最优二叉搜索树。

---
# 1. 钢条切割
第一个应用动态规划的例子，是求解一个如何切割钢条的简单问题。公司购买长钢条，将其切割为短钢条出售。切割工序本身没有成本支出，管理层希望知道最佳的切割方案。假定我们知道公司出售一段长度为 $i$ 英寸的钢条的价格为 $p_i\ (i =1,2,\dots)$ ，单位为美元。钢条的长度均为整英寸。图15-1给出了一个价格表的样例。
![](https://img-blog.csdnimg.cn/56587c4453df4fde950ce097a95efec9.png)
**钢条切割问题** `rod-cutting problem` 是这样的：给定一段长度为 $n$ 英寸的钢条和一个价格表 $p_i\ (i = 1, 2, \dots, n)$ ，求切割钢条方案，使得销售收益 $r_n$ 最大。注意，如果长度为 $n$ 英寸的钢条的价格 $p_n$ 足够大，最优解可能就是完全不需要切割。

考虑 $n = 4$ 的情况。图15-2给出了 $4$ 英寸钢条所有可能的切割方案，包括根本不切割的方案。我们发现，将一段长度为 $4$ 英寸的钢条切割为两段各长 $2$ 英寸的钢条，将产生 $p_2+p_2 = 5+5 = 10$ 的收益，为最优解。
![](https://img-blog.csdnimg.cn/37a19eb0159b4818b3153ed1d6844971.png)

长度为 $n$ 英寸的钢条共有 $2^{n-1}$ 种不同的切割方案，因为在距离钢条左端 $i\ (i=1,2,\dots, n-1)$ 英寸处，我们总是可以选择切割或不切割。我们用普通的加法符号表示切割方案，因此 $7 = 2+2+3$ 表示将 $7$ 英寸钢条切割为三段——两段长 $2$ 英寸、一段长 $3$ 英寸。如果一个最优解将钢条切割为 $k$ 段（对某个 $1\le k \le n$ ），那么最优切割方案：$$n = i_1 +i_2 + \dots + i_k$$

> 如果我们要求按长度非递减的顺序切割小段钢条，可能的切割方案会少得多，例如对 $n = 4$ ，我们只需考虑五种切割方案：图15-2中的(a)、(b)、c)、(e)和(h) 。切割方案的数量可由**划分函数** `partition function` 给出，此函数近似等于 $e^{\pi \sqrt{2n/3}} / 4n \sqrt{3}$ ，此值小于 $2^{n-1}$ 、但仍远远大于任何 $n$ 的多项式。我们将不再探究此问题。

将钢条切割为长度分别为 $i_1,i_2,\dots,i_k$ 的小段，得到最大收益为：$$r_n = p_{i_1} + p_{i_2} + \dots + p_{i_n}$$

对于上述价格表样例，我们可以观察所有最优收益值 $r_i\ (i = 1, 2, \dots, 10)$ 及对应的最优切割方案：
![](https://img-blog.csdnimg.cn/1f3bdb8846be4a0080015e83c989636e.png)

更一般地，对于 $r_n\ (n \ge 1)$ ，我们可以用「更短的钢条的最优切割收益」来描述它：
$$r_n =\max(p_n,\ r_1 + r_{n-1},\ r_2 + r_{n-2},\ \dots,\ r_{n-1} + r_1 ) \tag{15.1}$$

第一个参数 $p_n$ 对应不切割、直接出售长度为 $n$ 英寸钢条的方案。其他 $n - 1$ 个参数对应另外 $n - 1$ 种方案：对每个 $i = 1, 2, \dots, n - 1$ ，首先将钢条切割为长度为 $i$ 和 $n - i$ 的两段，接着求解这两段的最优切割收益 $r_i, r_{n-i}$（每种方案的最优收益为两段的最优收益之和）。由于无法预知哪种方案会获得最优收益，我们必须考察所有可能的 $i$ ，选取其中收益最大者。如果直接出售原钢条会获得最大收益，我们当然可以选择不做任何切割。

注意到，==为了求解规模为 $n$ 的原问题，我们**先**求解形式完全一样、但规模更小的子问题==。即当完成首次切割后，我们将两段钢条看成两个独立的钢条切割问题实例。==我们通过组合两个相关子问题的最优解，并在所有可能的两段切割方案中选取组合收益最大者，构成原问题的最优解==。我们称钢条切割问题满足**最优子结构** `optimal substructure` 性质：问题的最优解由相关子问题的最优解组合而成，而这些子问题可以独立求解。

除上述求解方法外，钢条切割问题还存在一种相似的、但更为简单的递归求解方法：==我们将钢条从左边切割下长度为 $i$ 的一段，只对右边剩下的长度为 $n - i$ 的一段继续进行切割（递归求解），对左边的一段则不再进行切割==。即问题分解的方式为：**将长度为 $n$ 的钢条分割为左边开始一段，以及剩余部分继续分解的结果**。这样不做任何切割的方案就可以描述为：第一段的长度为 $n$ ，收益为 $p_n$ ，剩余部分长度为 $0$ ，对应的收益为 $r_0 = 0$ 。于是我们可以得到公式 $(15.1)$ 的简化版本：
$$r_n = \max_{1 \le i \le n } (p_i + r_{n-i}) \tag{15.2}$$

在此公式中，原问题的最优解只包含一个相关子问题（右端剩余部分）的解，而不是两个。

## 自顶向下递归实现
下面的过程实现了公式 $(15.2)$ 的计算，它采用的是一种直接的自顶向下的递归方法。
```cpp
CUT-ROD(p, n)
	if n == 0 // 这里伪码有错,应改为n<=0
		return 0
	q = -INF
	for i = 1 to n
		q = max(q, p[i] + CUT-ROD(p, n - i) // 这里也有点错,应判断i是否大于n
	return q
```
过程 `CUT-ROD` 以价格数组 $p[1\dots n]$ 和整数 $n$ 作为输入，返回长度为 $n$ 的钢条的最大收益。若 $n = 0$ ，不可能有任何收益，所以 `CUT-ROD` 的第二行返回 $0$ 。第三行将最大收益 $q$ 初始化为 $-\infin$ ，以便第四至五行的 for 循环能正确计算 $q = \displaystyle \max_{1\le i \le n} (p_i + \textrm{CUT-ROD(p, n - i))}$ ，第六行返回计算结果。利用简单的归纳法，可以证明此结果与公式 $(15.2)$ 计算出的最大收益 $r_n$ 是相等的。

如果用熟悉的编程语言实现 `CUT-ROD` 并运行它，会发现一旦输入规模稍微变大、程序运行时间就变得相当长。例如，对 $n = 40$ ，程序至少运行好几分钟，很可能超过一小时。实际上会发现，每当将 $n$ 增大一，程序运行时间差不多就会增加一倍。

为什么 `CUT-ROD` 的效率这么差？原因在于，`CUT-ROD` 反复地用相同的参数值对自身进行递归调用，即它反复求解相同的子问题。图15-3显示了 $n = 4$ 时的调用过程：`CUT-ROD(p, n)` 对 $i = 1, 2, \dots, n$ 调用 `CUT-ROD(p, n - i)` ，等价于对 $j = 0, 1, \dots, n - 1$ 调用 `CUT-ROD(p, j)` 。当这个过程递归展开时，它所做的工作量（用 $n$ 的函数的形式描述）会爆炸性增长。
![](https://img-blog.csdnimg.cn/6ab0aa9ed4e24f569932a6c1f6358b5b.png)
为了分析 `CUR-ROD` 的运行时间，令 $T(n)$ 表示第二个参数值为 $n$ 时 `CUT-ROD` 的调用次数，此值等于递归调用树中根为 $n$ 的子树中的结点总数，注意，此值包含了根结点对应的最初的一次调用。因此 $T(0) = 1$ ，且：$$T(n)= 1 +\sum^{n-1}_{j=0} T(j) \tag{15.3}$$

第一项 $1$ 表示函数的第一次调用（递归调用树的根结点），$T(j)$ 为调用 `CUT-ROD(p, n - i)` 所产生的所有调用（包括递归调用）的次数，此处 $j = n - i$ 。（算导练习15.1-1要求）证明：
$$T(n) = 2^n \tag{15.4}$$ 则 `CUT-ROD` 的运行时间为 $n$ 的指数函数。

回过头看，`CUT-ROD` 的指数运行时间并不令人惊讶。对于长度为 $n$ 的钢条，`CUT-ROD` 显然考察了所有 $2^{n-1}$ 种可能的切割方案。递归调用树中共有 $2^{n-1}$ 个叶结点，每个叶结点对应一种可能的钢条切割方案。对每条从根到叶的路径，路径上的标号给出了每次切割前右边剩余部分的长度（子问题的规模）。也就是说，标号给出了对应的切割点（从钢条右端测量）。

## 使用动态规划方法求解最优钢条切割问题
现在展示，如何将 `CUT-ROD` 转换为一个更高效的动态规划算法。动态规划的思想如下所述。我们已经看得，朴素递归算法之所以效率很低，是因为它反复求解相同的子问题。因此，**动态规划仔细安排求解顺序，对每个子问题只求解一次，并将结果保存下来**。如果随后再次需要此子问题的解，只需查找保存的结果、而不必重新计算。因此，动态规划付出额外的内存空间来节省计算时间，是典型的时空权衡 `time-memory trade-off` 的例子。而时间上的节省可能是非常巨大的：可能将一个指数时间的解转换为一个多项式时间的解。==如果不同子问题的数量是输入规模的多项式函数，而我们可以在多项式时间内求解出每个子问题，那么动态规划的总运行时间就是多项式阶的==。

动态规划有两种等价的实现方法，下面以钢条切割问题为例展示这两种方法。
- 第一种称为**带备忘的自顶向下方法** `top-down with memoization`（不是拼写错误，是 `memoization` 而非 `memorization` ！前者源自 `memo` 、为备忘之意，因这种方法记录子问题的解、以备随后查找）。此方法仍按自然的递归形式编写过程，但过程会保存每个子问题的解（通常保存在一个数组或散列表中）。当需要一个子问题的解时，过程首先检查是否已经保存过此解。如果是，则直接返回保存的值，从而节省了计算时间；否则，按通常方式计算这个子问题。我们称这个递归过程是**带备忘的** `memoized` ，因为它“记住”了之前已经计算出的结果。
- 第二种称为**自底向上法** `bottom-up method` 。这种方法一般需要恰当定义子问题“规模”的概念，使得任何子问题的求解都只依赖于“更小的”子问题的求解。因而，**我们可以将子问题按规模排序，按由小至大的顺序进行求解**。当求解某个子问题时，它所依赖的那些更小的子问题都已求解完毕，结果已经保存。每个子问题只需求解一次，当我们求解它（也是第一次遇到它）时，它的所有前提子问题都已求解完成。

两种方法得到的算法具有相同的渐近运行时间，仅有的差异是在某些特殊情况下，自顶向下方法并未真正递归地考察所有可能的子问题。由于没有频繁的递归函数调用的开销，自底向上方法的时间复杂度函数通常具有更小的系数。


下面给出的是自顶向下 `CUT-ROD` 过程的伪代码，加入了备忘机制：
```cpp
MEMOIZED-CUT-ROD(p, n)
	let r[0...n] be a new array
	for i = 0 to n
		r[i] = -INF
	return MEMOIZED-CUT-ROD-AUX(p, n, r)

MEMOIZED-CUT-ROD-AUX(p, n, r)
	if r[n] >= 0
		return r[n]
	if n == 0
		q = 0
	else q = -INF
		for i = 1 to n
			q = max(q, p[i] + MEMOIZED-CUT-ROD-AUX(p, n - i, r))
	r[n] = q
	return q
```
这里，主过程 `MEMOIZED-CUT-ROD` 将辅助数组 $r[0\dots n]$ 的元素均初始化为 $-\infin$ ，这是一个常见的表述“未知值”的方法（已知的收益总是非负值），然后它会调用辅助过程 `MEMOIZED-CUT-ROD-AUX` ，这是最初的 `CUT-ROD` 引入备忘机制的版本。它首先检查所需值是否已知（第 $1$ 行），如果是则第 $2$ 行直接返回保存的值；否则，第 $3 \sim 7$ 行用通常方法计算所需值 $q$ ，第 $8$ 行将 $q$ 存入 $r[n]$ ，第 $9$ 行将其返回。

自底向上版本更为简单：
```cpp
BOTTOM-UP-CUT-ROD(p, n)
	let r[0...n] be a new array
	r[0] = 0
	for j = 1 to n
		q = -INF
		for i = 1 to j
			q = max(q, p[i] + r[j - i])
		r[j] = q
	return r[n]
```
自底向上版本 `BOTTOM-UP-CUT-ROD` 采用子问题的自然顺序：若 $i < j$ ，则规模为 $i$ 的子问题比规模为 $j$ 的子问题“更小”。因此，过程依次求解规模为 $j = 0, 1, \dots, n$ 的子问题。
- 过程 `BOTTOM-UP-CUT-ROD` 的第 $1$ 行创建一个新数组 $r[0\dots n]$ 来保存子问题的解，第 $2$ 行将 $r[0]$ 初始化为 $0$ ，因为长度为 $0$ 的钢条没有收益。
- 第 $3 \sim 6$ 行对 $j = 1, 2, \dots, n$ 按升序求解每个规模为 $j$ 的子问题。求解规模为 $j$ 的子问题的方法，与 `CUT-ROD` 采用的方法相同，只是现在直接访问数组元素 $r[j - i]$ 来获得规模为 $j - i$ 的子问题的解（第 $6$ 行），而不必进行递归调用。
- 第 $7$ 行将规模为 $j$ 的子问题的解存入 $r[j]$ 。最后，第 $8$ 行返回 $r[n]$ ，即最优解 $r_n$ 。

自底向上算法和自顶向下算法具有相同的渐近运行时间。过程 `BOTTOM-UP-CUT-ROD` 的主体是嵌套的双重循环，内层 for 循环（第 $5 \sim 6$ 行）的迭代次数构成一个等差数列，不难分析过程的运行时间为 $\Theta(n^2)$ 。自顶向下的 `MEMOIZED-CUT-ROD` 的运行时间也是 $\Theta(n^2)$ ，其分析略难一些：当求解一个之前已计算出结果的子问题时，递归调用会立即返回，即 `MEMOIZED-CUT-ROD` 对每个子问题只求解一次，而它要求解规模为 $0, 1, \dots, n$ 的（各个）子问题；为求解规模为 $n$ 的子问题，第 $6\sim 7$ 行的循环会迭代 $n$ 次；因此，`MEMOIZED-CUT-ROD` 进行的所有递归调用执行此 for 循环的迭代次数、也是一个等差数列，其和也是 $\Theta(n^2)$ ，与 `BOTTOM-UP-CUT-ROD` 内层 for 循环的迭代总次数一样（在这里实际上用到了某种形式的**聚合分析** `aggregate analysis` ，方法细节参考算导17.1节）。
## 子问题图
当思考一个动态规划问题时，我们应该弄清楚，所涉及的子问题及子问题之间的依赖关系。问题的**子问题图**准确地表达了这些信息。图15-4显示了 $n =4$ 时钢条切割问题的子问题图。它是一个有向图，每个顶点唯一地对应一个子问题。若求子问题 $x$ 的最优解时、需要直接用到子问题 $y$ 的最优解，那么在子问题图中就会有一条从子问题 $x$ 的顶点到子问题 $y$ 的顶点的有向边。例如，如果自顶向下过程在求解 $x$ 时，需要直接递归调用自身来求解 $y$ ，那么子问题图就包含从 $x$ 到 $y$ 的一条有向边。==我们可以将子问题图看做自顶向下递归调用树的“简化版”或“收缩版”，因为树中所有对应相同子问题的结点合并为图中的单一顶点，相关的所有边都从父结点指向子结点==。
![](https://img-blog.csdnimg.cn/476b90bae5da467b995c73f577c639cd.png)

自底向上的动态规划方法，处理子问题图中顶点的顺序为：对于一个给定的子问题 $x$ ，在求解它之前求解邻接至它的子问题 $y$（回忆算导B.4节，邻接关系不一定是对称的）。用（算导第22章）术语说，自底向上动态规划算法是按**逆拓扑序** `reverse topological sort` 或**反序的拓扑序** `topological sort of the transpose`（算导22.4节）来处理子问题图中的顶点。换句话说，对于任何子问题，直至它依赖的所有子问题均已求解完成，才会求解它。类似地，我们可以用**深度优先搜索** `depth-first search` 来描述（带备忘机制的）自顶向下动态规划算法处理子问题图的顺序（算导22.3节）。

**子问题图 $G = (V, E)$ 的规模，可以帮助我们确定动态规划算法的运行时间**。由于每个子问题只求解一次，因此算法运行时间等于每个子问题求解时间之和。通常，一个子问题的求解时间与子问题图中对应顶点的度（出射边的数目）成正比，而子问题的数目等于子问题图的顶点数。因此，通常情况下，动态规划算法的运行时间与顶点和边的数量呈线性关系。

## 重构解
前文给出的钢条切割问题的动态规划算法，返回最优解的收益值，但并未返回解本身（一个长度列表，给出切割后每段钢条的长度）。我们可以扩展动态规划算法，使之对每个子问题不仅保存最优收益值，还保存对应的切割方案。利用这些信息，我们就能输出最优解。

下面给出的是 `BOTTOM-UP-CUT-ROD` 的扩展版本，它对长度为 $j$ 的钢条不仅计算最大收益值 $r_j$ ，还保存最优解对应的第一段钢条的切割长度 $s_j$ ：
```cpp
EXTENDED-BOTTOM-UP-CUT-ROD(p, n)
	let r[0...n] and s[0...n] be new arrays
	r[0] = 0
	for j = 1 to n
		q = -INF
		for i = 1 to j
			if q < p[i] + r[j - i]
				q = p[i] + r[j - i]
				s[j] = i
		r[j] = q
	return r and s
```
此过程与 `BOTTOM-UP-CUT-ROD` 很相似，差别只是在第一行创建了数组 $s$ ，并在求解规模为 $j$ 的子问题时，将第一段钢条的最优切割长度 $i$ 保存在 $s[j]$ 中（第八行）。

下面的过程接受两个参数：价格表 $p$ 和钢条长度 $n$ ，然后调用 `EXTENDED-BOTTOM-UP-CUT-ROD(p, n)` 来计算切割下来的每段钢条的长度 $s[1\dots n]$ ，最后输出长度为 $n$ 的钢条的完整的最优切割方案：
```cpp
PRINT-CUT-ROD-SOLUTION(p, n)
	(r, s) = EXTENDED-BOTTOM-UP-CUT-ROD(p, n)
	while n > 0
		print s[n]
		n = n - s[n]
```
对于前文给出的钢条切割的实例，`EXTENDED-BOTTOM-UP-CUT-ROD(p, n)` 返回下面的数组：
![](https://img-blog.csdnimg.cn/a66312500ef5449d890b0907fa3b1c2a.png)
对此例调用 `PRINT-CUT-ROD-SOLUTION(p, 10)` 只会输出 $10$ ，但对 $n = 7$ 会输出最优方案 $r_7$ 切割出的两段钢条的长度 $1$ 和 $6$ 。

---
# 2. 矩阵链乘法
下个例子是求解矩阵链相乘问题的动态规划算法。给定一个 $n$ 个矩阵的序列（矩阵链）$\langle A_1, A_2, \dots, A_n\rangle$ ，我们希望计算它们的乘积：$$A_1A_2\dots A_n\tag{15.5}$$

为了计算表达式 $(15.5)$ ，我们可以先用括号明确计算次序，然后利用标准的矩阵相乘算法进行计算。**由于矩阵乘法满足结合律，因此任何加括号的方法都会得到相同的计算结果**。我们称有如下性质的矩阵乘积链为**完全括号化的** `fully parenthesized` ：它是一个单一矩阵，或者两个完全括号化的矩阵乘积链的积，且已外加括号。例如，如果矩阵链为 $\langle A_1, A_2, A_3, A_4\rangle$ ，则共有五种完全括号化的矩阵乘积链：
$$\begin{aligned}
&( A_1 (A_2 (A_3 A_4))) \\
&(A_1 (( A_2A_3) A_4)) \\
&((A_1 A_2) (A_3 A_4)) \\
& ((A_1 (A_2A_3) ) A_4)\\
& (((A_1A_2) A_3) A_4) \\
\end{aligned}$$

对矩阵链加括号的方式，会对乘积运算的代价产生巨大影响。我们先来分析两个矩阵相乘的代价。下面的伪码给出了两个矩阵相乘的标准算法，它是（算导4.2节）`SQUARE-MATRIX-MULTIPLY` 过程的推广。属性 $rows$ 和 $columns$ 是矩阵的行数和列数。
```cpp
MATRIX-MULTIPLY(A, B)
	if A.columns != B.rows
		error "incompatible dimensions"
	else let C be a new A.rows × B.columns matrix
		for i = 1 to A.rows
			for j = 1 to B.columns
				c[i][j] = 0
				for k = 1 to A.columns
					c[i][j] = c[i][j] + a[i][k] * b[k][j]
	return C
```
两个矩阵 $A, B$ 只有**相容** `compatible` ，即 $A$ 的列数等于 $B$ 的行数时，才能相乘。如果 $A$ 是 $p \times q$ 的矩阵，$B$ 是 $q \times r$ 的矩阵，那么乘积 $C$ 是 $p \times r$ 的矩阵。计算 $C$ 所需时间由第 $8$ 行的标量乘法的次数决定，即 $pqr$ 。下文中我们将用标量乘法的次数来表示计算代价。

我们以矩阵链 $\langle A_1, A_2, A_3 \rangle$ 相乘为例来说明，**不同的加括号方式会导致不同的计算代价**。假设三个矩阵的规模分别为 $10 \times 100, 100 \times 5, 5 \times 50$ 。
- 如果按 $(( A_1 A_2 ) A_3)$ 的顺序计算，为计算 $A_1 A_2$（规模 $10 \times 5$ ），需要做 $10 \cdot 100 \cdot 5 = 5000$ 次标量乘法，再与 $A_3$ 相乘又需要做 $10 \cdot 5 \cdot 50 = 2500$ 次标量乘法，共需 $7500$ 次标量乘法。
- 如果按 $( A_1 (A_2A_3))$ 的顺序，计算 $A_2A_3$（规模 $100 \times 50$ ），需要 $100 \cdot 5 \cdot 50  = 25000$ 次标量乘法，$A_1$ 再与之相乘又需 $10 \cdot 100 \cdot 50 = 50 000$ 次标量乘法，共需 $75 000$ 次标量乘法。

因此，按第一种顺序计算矩阵链乘积要比第二种顺序快 $10$ 倍。

**矩阵链乘法问题** `matrix-chain multiplication problem` 可描述如下：给定 $n$ 个矩阵的链 $\langle A_1, A_2, \dots, A_n \rangle$ ，矩阵 $A_i$ 的规模为 $p_{i-1} \times p_i\ (1 \le i \le n)$ ，求完全括号化方案，使得计算乘积 $A_1A_2\dots A_n$ 所需标量乘法次数最少。

注意，==求解矩阵链乘法问题并不是要真正进行矩阵相乘运算，我们的目标只是确定代价最低的计算顺序==。确定最优计算顺序所花费的时间 `the time invested in determining this optimal order` ，通常要比随后真正进行矩阵相乘所节省的时间 `more than paid for by the time saved later on when actually performing the matrix multiplications`（例如仅进行 $7500$ 次标量乘法、而不是 $75000$ 次）要多。
## 计算括号化方案的数量
在用动态规划求解矩阵链乘法问题之前，我们先来说服自己——穷举所有可能的括号化方案、不会产生一个高效的算法。对于一个 $n$ 个矩阵的链，令 $P(n)$ 表示可供选择的括号化方案的数量。当 $n =1$ 时，由于只有一个矩阵，因此只有一种完全括号化方案。==当 $n \ge 2$ 时，完全括号化的矩阵乘积、可描述为两个完全括号化的部分积相乘的形式，而两个部分积的划分点在第 $k$ 个矩阵和第 $k + 1$ 个矩阵之间，$k$ 为 $1, 2, \dots, n - 1$ 中的任意一个值==。因此，我们可得如下递归公式：
$$P(n) = \begin{cases} 
1 \qquad &如果n=1 \\
\displaystyle \sum^{n-1}_{k=1} P(k) P(n-k) &如果n\ge 2 \end{cases} \tag{15.6}$$

（算导思考题12-4）要求证明，一个相似的递归公式产生的序列为**卡特兰数** `Catalan numbers` ，这个序列的增长速度为 $\Omega \bigg(\dfrac{ 4^n } {n^{3/2} }\bigg)$ 。（算导练习15.2-3）要求证明，递归公式 $(15.6)$ 的结果为 $\Omega(2^n)$ 。因此，括号化方案的数量与 $n$ 呈指数关系，通过暴力搜索穷举所有可能的括号化方案来寻找最优方案，是一个糟糕的策略。

## 应用动态规划方法
下面用动态规划来求解矩阵链的最优括号化方案，还是按照开头提出的四个步骤进行：
1. 刻画一个最优解的结构特征。
2. 递归地定义最优解的值。
3. 计算最优解的值，通常采用自底向上的方法。
4. 利用计算出的信息，构造一个最优解。

我们按顺序进行这几个步骤，清楚地展示针对本问题每个步骤应如何做。

## 步骤1：最优括号化方案的结构特征
动态规划的第一步是寻找最优子结构，然后就可以利用这种子结构，从子问题的最优解构造出原问题的最优解。在矩阵链乘法问题中，此步骤的做法如下所述。为方便起见，我们用符号 $A_{i\dots j}\ (i \le j)$ 表示 $A_i A_{i+1} \dots A_j$ 乘积的结果矩阵。可以看出，==如果问题是非平凡的，即 $i < j$ ，那么为了对 $A_i A_{i+1} \dots A_j$ 进行括号化，我们就必须在某个 $A_k$ 和 $A_{k+1}$ 之间将矩阵链划分开（ $k$ 为 $i \le k < j$ 之间的整数）==。也就是说，对某个整数 $k$ ，我们首先计算矩阵 $A_{i\dots k}$ 和 $A_{k + 1\dots j}$ ，然后再计算它们的乘积得到最终结果 $A_{i\dots j}$ 。**此方案的计算代价，等于矩阵 $A_{i\dots k}$ 的计算代价、加上矩阵 $A_{k+1 \dots j}$ 的计算代价，再加上两者相乘的计算代价**。

下面我们给出本问题的最优子结构。假设 $A_i A_{i+1} \dots A_j$ 的最优括号化方案的分割点在 $A_k$ 和 $A_{k+1}$ 之间。那么，==继续对“前缀”子链 $A_iA_{i+1} \dots A_k$ 进行括号化时，我们应该直接采用独立求解它时所得的最优方案==。这样做的原因是什么呢？如果不采用独立求解 $A_i A_{i+1} \dots A_k$ 所得的最优方案来对它进行括号化，那么可以将此最优解代入 $A_i A_{i+1} \dots A_j$ 的最优解中，代替原来对子链 $A_i A_{i+1} \dots A_k$ 进行括号化的方案（比 $A_i A_{i+1} \dots A_k$ 最优解的代价更高），显然这样得到的解比 $A_i A_{i+1} \dots A_j$ 原来的“最优解”代价更低：产生矛盾。对子链 $A_{k+1}A_{k+2} \dots A_j$ ，我们有相似的结论：==在原问题 $A_i A_{i+1} \dots A_j$ 的最优括号化方案中，对子链 $A_{k+1}A_{k+2} \dots A_j$ 进行括号化的方法，就是它自身的最优括号化方案==。

现在我们展示了，如何利用最优子结构性质、从子问题的最优解构造原问题的最优解。我们已经看到，**一个非平凡的矩阵链乘法问题实例的任何解都需要划分链**，而任何最优解都是由子问题实例的最优解构成的。因此，为了构造一个矩阵链乘法问题实例的最优解，我们可以将问题划分为两个子问题 $(A_i A_{i+1} \dots A_k$ 和 $A_{k+1} A_{k+2} \dots A_j$ 的最优括号化问题），求出子问题实例的最优解，然后将子问题的最优解组合起来。我们必须保证，**在确定分割点时，已经考察了所有可能的划分点，这样就可以保证不会遗漏解**。

## 步骤2：一个递归求解方案
下面用子问题的最优解、来递归地定义原问题最优解的**代价**。对于矩阵链乘法问题，我们可以将「对所有 $1 \le i \le j \le n$ 确定 $A_i A_{i+1} \dots A_j$ 的最小代价括号化方案」作为子问题，令 $m[i, j]$ 表示计算矩阵 $A_{i \dots j}$ 所需标量乘法次数的最小值，那么原问题的最优解——计算 $A_{1\dots n}$ 所需的最低代价就是 $m[1, n]$ 。

我们可以递归定义 $m[i, j]$ 如下。
- 对于 $i = j$ 时的平凡问题，矩阵链只包含唯一的矩阵 $A_{i\dots i} = A_i$ 。因此不需要做任何标量乘法运算。所以对所有 $i = 1, 2, \dots , n$ ，$m[i, i] = 0$ 。
- 若 $i < j$ ，我们利用步骤1中得到的最优子结构来计算 $m[i, j]$ 。我们假设 $A_i A_{i+1} \dots A_j$ 的最优括号化方案的分割点在矩阵 $A_k$ 和 $A_{k+1}$ 之间，其中 $i \le k < j$ 。那么，$m[i, j]$ 就等于计算 $A_{i\dots k}$ 和 $A_{k+1\dots j}$ 的代价加上两者相乘的代价的最小值。==由于矩阵 $A_i$ 的大小为 $p_{i-1} \times p_i$ ，易知 $A_{i\dots k}$ 与 $A_{k+1 \dots j}$ 相乘的代价为 $p_{i-1}p_kp_j$ 次标量乘法运算==。因此我们得到：$$m[i,j] = m[i,k]+m[k+1,j]+p_{i-1}p_kp_j$$
	此递归公式假定最优分割点 $k$ 是已知的，但实际上我们是不知道的。不过，$k$ 只有 $j -i$ 种可能的取值，即 $k = i, i+1, \dots, j-1$ 。由于最优分割点必在其中，我们只需检查所有可能情况，找到最优者即可。因此，$A_iA_{i+1}\dots A_j$ 最小代价括号化方案的递归求解公式变为：
	$$m[i,j] = \begin{cases}
	0 \quad &如果i=j \\
	\displaystyle 
	\min_{i \le k < j} \{ m[i, k] + m[k+1, j] + p_{i-1}p_kp_j \} \quad&如果i<j \end{cases} \tag{15.7}$$

$m[i,j]$ 的值给出了子问题最优解的代价，但它并未提供足够的信息来构造最优解。为此，我们用 $s[i,j]$ 保存 $A_iA_{i+1} \dots A_j$ 最优括号化方案的分割点位置 $k$ ，即使得 $m[i, j] = m[i, k] +m[k+1, j] + p_{i-1} p_k p_j$ 成立的 $k$ 值。
## 步骤3：计算最优代价
现在，我们可以很容易地基于递归公式 $(15.7)$ 写成一个递归算法，来计算 $A_1A_2\dots A_n$ 相乘的最小代价 $m[1, n]$ 。像我们在钢条切割问题一节中看到的，以及即将（算导15.3节中）看到的那样，此递归算法是指数时间的，并不比检查所有括号化方案的暴力搜索方法更好。

注意到，我们需要求解的不同子问题的数目是相对较少的：每对满足 $1\le i \le j \le n$ 的 $i$ 和 $j$ 对应一个唯一的子问题，共有 $\begin{pmatrix} n \\ 2 \end{pmatrix} + n = \Theta(n^2)$ 个。递归算法会在递归调用树的不同分支中多次遇到同一个子问题。这种重叠子问题的性质，是应用动态规划的另一个标识（第一个标识是最优子结构）。

我们采用自底向上表格法，代替基于公式 $(15.7)$ 的递归算法来计算最优代价（算导15.3节给出对应的带备忘的自顶向下方法）。下面给出的过程 `MATRIX-CHAIN-ORDER` 实现了自底向上表格法。此过程假定矩阵 $A_i$ 的规模为 $p_{i-1} \times p_i\ (i = 1, 2, \dots n)$ 。它的输入是一个序列 $p = \langle p_0, p_1, \dots, p_n \rangle$ ，其长度为 $p.length = n+1$ 。过程用一个辅助表 $m[1\dots n, 1\dots n]$ 来保存代价 $m[i, j]$ ，用另一个辅助表 $s[1\dots n - 1, 2\dots n]$ 记录最优值 $m[i, j]$ 对应的分割点 $k$ 。我们就可以利用表 $s$ 构造最优解。

为了实现自底向上方法，我们必须确定计算 $m[i, j]$ 时需要访问哪些其他表项。==公式 $(15.7)$ 显示，$j-i+1$ 个矩阵相乘链的最优计算代价 $m[i,j]$ 只依赖于那些少于 $j-i+1$ 个矩阵相乘链的最优计算代价。即，对 $k=i,i+1, \dots , j - 1$ ，矩阵 $A_{i\dots k}$ 是 $k - i + 1 < j - i + 1$ 个矩阵的积，矩阵 $A_{k+1 \dots j}$ 是 $j - k < j - i + 1$ 个矩阵的积==。因此，算法应该按长度递增的顺序，求解矩阵链括号化问题，并按对应的顺序填写表 $m$ 。对矩阵链 $A_iA_{i+1} \dots A_j$ 最优括号化的子问题，我们认为其规模为链的长度 $j - i +1$ 。
```cpp
MATRIX-CHAIN-ORDER(p)
	n = p.length - 1
	let m[1...n, 1...n] and s[1...n-1, 2...n] be new tables
	for i = 1 to n
		m[i, i] = 0
	for l = 2 to n // l is the chain length
		for i = 1 to n - l + 1
			j = i + l - 1
			m[i, j] = INF
			for k = i to j - 1
				q = m[i, k] + m[k + 1, j] + p[i-1]p[k]p[j]
				if q < m[i, j]
					m[i, j] = q
					s[i, j] = k
	return m and s
```
算法首先在第 $3 \sim 4$ 行对所有 $i = 1, 2, \dots, n$ ，计算 $m[i, i] = 0$（长度为 $1$ 的链的最小计算代价）。接着在第 $5 \sim 13$ 行 for 循环的第一个循环步中，利用递归公式 $(15.7)$ 对所有 $i = 1, 2, \dots, n - 1$ ，计算 $m[i, i+1]$（长度 $l = 2$ 的链的最小计算代价）。在第二个循环步中，算法对所有 $i = 1, 2, \dots, n - 2$ ，计算 $m[i, i+2]$（长度 $l = 3$ 的链的最小计算代价），依次类推。**在每个循环步中，第 $10 \sim 13$ 行计算代价 $m[i, j]$ 时，仅依赖于已经计算出的表项 $m[i, k]$ 和 $m[k+1, j]$** 。

图15-5展示了对一个长度为 $6$ 的矩阵链执行此算法的过程。==由于我们定义 $m[i, j]$ 仅在 $i \le j$ 时有意义，因此表 $m$ 只使用主对角线之上的部分==。图中的表是经过旋转的，主对角线已经旋转到了水平方向。矩阵链的规模列在了图的下方。在这种布局中，我们可以看到==子矩阵链 $A_iA_{i+1} \dots A_j$ 相乘的代价 $m[i, j]$ ，恰好位于「始于 $A_i$ 的东北至西南方向的直线」与「始于 $A_j$ 的西北至东南方向的直线」的交点上==。表中同一行中的表项，都对应长度相同的矩阵链。`MATRIX-CHAIN-ORDER` 按自下而上、自左而右的顺序计算所有行。当计算表项 $m[i, j]$ 时，会用到乘积 $p_{i-1} p_k p_j\ (k = i, i +1, \dots, j-1)$ ，以及 $m[i,j]$ 西南方向和东南方向的所有表项。
![](https://img-blog.csdnimg.cn/bee8d731cf3d4beaa835bb8e3cdaf4f7.png)
简单分析 `MATRIX-CHAIN-ORDER` 的嵌套循环结构，可以看得算法的运行时间为 $O(n^3)$ 。循环嵌套的深度为三层，每层的循环变量 $(l, i, k)$ 最多取 $n - 1$ 个值。（算导练习15.2-5）要求证明此算法的运行时间实际上是 $\Omega(n^3)$ 。算法还需要 $\Theta(n^2)$ 的内存空间来保存表 $m, s$ 。因此，`MATRIX-CHAIN-ORDER` 比起穷举所有可能的括号化方案来寻找最优解的指数阶算法，要高效地多。
## 步骤4：构造最优解
虽然 `MATRIX-CHAIN-ORDER` 求出了计算矩阵链乘积所需的最少标量乘法运算次数，但它并未直接指出，如何进行这种最优代价的矩阵链乘法计算。表 $s[1\dots n - 1, 2\dots n]$ 记录了构造最优解所需的信息。==每个表项 $s[i, j]$ 记录了一个 $k$ 值，指出 $A_i A_{i+1} \dots A_j$ 的最优括号化方案的分割点应在 $A_k$ 和 $A_{k+1}$ 之间==。因此，我们知道 ==$A_{1\dots n}$ 的最优计算方案中、最后一次矩阵乘法运算应该是 $A_{ 1 \dots s[1, n] } A_{s[1, n] + 1\dots n}$== 。我们可以用相同的方法，递归地求出更早的矩阵乘法的具体计算过程，因为 $s[1, s[1, n]]$ 指出了计算 $A_{1\dots s[1, n]}$ 时应进行的最后一次矩阵乘法运算；$s[s[1, n] + 1, n]$ 指出了计算 $A_{s[1, n] + 1\dots n}$ 时应进行的最后一次矩阵乘法运算。

下面给出的递归方程，可以输出 $\langle A_i, A_{i+1} , \dots, A_j \rangle$ 的最优括号化方案，其输入为 `MATRIX-CHAIN-ORDER` 得到的表 $s$ 及下标 $i$ 和 $j$ 。调用 `PRINT-OPTIMAL-PARENS(s, 1, n)` 即可输出 $\langle A_1, A_2, \dots, A_n \rangle$ 的最优括号化方案。 
```cpp
PRINT-OPTIMAL-PARENS(s, i, j)
	if i == j
		print "A"
	else print("(")
		PRINT-OPTIMAL-PARENS(s, i, s[i, j])
		PRINT-OPTIMAL-PARENS(s, s[i, j] + 1, j)
		print(")")
```
对图15-5中的例子，调用 `PRINT-OPTIMAL-PARENS(s, 1, 6)` 输出括号化方案：$$(( A_1 (A_2 A_3)) ((A_4 A_5) A_6))$$

---
# 3. 动态规划原理
虽然已经用动态规划解决了两个问题，但可能还是弄不清，应该在何时使用动态规划。从工程角度看，什么情况下应该寻求用动态规划求解问题呢？本节中我们关注，适合应用动态规划求解的最优化问题应该具备的两个要素：最优子结构和重叠子问题。我们还会再次讨论备忘方法，更深入地讨论在自顶向下方法中、如何借助备忘机制来充分利用重叠子问题特性。
## 最优子结构
用动态规划求解最优化问题的第一步就是，刻画最优解的结构。如前所述，==如果一个问题的最优解包含其子问题的最优解，我们就称此问题具有**最优子结构**性质==。因此，某个问题是否适合应用动态规划算法，它是否具有最优子结构性质是一个**好线索**（当然，具有最优子结构性质，也可能意味着适合应用贪心策略，参见算导第16章）。==使用动态规划时，我们用子问题的最优解来构造原问题的最优解。因此，我们必须小心确保考察了最优解中用到的所有子问题==。

到目前为止介绍的两个问题，都具有最优子结构性质。（算导15.1节中）我们观察到，长度为 $n$ 的钢条的最优切割方案，是由第一次切割后（如果最优切割方案需要进行切割）得到的两段钢条的最优切割方案组成的。（算导15.2节中）我们看到 $A_i A_{i+1} \dots A_j$ 的最优括号化方案首先在 $A_k$ 和 $A_{k+1}$ 之间进行划分，然后对 $A_i A_{i+1} \dots A_k$ 和 $A_{k+1} A_{k+2} \dots A_j$ 继续进行最优括号化。

我们发现，在发掘最优子结构性质的过程中，实际上遵循了如下的通用模式：
1. 证明**问题最优解的第一个组成部分是做出一个选择**，例如选择钢条第一次切割位置，选择矩阵链的划分位置等。**做出这次选择会产生一个或多个待解的子问题**。
2. 对于一个给定问题，在其可能的第一步选择中，**我们假定已经知道哪种选择才会得到最优解**。我们现在并不关心这种选择具体是如何得到的，只是假定已经知道了这种选择。
3. 给定可获得最优解的选择后，**我们确定这次选择会产生哪些子问题**，以及如何最好地刻画子问题空间。
4. 利用**剪切-粘贴** `cut-and-paste` 技术证明：**在问题的最优解中使用的子问题的解本身必须是最优的**。证明这一点是利用反证法：==假定子问题的解不是其自身的最优解，那么我们就可以从原问题的解中“剪切”掉这些子问题的非最优解，将最优解“粘贴”进去，从而得到原问题的一个更优的解，这与「最初的解是原问题最优解」的前提假设矛盾==。如果原问题的最优解包含多个子问题，通常它们都很相似，我们可以将针对一个子问题的“剪切-粘贴”论证方法稍加修改，用于其他子问题。

一个刻画子问题空间 `the space of subproblems` 的好经验是：保持子问题空间尽可能简单，只在必要时才扩展它。例如，我们在求解钢条切割问题时，子问题空间中包括的问题为：对每个值 $i$ ，长度为 $i$ 的钢条的最优切割问题。这个子问题空间很有效，因此我们不必尝试更一般性（从而也更大）的子问题空间。

与之相对的，假定我们试图限制矩阵链 $A_1 A_2 \dots A_j$ 乘法问题的子问题空间。如前所述，最优括号化方案必然在某个位置 $k\ (1 \le k < j)$ 处，即 $A_k$ 和 $A_{k+1}$ 之间对矩阵链进行划分。除非我们能保证 $k$ 永远等于 $j - 1$ ，否则我们会发现我们得到两个形如 $A_1 A_2 \dots A_k$ 和 $A_{k+1} A_{k+2} \dots A_j$ 的子问题，而后者的形式与 $A_1 A_2 \dots A_j$ 是不同的。因此，==对矩阵链乘法问题，我们必须允许子问题在“两端”都可以变化，即允许子问题 $A_iA_{i+1} \dots A_j$ 中 $i, j$ 都可变==。

对于不同问题领域，最优子结构的变化体现在两个方面：
1. 原问题的最优解中涉及多少个子问题，以及
2. 在确定最优解使用哪些子问题时，我们需要考察多少种选择。

在钢条切割问题中，长度为 $n$ 的钢条的最优切割方案，**仅仅使用一个子问题**（长度为 $n - i$ 的钢条的最优切割），但我们**必须考察 $i$ 的 $n$ 种不同取值**，来确定哪个会产生最优解。在 $A_i A_{i+1} \dots A_j$ 的矩阵链乘法问题中，**最优解使用两个子问题，我们需要考察 $j -i$ 种情况**。对于给定的矩阵链划分位置——矩阵 $A_k$ ，我们需要**求解两个子问题**—— $A_i A_{i+1}\dots A_k$ 和 $A_{k+1} A_{k+2} \dots A_j$ 的括号化方案——而且两个子问题都必须求解最优方案。一旦我们确定了子问题的最优解，我们就从 $j- i$ 个候选值中选出最优的 $k$ 下标。

我们可以用「子问题的总数」和「每个子问题需要考察多少种选择」这两个因素的乘积，来粗略分析动态规划算法的运行时间。
- 对于钢条切割问题，共有 $\Theta(n)$ 个子问题，每个子问题最多需要考察 $n$ 种选择，因此运行时间为 $O(n^2)$ 。
- 矩阵链乘法问题共有 $\Theta(n^2)$ 个子问题，每个子问题最多需要考察 $n - 1$ 种选择，因此运行时间为 $O(n^3)$（算导练习15.2-5要求证明运行时间实际为 $\Theta(n^3)$ ）。

==子问题图也可用来做同样的分析。图中每个顶点对应一个子问题，而需要考察的选择对应关联至子问题顶点的边==。回忆一下，钢条切割问题的子问题图有 $n$ 个顶点，每个顶点最多 $n$ 条边，因此运行时间为 $O(n^2)$ 。对于矩阵链乘法问题，子问题图会有 $\Theta(n^2)$ 个顶点，而每个顶点最多有 $n - 1$ 条边，因此共有 $O(n^3)$ 个顶点和边。

在动态规划中，我们通常自底向上地使用最优子结构。也就是说，**首先求得子问题的最优解，然后求原问题的最优解**。在求解原问题过程中，我们需要在涉及的子问题中做出选择，选出能得到原问题最优解的子问题。**原问题最优解的代价，通常就是子问题最优解的代价、再加上由此次选择直接产生的代价**。例如，对于钢条切割问题，我们首先求解子问题，确定长度为 $i = 0,1, \dots, n - 1$ 的钢条的最优切割方案。此次选择本身所产生的代价，就是公式 $(15.2)$ 中的 $p_i$ 。在矩阵链乘法问题中，我们先确定子矩阵链 $A_i A_{i+1} \dots A_j$ 的最优括号化方案，然后选择划分位置 $A_k$ ，选择本身所产生的代价就是 $p_{i-1}p_k p_j$ 。

（算导第16章介绍贪心算法），它与动态规划有很多相似之处。特别是，能够应用贪心算法的问题也必须具有最优子结构性质。贪心算法和动态规划最大的不同在于，它并不是首先寻找子问题的最优解，然后在其中进行选择，而是==首先做出一次“贪心”选择——在当时（局部）看来最优的选择——然后求解选出的子问题，从而不必费心求解所有可能相关的子问题==。令人惊讶的是，在某些情况下这一策略也能得到最优解！

## 一些微妙之处
在尝试使用动态规划方法时要小心，要注意问题是否具有最优子结构性质。考虑下面两个问题，其中都是给定一个有向图 $G=(V, E)$ 和两个顶点 $u, v \in V$ 。
- **无权** `unweighted` **最短路径**：找到一条从 $u$ 到 $v$ 的**边数最少的路径**。这条路径**必然是简单路径**，因为如果路径中包含环，将环去掉显然会减少边的数量。
- **无权最长路径**：找到一条从 $u$ 到 $v$ 的**边数最多的简单路径**。这里必须加上简单路径的要求，因为我们可以不停地沿着环走，从而得到任意长的路径。

下面证明，**无权最短路径问题具有最优子结构性质**。假设 $u\ne v$ ，则问题是非凡的。这样从 $u$ 到 $v$ 的任意路径 $p$ 都必须包含一个中间顶点，比如 $w$（注意，$w$ 可能是 $u$ 或 $v$ ）。因此，我们可以将路径 $u\stackrel{p} {\leadsto} v$ 分解为两条子路径 $u \stackrel{p_1} {\leadsto} w \stackrel{p_2} {\leadsto} v$ 。显然，$p$ 的边数等于 $p_1$ 的边数加上 $p_2$ 的边数。
- 于是我们断言：**如果 $p$ 是从 $u$ 到 $v$ 的最优（即最短）路径，那么 $p_1$ 必须是从 $u$ 到 $w$ 的最短路径**。为什么呢？我们可以用“剪切-粘贴”方法来证明：如果存在另一条从 $u$ 到 $w$ 的路径 $p_1'$ ，其边数比 $p_1$ 少，那么可以剪切掉 $p_1$ ，将 $p_1'$ 粘贴上，构造出一条比 $p$ 边数更少的路径 $u \stackrel{p_1'} {\leadsto} w \stackrel{p_2} {\leadsto} v$ ，与 $p$ 最优的假设矛盾。
- 对称地，**$p_2$ 必须是从 $w$ 到 $v$ 的最短路径**。

因此，==我们可以通过考察所有中间顶点 $w$ 来求 $u$ 到 $v$ 的最短路径，对每个中间顶点 $w$ ，求 $u$ 到 $w$ 和 $w$ 到 $v$ 的最短路径，然后选择两条路径之和最短的顶点 $w$== 。（算导25.2节中）我们将使用这种最优子结构的一个变形来求解「加权有向图的所有顶点对间最短路径」问题。

你可能已经倾向于假设，无权最长简单路径问题也具有最优子结构性质。毕竟，如果我们将最长简单路径 $u \stackrel{p} {\leadsto} v$ 分解为子路径 $u \stackrel{p_1} {\leadsto} w \stackrel{p_2}{\leadsto} v$ ，难道 $p_1$ 不应该是从 $u$ 到 $w$ 的最长简单路径，$p_2$ 不应该是从 $w$ 到 $v$ 的最长简单路径吗？但答案是否定的！图15-6给出了一个例子。考虑路径 $q \to r \to t$ ，它是从 $q$ 到 $t$ 的最长简单路径。$q \to r$ 是从 $q$ 到 $r$ 的最长简单路径吗？不是的，$q \to s \to t \to r$ 是一条更长的简单路径。$r\to t$ 是从 $r$ 到 $t$ 的最长简单路径吗？同样不是，$r \to q \to s \to t$ 比他更长。
![](https://img-blog.csdnimg.cn/b079bec86a7b4217b9321e9552907121.png)

这个例子说明，**最长简单路径问题不仅缺乏最优子结构性质，由子问题的解组合出的甚至都不是原问题的“合法”解**。如果我们组合最长简单路径 $q \to s \to t \to r$ 和 $r \to q \to s \to t$ ，得到的是路径 $q\to s \to t \to r \to q \to s \to t$ ，并不是简单路径。的确，无权最长简单路径问题看起来不像有任何形式的最优子结构。对此问题尚未找到有效的动态规划算法。实际上，此问题是NP完全的（算导第34章），这意味着我们不太可能找到多项式时间的求解方法。

为什么最长简单路径问题的子结构与最短路径有这么大的差别？原因在于，虽然最长路径问题和最短路径问题的解都用到了两个子问题，但两个最长简单路径子问题是相关的，而两个最短路径子问题是**无关的** `independent` 。这里==子问题无关的含义是，同一个原问题的一个子问题的解不影响另一个子问题的解==。对图15-6中的例子，求 $q$ 到 $t$ 的最长简单路径可以分解为两个子问题：求 $q$ 到 $r$ 的最长简单路径和 $r$ 到 $t$ 的最长简单路径。对于前者，我们选择路径 $q \to s \to t \to r$ ，其中用到了顶点 $s, t$ 。由于这两个子问题的解的组合必须产生一个简单路径，因此我们在求解第二个子问题时、就不能再用这两个顶点了。但如果在求解第二个子问题上不允许使用顶点 $t$ ，就根本无法进行下去了，因为 $t$ 是原问题解的路径终点，是必须用到的，还不像子问题解的“接合”顶点 $r$ 那样可以不用。这样，由于一个子问题的解使用了顶点 $s, t$ ，在另一个子问题的解中就不能再使用它们，但其中至少一个顶点在求解第二个子问题时又必须用到，而获得最优解则两个都要用到。因此，我们说两个子问题是相关的。换个角度看，==我们面临的困境就是：求解一个子问题时用到了某些资源（本例中是顶点），导致这些资源在求解其他子问题时不可用==。

那么，求解最短路径的子问题间又为什么是无关的呢？根本原因在于，**最短路径子问题间是不共享资源的**。我们可以断言：==如果一个顶点 $w$ 出现在 $u$ 到 $v$ 的最短路径上，那么可以通过拼接任意的最短路径 $u \stackrel{p_1} {\leadsto} w$ 和任意的最短路径 $w \stackrel{p_2} {\leadsto} v$ 来构造 $u$ 到 $v$ 的最短路径==。我们可以保证，**除了 $w$ ，其他任何顶点都不会同时出现在 $p_1$ 和 $p_2$ 上**。原因何在？假定某个顶点 $x \ne w$ 同时出现在路径 $p_1$ 和 $p_2$ 上，我们就可以把 $p_1$ 分解为 $u \stackrel{p_{ux}} {\leadsto} x \leadsto w$ ，把 $p_2$ 分解为 $w \leadsto x \stackrel{p_{xv}} {\leadsto} v$ 。根据最优子结构性质，路径 $p$ 的边数等于 $p_1$ 和 $p_2$ 边数之和，假定为 $e$ 。接下来我们构造一条 $u$ 到 $v$ 的路径 $p' = u \stackrel{p_{ux}}{\leadsto} x \stackrel {p_{xv} } {\leadsto} v$ 。由于已经删掉 $x$ 到 $w$ 和 $w$ 到 $x$ 的路径，这两条路径每条至少包含一条边，因此 $p'$ 最多包含 $e - 2$ 条边，与 $p$ 为最短路径的假设矛盾。因此，我们可以保证**最短路径问题的子问题间是无关的**。

（算导15.1、15.2节讨论的）前面两个问题都具有子问题无关性质。
- 在矩阵链乘法中，子问题为子链 $A_i A_{i+1} \dots A_k$ 和 $A_{k+1} A_{k+2} \dots A_j$ 的乘法问题。子链是互不相交的，因此任何矩阵都不会同时包含在两条子链中。
- 在钢条切割问题中，为了确定长度为 $n$ 的钢条的最优切割方案，我们考察所有长度为 $i\ (i = 0, 1, \dots, n - 1)$ 的钢条的最优切割方案。由于长度为 $n$ 的问题的最优解只包含一个子问题的解（我们切掉了第一段），子问题无关性显然是可以保证的。

## 重叠子问题
适合用动态规划求解的最优化问题，应该具备的第二个性质是**子问题空间必须足够“小”**。即问题的递归算法会反复地求解相同的子问题，而不是一直生成新的子问题。一般来说，不同子问题的总数是输入规模的多项式函数为好。如果递归算法反复求解相同的子问题，我们就称最优化问题具有**重叠子问题** `overlapping subproblems` 性质。
> 一个问题是否适合用动态规划求解，同时依赖于子问题的无关性和重叠性，这看起来很奇怪。虽然这两个要求听起来似乎是矛盾的，但它们描述的是不同的概念，~~而不是同一个坐标轴上的两个点~~。两个子问题如果不共享资源，它们就是独立的；而重叠是指两个子问题实际上是同一个子问题，只是作为不同问题的子问题出现而已。

与之相对的，**适合用分治方法求解的问题，通常在递归的每一步都生成全新的子问题**。==动态规划算法通常这样利用重叠子问题性质：对每个子问题求解一次，将解存入一个表中，当再次需要这个子问题时直接查表，每次查表的代价为常量时间==。

（算导15.1节中）简单分析了，钢条切割问题的递归算法、是如何通过指数次的递归调用来求解小的子问题。而我们的动态规划算法，将运行时间从递归算法的指数阶降为平方阶。

为了详细说明重叠子问题性质，我们重新考察矩阵链乘法问题。再看图15-5，发现 `MATRIX-CHAIN-ORDER` 在求解高层的子问题时，会反复查找低层上子问题的解。例如，算法会访问表项 $m[3, 4]$ 四次：分别在计算 $m[2, 4],\ m[1, 4],\ m[3, 5],\ m[3, 6]$ 时。如果我们每次都重新计算 $m[3, 4]$ ，而不是简单地查表，那么运行时间会急剧上升。为了更好地理解，请看下面的递归过程，它计算矩阵链乘法 $A_{i \dots j} = A_i A_{i+1} \dots A_j$ 所需最少标量乘法运算次数 $m[i, j]$ ，而计算过程是低效的。这个过程直接基于递归式 $(15.7)$ 。
![](https://img-blog.csdnimg.cn/8f03ccdf01284ea2a6a895243783a8b9.png)

图15-7显示了调用 `RECURSIVE-MATRIX-CHAIN(p, 1, 4)` 产生的递归调用树。每个结点都标记出了参数 $i$ 和 $j$ ，可以看到某些 $i, j$ 值对出现了许多次。
![](https://img-blog.csdnimg.cn/54872e51f09c43c290c34b7acffb79d7.png)

实际上，我们可以证明此过程计算 $m[1, n]$ 的时间至少是 $n$ 的指数函数。令 $T(n)$ 表示 `RECURSIVE-MATRIX-CHAIN` 计算 $n$ 个矩阵的矩阵链的最优括号化方案花费的时间。由于第 $1 \sim 2$ 行和第 $6 \sim 7$ 行至少各花费单位时间，第 $5$ 行的加法运算也是如此，因此我们得到如下递归式：$$\begin{aligned}
&T(n) \ge 1 \\
&T(n) \ge 1 + \sum_{k=1}^{n-1}( T(k)+ T(n-k) + 1), \ n > 1
\end{aligned}$$

注意，对 $i = 1, 2, \dots, n - 1$ ，每一项 $T(i)$ 在公式中以 $T(k)$ 的形式出现了一次，还以 $T(n - k)$ 的形式出现了一次，而求和项中累加了 $n - 1$ 个 $1$ ，在求和项之前还加了 $1$ ，因此公式可改写为：$$T(n)\ge 2 \sum^{n-1}_{i=1} T(i) + n \tag{15.8}$$

下面用代入法证明 $T(n) = \Omega(2^n)$ 。特别地，我们将证明，对所有 $n \ge 1$ ，$T(n) \ge 2^{n-1}$ 都成立。基本情况很简单，因为 $T(1) \ge 1 =2^0$ ，利用数学归纳法，对 $n \ge 2$ 我们有：
$$\begin{aligned}
T(n) &\ge 2 \sum^{n-1}_{i=1} 2^{i-1} + n = 2\sum^{ n-2}_{i=0} 2^i +n = 2(2^{n-1} - 1) + n\quad 由公式(A.5) \\
&= 2^n - 2 + n \ge 2^{n-1}
\end{aligned}$$

因此，调用 `RECURSIVE-MATRIX-CHAIN(p, 1, n)` 所做的总工作量至少是 $n$ 的指数函数。

将此自顶向下的递归算法（无备忘）与自底向上的动态规划算法进行比较，后者要高效得多，因为它利用了重叠子问题性质。矩阵链乘法问题只有 $\Theta(n^2)$ 个不同的子问题，动态规划算法对每个子问题只求解一次。而递归算法则相反，对每个子问题，每当在递归树中（递归调用时）遇到它，都要重新计算一次。凡是一个问题的自然递归算法的递归调用树中，反复出现相同的子问题，而不同子问题的总数很少时，动态规划方法都能提高（有时还是极大地提高）效率。

## 重构最优解
从实际考虑，我们通常将每个子问题所做的选择存在一个表中，这样就不必根据代价值来重构这些信息。

对矩阵链乘法问题，利用表 $s[i, j]$ ，我们重构最优解时可以节省很多空间。假定我们没有维护 $s[i, j]$ 表，只是在表 $m[i, j]$ 中记录了子问题的最优代价。当我们确定 $A_i A_{i+1} \dots A_j$ 的最优括号化方案用到了哪些子问题时，就需要检查所有 $j - i$ 种可能，而 $j - i$ 并不是一个常数。因此，对一个给定问题的最优解，重构它用到了哪些子问题就需花费 $\Theta(j - i)= \omega(1)$ 的时间。而通过在 $s[i, j]$ 中保存 $A_i A_{i+1} \dots A_j$ 的划分位置，我们重构每次选择只需 $O(1)$ 时间。
## 备忘
如在钢条切割问题中所见，我们可以保持自顶向下策略，同时达到与自底向上动态规划相似的效率。思路就是对自然但低效的递归算法加入备忘机制。与自底向上方法一样，我们维护一个表记录子问题的解，但仍然保持递归算法的控制流程。

带备忘的递归算法，为每个子问题维护一个表项来保存它的解。每个表项的初值设为一个特殊值，表示尚未填入子问题的解。当递归调用过程中第一次遇到子问题时，计算其解，并存入对应表项。随后每次遇到同一个子问题，只是简单地查表，返回其解。注意，==这种方法假定我们预先已经知道所有可能的**子问题参数**（子问题空间），并已经在表项和子问题间建立起对应关系。另一个更通用的备忘方法是使用散列技术，以**子问题参数**为关键字==。

下面给出的是，带备忘的 `RECURSIVE-MATRIX-CHAIN` 版本，注意它与带备忘的自顶向下钢条切割算法的相似之处。
```cpp
MEMOIZED-MATRIX-CHAIN(p)
	n = p.length - 1
	let m[1...n, 1...n] be a new table
	for i = 1 to n
		for j = i to n
			m[i][j] = INF
	return LOOKUP-CHAIN(m, p, 1, n)

LOOKUP-CHAIN(m, p, i, j)
	if m[i][j] < INF
		return m[i][j]
	if i == j
		m[i][j] = 0
	else for k = i to j - 1
		q = LOOKUP-CHAIN(m, p, i, k) + LOOKUP-CHAIN(m, p, k + 1, j) + p[i-1]p[k]p[j]
		if q < m[i][j]
			m[i][j] = q
	return m[i][j]
```
`MEMOIZED-MATRIX-CHAIN` 与 `MATRIX-CHAIN-ORDER` 一样维护一个表 $m[1\dots n, 1\dots n]$ ，来保存计算出的矩阵 $A_{i \dots j}$ 的最小计算代价 $m[i, j]$ 。每个表项被初始化为 $\infin$ ，表示还未存入过值。调用 `LOOKUP-CHAIN(m, p, i, j)` 时，如果第一行发现 $m[i, j] < \infin$ ，就直接返回之前已经计算出的代价 $m[i, j]$（第二行）；否则，像 `RECURSIVE-MATRIX-CHAIN` 一样计算最小代价，存入 $m[i, j]$ 并返回。因此，虽然 `LOOKUP-CHAIN(m, p, i, j)` 总是返回 $m[i, j]$ 的值，但只在第一次（以特定的参数 $i$ 和 $j$ ）调动时才真正计算。

图15-7说明了，与 `RECURSIVE-MATRIX-CHAIN` 相比，`MEMOIZED-MATRIX-CHAIN` 是如何节省时间的。阴影子树表示那些直接查表获得、而非重新计算的值。

与自底向上动态规划算法 `MATRIX-CHAIN-ORDER` 类似，`MEMOIZED-MATRIX-CHAIN` 的运行时间为 $O(n^3)$ 。`MEMOIZED-MATRIX-CHAIN` 的第五行运行了 $\Theta(n^2)$ 次。我们可以将对 `LOOKUP-CHAIN` 的调用分为两类：
1. 调用时 $m[i, j] = \infin$ ，因此第 $3 \sim 9$ 行会执行。
2. 调用时 $m[i, j] < \infin$ ，因此 `LOOKUP-CHAIN` 执行第 $2$ 行，简单返回值。

第一种调用会发生 $\Theta(n^2)$ 次，每个表项一次。第二种调用均为第一种调用所产生的递归调用。而无论何时一个 `LOOKUP-CHAIN` 的调用继续进行递归调用，都会产生 $O(n)$ 次递归调用。因此，第二种调用共有 $O(n^3)$ 次、每次花费 $O(1)$ 时间，而第一种调用每次花费 $O(n)$ 时间、再加上它产生的递归调用的时间。因此，算法的总时间为 $O(n^3)$ ，备忘技术将一个 $\Omega(2^n)$ 时间的算法、转换为一个 $O(n^3)$ 时间的算法。

总之，为求解矩阵链乘法问题，我们既可使用带备忘的自顶向下动态规划算法，也可用自底向上的动态规划算法，时间复杂度均为 $O(n^3)$ 。两种方法都利用了重叠子问题性质。不同的子问题一共只有 $\Theta(n^2)$ 个，对每个子问题，两种方法都只计算一次。而没有备忘机制的自然递归算法的运行时间为指数阶，因为它会反复求解相同的子问题。

通常情况下，==如果每个子问题都必须至少求解一次，自底向上动态规划算法会比自顶向下备忘算法快==（都是 $O(n^3)$ 时间，相差一个常量系数），==因为自底向上算法没有递归调用的开销，表的维护开销也更小==。而且，**对于某些问题，我们可以利用表的访问模式来进一步降低时空代价**。相反，==如果子问题空间中的某些子问题完全不必求解，备忘方法就会体现出优势了，因为它只会求解那些绝对必要的子问题==。

---


