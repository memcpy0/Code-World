@[toc]


---
# 4.1 存储系统的原理
存储器是计算机的核心部件之一， 其性能直接关系到整个计算机系统性能的好坏。计算机中的存储器， 从结构上讲可分为多种， 主存储器( 内存 )、高速缓冲存储器(`Cache`)， 联机辅存和脱机辅存等。计算机中常用存储器的基本层次结构如图 4.1 所示。

注 : 图中所标参数是 1995 年末中低档台式计算机的典型值
图 4.1 常用存储器的基本层次结构
## 4.1.1 存储系统的意义
1.存储器的三个主要参数
一个存储器的性能通常用三个主要参数(指标) 来表示:容量、速度和每位价格。
① 存储器的容量 SM = W× l× m。其中， W 为存储器的字长( 单位为位或字节)，
l 为存储器的体长(字数)， m 为并行工作的存储体的个数 ( 或称为模数) 。容量的单
位有位( bit)， 字节(B)， 千字节( KB) ( 1KB = 2
10 B)， 兆字节 ( MB) ( 1MB = 2
10 KB = 2
2 0
B) 和千兆字节(GB) ( 1GB = 2
3 0 B) 等。
② 存储器的速度可用访问时间 TA 、存储周期 T M 和频宽 B M 来描述。

177
TA 是存储器接到访存申请， 完成一次 R/ W 所需的时间;
T M 是指连续完成两次 R/ W 所需的时间间隔， 一般有 T M > TA ;
BM 是指存储器在单位时间内传送的信息量， 常用下式表示:
BM = m× W
T M
BM 单位常用 b/ S 或者 B/ S, KB/ S, MB/ S 和 GB/ S 等表示。
③ 存储器的价格是指每位价格， 即 C = 存储器的总价格
存储器的总容量， 单位为每位多少美分
(＄C/ bit)。
主观上， 人们总希望存储器的容量越大越好， 速度越快越好， 而价格越便宜越好。
实际上， 这三个指标的提高总是相互矛盾的， 那么， 系统结构设计者又是如何解决这
一矛盾的呢 ? 答案是发展存储系统。
2.存储系统的意义
存储系统又称为存储体系或存储层次， 它是指两个或两个以上的速度、容量和价
格不同的存储器用硬件、软件或软硬结合的方法构成的一个完整的系统。这个系统
对应用程序员透明。
存储系统有两个特点:一是由多级存储器构成的这个系统， 对于应用程序员是一
个存储器， 而且速度接近第一级存储器的速度， 容量和每位价格接近最后一级存储器
的容量和每位价格;二是很好地解决了存储器速度、容量和价格三者之间的主客观矛
盾， 为计算机中存储器性能的提高找到了一个很好的途径。
3.存储系统的四个基本问题
存储系统的构成是基于程序访问具有局部性 ( 时间上和空间上) 规律的这一原
理。在这种层次结构的系统中， 每上一层存储的信息都是其下一层的一个子集， 因
此， 与之相关联的有四个问题:
① 当把某一层中的信息块调入上一层存储器时， 应该存放在什么位置 ? 这就是
地址映像(映像规则) 问题。
② 如何查找(或访问) 到指定的存储层次中的内容， 即地址变换问题。
③ 如果访问失效， 将下一层信息块调入上一层已被占用的信息块位置时， 应如
何替换 ? 即替换算法及其实现问题。
④ 当对某一信息块内容进行修改时， 应该进行哪些操作 ? 即相应的写策略问
题。
4.1.2 存储系统的性能指标
为了方便起见， 我们以二级存储系统为例说明存储系统的性能指标。两级存储

178
器 M1 和 M2 的访问时间分别为 TA1 和 TA2， 容量分别为 SM1 和 SM2， 单位价格分别为
C1 和 C2， 很显然， 它们之间有 TA1 < TA2， SM1 < SM2， C1 > C2， 如图 4.2 所示。
M1
( TA1， SM1， C1 )
M2
( TA2， SM2， C2 )
( TA， SM， C)
图 4.2 二级存储系统
1.每位平均价格
两级存储系统的每位平均价格可以表示为:
C = C1 SM1 + C2 SM2
SM1 + SM2
若希望存储系统的平均每位价格能接近于 C2， 就应使 SM1 n SM2 。但是， 如果 SM1
与 SM2 相差太大， 则会使得对 M1 的命中率很低。同时， 上式没有把由于采用存储系统
所必须增加的辅助软、硬件价格计算在内， 所以要使 C 接近于 C2， 还应使增加的辅助
软、硬件价格只占价格中很小的比例， 否则存储系统的性能价格比将会显著降低。
2.命中率
命中率可简单地定义为 CPU 访问存储系统时在存储器 M1 中访问到指定信息
的概率。命中率可用实验或模拟方法来获得， 即执行或模拟一段有代表性的程序， 若
逻辑地址流指定的信息能在 M1 中被访问到的次数为 N1， 在 M1 中未被访问到的次
数为 N2， 则命中率为:
H =
N1
N1 + N2
命中率 H 与程序的访存地址流、所采用的地址映像关系、M1 中的块或页被替换的算
法及 M1 的容量都有很大的关系。显然， H 越接近于 1 越好。
为了突出反映不命中的情况， 我们还经常使用不命中率或失效率 F 这个参数，
它是指 CPU 访存时， 在 M1 中找不到所需信息的概率。显然:
F = 1 - H
3.平均访问时间 TA
分两种情况来考虑 CPU 的一次访存:
① 当命中时， 访问时间即为 TA1 。 T A1 常称为命中时间。
② 当不命中时， 必须依据二级存储层次结构原理的不同， 分别予以考虑。在大
多数二级存储层次中， 若访问的字不在 M1 中， 就必须从 M2 中把包含所请求的字的
信息块传送到 M1 之后， CPU 才能在 M1 中访问到这个字。假设传送一个信息块所
需的时间为 TB， 则不命中时的访问时间为:

179
T A2 + TB + TA1 = TA1 + T M
其中， T M = TA2 + TB， 它为从向 M2 发出访问请求到把整个数据块调入 M1 中所需的
时间。 T M 常称为失效开销。
TA = HT A1 + (1 - H) ( TA1 + T M ) = TA1 + (1 - H) T M
或
TA = TA1 + FT M
4.访问效率
二级存储系统的访问效率为:
e = T A1
T A
=
TA1
HT A1 + ( 1 - H ) TA2
=
1
H + ( 1 - H) TA 2/ TA1
可见， 存储系统的访问效率主要与命中率和构成存储系统的两级存储器的访问时间
比有关。
4.1.3 “`Cache`—主存”和“主存—辅存”层次
“`Cache`—主存”和“主存—辅存”层次是常见的两种层次结构， 几乎所有当代计算
机都同时具有这两种层次。我们知道， 程序在执行前需先调入主存( 在虚拟存储器中
也是如此， 只是不必一次全部调入) 。因此， 下面我们将从主存的角度来讨论这两个
存储层次。
1.“`Cache`—主存”层次
近十多年来， CPU 的性能提高得很快， 在 1980～1986 年之间， CPU 以每年 35 %
的速度递增， 而从 1987 年开始， CPU 性能则是每年提高 55 % ( 见图 4.3) 。但是主存
储器性能的提高却慢得多。例如， DRAM 的速度每年只提高 7 % 。因此， CPU 和主
存之间在性能上的差距越来越大。现代计算机都采用 `Cache` 来解决这个问题。图 4.4
(a)是“`Cache`—主存”层次的示意图。这是在 CPU 和主存之间增加一级速度快， 但容
量较小且每位价格较高的高速缓冲存储器(`Cache`) 。它与主存构成一个有机的整体，
以弥补主存速度的不足。这个层次的工作主要由硬件实现。
2.“主存—辅存”层次
引入“主存—辅存”层次的目的是为了弥补主存容量的不足。它是在主存外面增
加一个容量更大、每位价格更低、但速度更慢的存储器， 称为辅存( 一般由联机硬盘系
统构成)。它们依靠辅助软硬件的作用， 使之构成一个整体， 如图 4.4 ( b ) 所示。“主
存—辅存”层次常被用来实现虚拟存储器， 向编程人员提供大量的程序空间。
3.两种存储层次的比较
表 4.1 对“`Cache`—主存”和“主存—辅存”两种存储层次做了一个简单的比较。

180
图 4.3 1980 年以来存储器和 CPU 性能随时间而
提高的情况 (以 1980 年时的性能作为基础
)
图 4.4 两种常用的存储层次
表 4.1
“`Cache`—主存”和“主存—辅存”层次的比较
存储层次
比较项目
“`Cache`—主存”层次
“主存—辅存”层次
目
的
为了弥补主存速度的不足
为了弥补主存容量的不足
存储管理实现
主要由专用硬件实现
主要由软件实现
访问速度的比值
( 第一级比第二级 )
几比一
几万比一
典型的块 (页 ) 大小
几十个字节
几百到几千个字节
CPU 对第二级的访问方式
可直接访问
均通过第一级
失效时 CPU 是否切换
不切换
切换到其他进程

181
4.1.4 主存频宽的平衡与提高
现代计算机是以存储器为中心工作的， 这里所指的存储器是广义的， 不仅是主存
(内存)， 也包括所有的存储器。一般计算机中的存储器有四个访问源: CPU 取指令、
CPU 读取操作数、CPU 写运算结果和各种 I/ O 设备的访问。计算机系统结构设计
者的一项重要工作就是使计算机系统中的各级存储器的频宽达到平衡。
假设一台普通的计算机， 处理速度为 200 MIPS。那么各种访问源的频宽如下:
① CPU 读存储器取指令: 200MW/ S(设每条指令平均长度为 1W 长 )。
② CPU 访问存储器读/ 写操作数和结果: 400MW/ S( 平均每条指令访问两个操
作数)。
③ 各种 I/ O 设备访问: 5MW/ S。
以上三项相加， 要求存储器的频宽不低于 605MW/ S， 这就是频宽平衡。
那么， 如何提高存储器的频宽， 以保证计算机系统的频宽， 满足上述要求， 达到平
衡呢 ? 一般说来有三种途径， 简单介绍如下:
① 采用存储系统， 特别是 `Cache` 存储系统， 这是目前计算机中提高主存速度最
有效的一种方法。有关内容在 4.3 节中介绍。
② 设置各种缓冲存储器。如取指令缓冲栈、操作数先行读数栈、运算结果后行
缓冲栈等。有关内容在第五章中介绍。
③ 设计并行访问存储器。在主存储器设计中， 让多个存储器并行交叉地工作，
以提高其主存频宽。下面介绍几种并行访问存储器。
1.单体多字并行存储器
常规的存储器一个存储单元只能存放一个存储字 W， 一个存储周期只能访问 W
位二进制信息， 这种存储器称之为单体单字存储器， 如图 4.5( a)所示。
如果将存储器的字长扩大 m 倍， 就可以在一个存储周期内同时访问到 m W 位内
容， 由频宽 Bm = m W
T M 可知， 理想值可提高到 m 倍。这种存储器称为单体多字存储
器， 如图 4.5 ( b) 所示。
单体多字并行存储器的优点是实现简单， 缺点是访问冲突概率大。访问冲突主
要来自以下几个方面。
① 取指令冲突。单体多字并行存储器一次取出 m 个指令字， 能很好地支持程序
的顺序执行。但是， 若一个存储字中有一条转移指令字时， 那么存储字中转移指令后
面被同时预取的几个指令字只能作废。
② 读操作数冲突。单体多字并行存储器一次取出的 m 个数据字不一定都是要
执行的指令所需要的操作数， 而当前执行指令需要的全部操作数也可能不包含在一
个存储字中而不能被一次取出。因为数据存放的随机性比程序指令存放的随机性

182
图 4.5 单体单字和单体多字存储器
大， 所以读操作数冲突的概率较大。
③ 写数据冲突。单体多字并行存储器必须是凑齐了 m 个数据字之后才能作为
一个存储字一次写入存储器。因此， 需要先把属于一个存储字的 m 个数读到数据寄
存器中， 然后再把整个存储字写回存储器。
④ 读写冲突。当要读出的数据字和要写入存储器的数据字同处于一个存储字
中时， 读和写的操作就无法在同一存储周期中完成。
2.交叉访问存储器
一个存储器通常对存储单元是顺序编址的。由多个存储体(存储模块) 组成一个
更大容量的主存时， 对多个存储体的存储单元采用交叉编址方式， 组成交叉访问存储
器。交叉访问存储器通常有两种交叉编址方式， 一是地址码的高位交叉编址， 二是地
址码的低位交叉编址。高位交叉编址存储器目前使用很普遍， 这种编址方式能很方
便地扩展常规主存的容量， 但只有低位交叉编址存储器才能作为并行存储器的一种。
低位交叉访问存储器的结构如图 4.6 所示。由 m 个存储体组成的低位交叉存
储器的存储单元地址的低 log2 m 位称为体号 k， 高 log2 n 位称为体内地址 j， 存储单元
地址 A 的计算公式为: A = m× j× k。若已知地址 A, 可计算出对应的体号 k = A
mod m, 体内地址 j =
A/ m」。
为了提高主存的速度， 在一个存储周期内分时启动 m 个存储体， 由于地址码低
位交叉编址， 因此对连续的地址访问将分布在不同的存储体中， 避免了存储体访问冲
突。理想情况下， 存储器的速度可提高 m 倍。

183
图 4.6 低位交叉访问存储器的结构
3.无访问冲突存储器
实际上， 一个由 m 个存储体组成的低位交叉存储器的速度并不能提高 m 倍， 其
根本原因是存在存储体的访问冲突。产生访问冲突的根源主要有两个， 一是程序中
的转移指令， 二是数据被访问的随机性， 后者的影响更为严重。以一维数组和二维数
组为例， 介绍无冲突访问存储器。
(1 )一维数组的无冲突访问
若采用低位交叉访问方式的并行存储器有 4 个存储体， 交叉存放一维数组 a0，a1， a2， ⋯如图 4.7 所示。
 
图 4.7 一维数组的存储方案
如果每次都按连续地址对数组元素顺序访问， 那么一个存储周期可以访问 $4$ 个存储单元。若按位移量为 $2$ 的变址方式访存 (对下标为奇数或偶数的数组元素进行操作)， 则有一半的地址发生冲突， 使存储器的频宽降低一半。若按位移量为 $4$ 的变址方式访存， 则情况就更糟。但若把存储体的个数 $m$ 选为质数， 变址位移量与 $m$ 互质， 那么， 一维数组的访问冲突就不存在了。

许多以向量计算为主要任务的大型计算机系统， 其主存储器的存储体个数一般都是质数。例如， 我国研制的银河计算机， 存储体的个数为 $31$ 。美国Burroughs公司研制的科学处理机 `BSP` 的存储体个数为 $17$ 。
(2 )二维数组的无冲突访问
假设一个 n× n 的二维数组存储在一个并行存储器中。现在要求对这个二维数
组实现按行、按列、按对角线和按反对角线访问， 并且在不同的变址位移量情况下， 都
能实现无冲突访问。
现以 4×4 的二维数组为例来讨论这个问题。按照地址顺序存储各行元素， 一个
4×4 二维数组存储在 4 个存储体中的情况如图 4.8 所示。显然， 按行、按对角线访
问都不发生访问冲突， 但按列访问时， 由于同一列的 4 个元素在同一个存储体内， 就
产生了对存储体的访问冲突， 只能用 4 个存储周期顺序读取。
 
图 4.8 一维数组的存储方案
P·Budnik 和 D·J·Kuck 提出了一种能够对 n× n 二维数组实现上述要求的
无冲突存储方案。
并行存储体实现 n× n 二维数组无冲突访问方案要求:
条件一:并行存储体的个数 m 大于并行访问元素个数 n, 要求 m 取质数， 一般取
m= n + 1。
条件二:行、列方向的元素错位存放， 即同一列相邻两元素错开的距离为 d1， 同
一行相邻两元素错开的距离为 d2， 当 m = 2
2 P + 1 时， d1 = 2 P, d2 = 1。
以 4×4 的二维数组为例， 取大于 4 的最小质数 m = 5 作为并行存储体的个数，
并把 m 代入关系式 m = 2
2 P + 1， 得 p = 1， 计算得: d1 = 2, d2 = 1。一个 4×4 的二维数
组在 5 个存储体中错位存储的存储情况如图 4.9 所示。由图 4.9 可见， 二维数组按
行、列、对角线和反对角线访问都不会发生存储体的访问冲突。
 
图 4.9 二维数组无访问冲突的存储方案
n× n 二维数组中的任意元素 aij 在无冲突并行存储器中的体号和体内地址可以
通过如下的一般公式来计算:
体号地址 = (2
P · i + j + k) mod m
体内地址 = i
其中，0≤i≤ n - 1, 0≤ j≤ n - 1, k 是数组的第一个元素 a00 所在存储体的体号， 一
般取 k = 0; 存储体的个数 m 是大于等于 n 的质数; p 是满足 m = 2
2 p + 1 的任意自然
数。
对于行列不相等的二维数组， 如何实现无冲突访问的存储方案呢 ?
方案是:首先将二维数组按一维线性排列， 并给出地址 a; 然后分别求出每个元
素存储的体号地址和体内地址。
体号地址: k = a mod m ( m 为存储体的个数)
体内地址: j = [ a/ n]
( n 为并行访问元素的个数 )
例如， 对于 4×5 的二维数组 B
B =
b00 b01 b02 b03 b04
b10 b11 b12 b13 b14
b20 b21 b22 b23 b24
b30 b31 b32 b33 b34
取存储体个数 m = 7, 并行访问元素的个数 n= 6, 则它们之间的对应关系如表 4.2 所
示:
表 4.2
 
3
根据表 4.2 所指示元素的体内地址的体号地址， 二维数组的并行无访问冲突的
存储方案如图 4.10 所示。
 
图 4.10 4×5 二维数组并行访问无冲突存储方案
### 4.按内容访问的存储器
按内容访问方式与按地址访问方式不同， 这种访问方式并不提供欲被访问存储
单元的地址， 而是给出欲被访问的内容。显然采用这种访问方式， 存储器的结构形式
就要作相应的变化。为了加快访问速度， 必须采用并行访问方式， 而相应的存储器称
为联想存储器， 由于这种存储器的价格比较昂贵， 因此其容量通常不可能做得很大。
其主要特点是以并行方式查找所需信息内容。联想存储器的基本结构， 如图 4.11 所
示。存储阵列有 n 个字， 每个字 m 位。存储器中有比较寄存器 CR， 用来存放要检索
的数;屏蔽寄存器 MR, 用来屏蔽不参加并行比较的位。以上两个寄存器长度均为 m
位。指示寄存器 IR( n 位 ) 用来存放当前检索结果。当检索条件符合时， 相应的 IR
的位就被置成“1”; 否则仍保留初始值“0”。此外还有一个到多个暂存寄存器 TR( n
位)， 以存放前几次的检索结果。
要访问联想存储器时， 先要在 CR 中存放好要检索的内容， 由 MR 寄存器屏蔽掉
那些不参加比较的部分。未经屏蔽欲进行检索的关键码与联想存储器所有单元中的
相应部分进行并行比较。比较的结果可能会有好几个单元中相应内容满足比较条
件， 将所有符合条件的相应单元所对应的指示寄存器中的相应位置成“1”。下面通过
一个例子来说明联想存储器的工作情况。假定在联想存储器中已存放了一张高校考
生的登记表， 如图 4.12 所示。现在要检索出所有考分大于或等于 520 分而又低于

187
图 4.11 联想存储器的基本结构
540 分的考生名字。在进行这一特定的查询时， 在 CR 中所设置的“考分”关键字是
540, 与所有相应内容作小于比较， 找出低于 540 分的所有考生， 并在相应的 IR 寄存
器的相应位置“1”, 再将其送往 TR。接着进行第二次查询， 将在 CR 中设置的“考分”
关键字改为 520, 然后作大于等于 (或不小于) 的查询比较， 并将结果在 IR 寄存器的
相应位作标志。最后把 IR 和 TR 中的相应内容作一次“与”操作， 就可得到最后所需
的查询结果。凡相应位带标志“1”的考生应在输出名单中 (这里是周钢， 王燕和钱红
三位同学)
。
图 4.12 联想存储器用于学生高考文档的存储和检索

188
在联想存储器中由于要求每个基本存储单元(图 4.11 中的 Bij )， 具有比较功能，
因此相应的存储单元的电路及相互间的连线要比一般的存储器中的复杂得多， 因此
设计复杂， 成本较高， 特别当存储容量较大时。在早期的存储系统中联想存储器用做
地址变换的旁视缓冲器( Translation Lookaside Buffer, T LB)， 容量都比较小。但随
着 VLSI 技术的发展， 联想存储器已开始得到更多的应用。如在 Intel `Pentium` 处理
器中用来构成转移目标缓冲器(Branch Target Buffer, BTB)。
实用的联想存储器， 一般除有按内容访问能力外， 还有按地址访问的能力。故仍
保留有地址寄存器、译码电路和读写寄存器。此外， 联想存储器的每个基本单元除了
有存储能力和相等比较功能外， 还可实现≠， <， ≤， ≥， MAX, MIN， BET WEEN，
NEXT， HIGHER， NEXT—LOWER 等比较功能。
4.2 虚拟存储器
虚拟存储器最早是由英国曼彻斯特大学的 Kilbrn 等人提出的， 并于 1961 年在
该校 Atras 计算机上予以实现。20 世纪 70 年代以来， 这一技术不仅被中、大型计算
机采用， 而且在当今的微型计算机上都普遍采用。那么， 什么是虚拟存储器的技术
呢 ?
一个高级语言程序经过编译后生成目标代码程序。目标代码程序只有装入内
存， 程序才能执行。我们把目标代码程序指令和数据占用的地址空间称为程序地址
空间， 或称为逻辑地址空间。将主存储器的存储空间称为物理地址空间， 或称为实存
地址空间。
虚拟存储器是主存容量的扩展， 它是借助于磁盘等辅助存储器扩大主存容量， 是
一个容量非常大的存储器的逻辑模型， 不是任何实际的物理存储器。
引入虚拟存储器的基本思想是， 实现多用户软件共享宝贵的主存资源。虚拟存
储器技术的实现， 是基于程序访问的局部性原理的。
4.2.1 虚拟存储器的管理方式
在虚拟存储器中有三种地址空间:一是虚拟地址空间， 它是由应用程序员编程时
使用的地址空间;二是主存储器的地址空间; 三是联机辅存地址空间。与这三种地址
空间相对应的有三种地址， 即虚拟地址( 虚存地址、虚地址 )、主存地址 (物理地址、实
地址)、辅存地址(磁盘存储器地址) 。
虚拟存储器管理的主要任务是利用软、硬件的方法， 实现虚拟地址空间到物理地
址空间(包括辅存地址空间) 的映像和变换。
地址映像就是把多用户的虚拟地址编写的程序按照某种规则装入主存储器中，
并建立多用户虚地址与主存实地址之间的对应关系。
地址变换是在程序被装入主存储器之后， 在实际运行时， 把多用户的虚地址变换

189
成主存实地址(内部地址变换) 或磁盘存储器地址(外部地址变换) 。
根据虚拟存储器所采用的地址映像和地址变换方法不同， 则有多种不同的虚拟
存储器。常用的有三种， 即段式虚拟存储器、页式虚拟存储器和段页式虚拟存储器。
下面分别介绍这三种虚拟存储器。
1.段式虚拟存储器
(1 )分段原理
根据程序在结构上都具有相对独立的模块化这一特点， 可将用户程序分成若干
段， 每段以零为起始地址编址。如主程序段、公共子程序段、数据段、表格段、向量段
等。
(2 )地址映像
在段式虚拟存储器的管理中， 是利用段表( Segment Table)来建立地址映像关系
的。例如某用户 A 的程序由 4 段组成， 各段长度及映像如图 4.13 所示
。
图 4.13 段式虚拟存储器的地址映像
A 用户程序共有四个逻辑段组成， 在一张段表的控制下， 将它们分别映像到主存
储器的各个不同区域中。实际上每个程序段可以映像到主存储器的任意位置， 它们
可以连续存放， 也可以不连续存放， 可以顺序存放， 也可以前后倒置存放。
(3 )地址变换
有了地址映像， 可以把在虚拟地址空间中编写的程序装入主存储器中。但在程
序实际执行时， 还要把用来访问主存储器的多用户虚地址变换成主存实地址， 才能访
问已经装在主存储器中的用户程序或数据， 地址变换过程如图 4.14 所示。
一个多用户的虚地址由三部分组成， 用户号 U、段号 S 和段内偏移 D。地址变换
过程可描述如下:
① 查段表基址寄存器。根据多用户的虚地址中的“用户号”字段， 查找段表基址

190
寄存器(段表基址寄存器通常设置在 CPU 内部， 每个用户程序使用其中的一个基址
寄存器)， 找到该用户程序的段表在主存中的首地址。
② 查段表。每个用户程序在主存中都设置有一个段表， 段表的项( 行) 数等于用
户程序的逻辑段数。由段表基地址加上虚地址中的“段号”, 就可得到所要访问程序
段的全部信息所在的地址。
③ 形成访存实地址。如果段表中的装入位为“1”, 表示该段程序已经装入主存。
这时， 取出段表中该段程序在主存中的“起始地址”加上虚地址中的“段内偏移”, 从而
形成访问主存的实地址
。
图 4.14 段式虚拟存储器的地址变换
段表中的段长和访问方式是用来保护程序段的。可以根据程序段的起始地址和
段长计算出本次访问主存储器的地址是否越界。访问方式可以指出本程序段是否需
要保护和保护的级别。例如， 对于子程序段， 通常只能执行， 不能改写; 对于一些常数
段或数据库中的数据段， 一般用户程序只能读， 不能改写， 不能执行; 对于有些需要保
密的表格， 一般用户应禁止访问等。
如果装入位给出的信息表示要访问的这个程序段不在主存储器中， 则段表中的
起始地址和访问方式字段等均无用。这时， 可以把它们用来存放该程序段在磁盘存
储器中的起始地址等信息。使用磁盘存储器的起始地址和段长就可以从磁盘存储器
中把该程序段读到主存储器中。
根据需要还可以在段表中增加其他字段， 例如， 增加一个修改标志字段， 表示本
程序段是否被修改过。如果这个程序段从装入主存储器起一直没有被修改过， 则在
需要把它替换出主存储器时， 不必把这个程序写回到外部的磁盘存储器中， 只要用新
调入的程序段把它覆盖掉即可。如果这个程序段被修改过， 则必须先把这个程序段

191
全部写回到磁盘存储器中存放这个程序段的原来位置上。
段表本身也是一个段， 一般常驻在主存储器中。如果段表太长， 也可以把暂时不
用的一部分段表放在磁盘存储器中， 当需要时再把有用的段表调入主存储器。
段式虚拟存储器的主要优点如下:
① 程序的模块化性能好。对于大程序， 可以划分成多个程序段， 每个程序段赋
予不同的名字， 由多个程序员并行编写， 分别编译和调试， 从而可以缩短程序的编制
和调试时间。
② 便于程序和数据的共享。当某个程序段需要被共享时， 只要在主存储器中装
入一份， 同时在需要调用这个程序段的那些程序( 或用户)被共享时， 在需要调用这个
程序段的那些程序(或用户) 的段表中都使用这个程序段的主存起始地址和段长等信
息， 就能很方便地实现程序段的共享。
③ 便于实现信息保护。在一般情况下， 一段程序是否需要保护是根据这个段程
序的功能来决定的。由于段式虚拟存储器本身就是按照功能划分程序段的， 因此， 只
要在段表中设置一个信息保护字段， 就能根据需要很方便地实现对该程序段的保护。
段式虚拟存储器的主要缺点如下:
① 地址变换所花费的时间比较长。从图 4.14 中可以看到， 从多用户虚地址变
换到主存实地址需要查两次表， 做两次加法运算。
② 主存储器的利用率往往比较低。由于每个程序段的长度是不同的， 程序段在
主存储器不断地调入、调出， 有些程序段在执行过程中还要动态地增加长度， 从而使
得主存储器中有很多的空隙存在。
③ 对辅存(磁盘存储器) 的管理比较困难。磁盘存储器通常是按固定大小的块
来访问的， 如何把不定长度的程序段映像到固定长度的磁盘存储器中， 需要做一次地
址变换。
2.页式虚拟存储器
(1 )分页原理
页式虚拟存储器把虚拟地址空间和主存地址空间等分成大小相同的页。页是一
种逻辑上的划分， 它可以由系统管理软件任意指定。然而， 由于磁盘存储器的物理块
大小是 0.5KB, 为了与外部存储器， 特别是磁盘存储器相配合， 虚拟存储器中页的大
小通常指定为 0.5KB 的整倍数。目前在一般计算机系统中， 一页的大小通常为 1KB
～16KB。
(2 )地址映像
在页式虚拟存储器中， 虚拟地址空间的页称为虚页( 页面)， 主存地址空间的页称
为实页(页框) 。将虚拟空间到主存空间的映像关系， 转换为虚页与实页的对应关系。
所以， 在页式虚拟存储器中， 映像是由“页表”来完成的。例如， 某用户程序空间为
15KB, 每页大小为 4KB, 则虚页为 4 页， 如图 4.15 所示。

192
图 4.15 页式虚拟存储器的地址映像
与段式虚拟存储器相比， 由于每一页的长度是固定的， 因此， 不需要像段式虚拟
存储器中的段长度这一字段。另外， 主存地址这一字段只需要指出主存储器的页号，
与段式虚拟存储器中的主存地址必须指出整个主存地址长度相比要节省很多。
(3 )地址变换
在 CPU 内部有一个页表基址寄存器， 用来存放多用户页表在主存中的基地址。
每个用户(每道程序) 使用其中一个基址寄存器。
多用户的虚地址由三部分组成:用户号 U， 虚页号 P 和页内偏移 D。页式虚拟存
储器的地址变换过程如图 4.16 所示， 并可描述为以下三个过程。
① 查页表基址寄存器。根据多用户的虚地址中的用户号查页表基址寄存器， 从
中读出这个用户程序的页表在主存中的起始地址。
② 查页表。根据页表的首地址， 再加上用户虚页号， 就能得到被访问页的所有
信息， 包括该页是否已装入主存， 对应主存实页号以及其他与访问有关的信息。
③ 形成实地址。如果被访问的页已经装入主存， 则根据页表中的实页号 P 与多
用户虚地址中的页内偏移 D 直接拼接起来构成访问主存的实地址。
页式虚拟存储器的主要优点如下:
① 主存储器的利用率比较高。每个用户程序只有不到一页 (平均为半页) 的浪
费， 与段式虚拟存储器每两个程序段之间都有浪费相比要节省许多。
② 页表相对比较简单。它需要保存的字段数比较少， 一些关键字段的长度与段
式相比要短许多， 因此， 节省了页表的存储容量。
③ 地址变换的速度比较快。在把用户程序装入到主存储器的过程中， 只要建立
用户程序的虚页号与主存储器的实页号之间的对应关系即可， 不必使用整个主存的
地址长度， 也不必考虑每页的长度等。在地址变换过程中， 从图 4.16 中可以看到， 主
存实地址 A 是由页表中的主存页号 P 和多用户虚地址中的页内偏移 D 直接拼接而
得到的， 不必经过任何运算， 因此， 地址变换的速度比较快。
④ 对辅存(磁盘存储器) 的管理比较容易。因为页的大小一般取磁盘存储器物

193
图 4.16 页式虚拟存储器的地址变换
理块大小(512 字节 )的整倍数。
页式虚拟存储器的缺点主要有两个:
① 程序的模块化性能不好。由于用户程序是强制按照固定大小的页来划分的，
而程序段的实际长度一般是不固定的。因此， 页式虚拟存储器中一页通常不能表示
一个完整的程序功能。一页可能只是一个程序段中的一部分， 也可能在一页中包含
了两个或两个以上的程序段。
② 页表很长， 需要占用很大的存储空间。通常， 虚拟存储器中的每一页在页表
中都要占有一个存储字。假设有一个页式虚拟存储器， 它的虚拟存储空间大小为
4GB, 每一页的大小为 1KB, 则页表的容量为 4MB 存储字。如果每个页表存储字占
用 4 个字节， 则页表的存储容量为 16MB。
3.段页式虚拟存储器
(1 )分段分页原理
段式虚拟存储器和页式虚拟存储器各有其优点和缺点， 段页式虚拟存储器是它
们二者的结合。它将用户的虚拟存储空间按逻辑模块分成若干段， 每段又分成大小
相同的页。段的长度必须是页长的整倍数， 段的起点必须是某一页的起点。每页的
大小仍然是 0.5KB 的整倍数。
一个用户程序由三个独立的程序段组成。0 号程序段的长度为 12KB, 由于页的
长度是 4KB, 因此， 正好分成 3 页。1 号程序段的长度为 10KB, 也分成 3 页， 其中最
后一页有 2KB 是浪费的。2 号程序段的长度为 5KB, 分成 2 页， 其中后面一页浪费
3KB。
(2 )地址映像

194
段页式虚拟存储器的地址映像是由段表和页表共同完成的。在图 4.17 中， 一个
用户程序的三个程序段通过一张段表来控制。与段式虚拟存储器一样， 每个程序段
在段表中占一行。在段表中给出该程序段的页表长度和页表的起始地址， 根据这两
个参数就能找到这个程序段的页表。页表的长度就是这个程序段的页数， 页表中给
出这个程序段的每一页在主存储器中的实页号。这样就完成了用户程序的虚拟空间
到主存实地址空间的映像
。
图 4.17 段页式虚拟存储器的地址映像
(3 )地址变换
在段页式虚拟存储器中， 一个多用户虚拟地址由四部分组成: 用户号 U、段号 S、
虚页号 P 和页内偏移 D， 见图 4.18。在程序运行过程中， 要把用户程序中的虚拟地
址变换成实页号 p 和页内偏移 d。在程序运行过程中， 要把用户程序中的虚拟地址
变换成主存实地址， 必须在 CPU 内部设置段表基址寄存器组， 每个用户占用一个基
址寄存器， 同时在主存中要建立多用户段表和多用户页表。
段页式虚拟存储器的地址变换过程， 如图 4.18 所示。
① 查段表基址寄存器。根据多用户的虚地址中的用户号 U， 在段表基址寄存器
中找到该用户段表在主存储器中的基地址 a。
② 查段表。由段基址加上虚地址中的段号 S, 形成该段程序页表在主存储器中
的基地址。
③ 查页表。由页表基地址加上虚地址中的虚页号 P， 找到所访问页在页表中的
相应项。
④ 形成访问实地址。由页表中的实页号( 设该页已经装入主存 ) 与虚地址中的
页内偏移 D 拼接形成物理地址。
图 4.18 段页式虚拟存储器的地址变换
由图 4.18 可以看到， 在段页式虚拟存储器中， 要从主存储器中访问一个数据( 取
指令、读操作数或写结果)， 需要查两次表， 一次是页表， 另一次是段表。如果段表和
页表都是在主存储器中， 则要访问主存储器三次。对于段式虚拟存储器和页式虚拟
存储器也要访问主存储器两次。因此， 要想使虚拟存储器的速度接近主存储器的速
度， 或者说， 要想使虚拟存储器能够真正实用， 必须加快查表的速度。有关具体方法，
将在后面作比较详细的介绍。
## 4.2.2 页式虚拟存储器的构成
页式虚拟存储器是以上三种虚拟存储器中使用最为普遍的一种， 因此， 对其构成
按以下几个方面进行介绍。
1.地址映像法则
页式虚拟存储器的地址映像法则是建立起多用户的虚拟程序空间到实际主存空
间的映像关系， 对应关系如图 4.19 所示。
按照上述分页原理可知， 由于虚拟空间与实存空间的页大小是相同的， 多用户的
虚地址中的“页内偏移 D”无需变换可直接形成实存地址中的页内偏移 d。关键在于
将虚地址中的“多用户的虚页号”(即用户号加虚页号部分) 变换成实地址中的实页号
p。
由于是把大的虚存空间映像到较小的主存空间， 页式虚拟存储器采用的是全相

196
图 4.19 虚—实地址的对应关系
联映像法则。即让每道程序的任何虚页可以映像到任何实页位置。例如， 某用户程
序空间有 8 页， 系统分配给该用户的实际主存空间只有 4 页时， 全相联的映像关系如
图 4.20 所示
。
图 4.20 全相联映像
由图 4.20 可知， 在任何时刻用户的程序能够装入主存的页面数最多只有 4 页。
当 CPU 要访问的某一页没有装入主存时， 就会产生页面失效。失效的页面 CPU 仍
需要访问， 系统通过通道将其调入主存后再进行访问， 但由于主存已满， 这就发生了
两个或两个以上的页面想要进入主存中同一页位置的现象， 这种现象称为页面争用
或页面冲突。
例 4.1 某 虚拟存 储器的 用户 编程空 间共 有 32 个 页面， 每 页 1KB, 主存 为
16KB。假定某时刻该用户页表已调入主存时页面的虚页号和实页号对照如表 4.3
所示。

197
表 4.3
已装入主存的部分虚、实对照表
 
问与虚地址 OA5C H， 1A5CH 相对应的物理地址为多少 ?
解:根据前面介绍的虚实地址对应关系， 可将 16 进制虚地址写成二进制形式， 然
后划分出虚地址中的各字段后， 进而转换成主存物理地址， 如图 4.21 所示
。
图 4.21 虚—实地址计算过程
2.外部地址变换
以上介绍了内部地址映像和变换方法， 即把虚拟地址空间映像到主存物理地址
空间， 以及把虚拟地址变换成主存实地址的方法。当页表的有效位指示发生页面失
效时， 表示需要访问的那一页还没有装入到主存储器中， 这时必须进行外部地址变

198
换。外部地址变换的目的是要找到辅存( 磁盘存储器 ) 的实地址， 并且把需要访问的
那一页调入到主存储器中。
磁盘存储器的地址格式如图 4.22 所示。由于一台机器可能有多个磁盘， 因此，
首先要给出磁盘号， 然后是一个磁盘内的柱面号、磁头号和块号。磁盘存储器每一个
物理块的大小是 512 字节。由于在页式虚拟存储器和段页式虚拟存储器中， 每一页
面的大小是固定的， 通常是磁盘存储器物理块大小的整数倍， 这个倍数在外部地址变
换软件中是知道的。因此， 在进行外部地址变换时只要给出磁盘存储器的起始地址，
就能把一页或一个程序段都调入主存储器中。
磁 盘 号
柱 面 号
磁 头 号
块
号
图 4.22 磁盘存储器的地址格式
外部地址变换的过程如图 4.23 所示。由于页面失效的概率非常低， 一般只有
1‰左右， 因此， 外部地址变换通常用软件来实现。每一个用户程序都有一张外页表
(之所以称为外页表是因为它是在外部地址变换中使用的， 与在内部地址变换中使用
的页表被称为内页表相对应)。虚拟地址空间中的每一个页面或每一个程序段， 在外
页表中都有对应的一个存储字。每一个存储字中除了必须有磁盘存储器的地址外，
至少还应包括一个装入位
。
图 4.23 外部地址变换
由于每一个用户程序有一张外页表， 因此， 通过多用户虚地址中的用户号 U 就
能够找到该用户程序的外页表起始地址。再通过虚页号 P 就能惟一确定外页表中
与需要访问的页面相对应的那个存储字。如果该存储字中的装入位为“1”, 则表示要
访问的页面已经在磁盘存储器中， 否则表示要访问的页面还不在磁盘存储器中， 需要

199
从磁带、光盘存储器等海量存储器中调入。在段式虚拟存储器中， 采用类似的方法，
通过段号 S 惟一确定外页表中与需要访问的程序段相对应的那个存储字。
3.页面替换算法
常用的页面替换算法有如下几种:
① 随机算法， 即 RAND 算法(RANDom algorithm)。利用软件或硬件的随机数
发生器来确定主存储器中被替换的页面。这种算法最简单， 而且容易实现。但是， 这
种算法完全没有利用主存储器中页面使用情况的历史信息， 也没有反映程序的局部
性， 所以命中率比较低。
② 先进先出算法， 即 FIFO 算法( First-In First-Out algorithm )。这种算法选择
最先调入主存储器的页面作为被替换的页面。它的优点是比较容易实现， 能够利用
主存储器中页面调度情况的历史信息， 但是， 没有反映程序的局部性。因为最先调入
主存的页面， 很可能也是经常要使用的页面， 如公用子程序或公用数据等。
③ 近期最少使用算法， 即 LRU 算法( Least Recently Used algorithm )。这种算
法选择近期最少访问的页面作为被替换的页面。显然， 这是一种非常合理的算法， 因
为到目前为止最少使用的页面， 很可能也是将来最少访问的页面。该算法既充分利
用了主存储器中页面调度情况的历史信息， 又正确反映了程序的局部性。但是， 这种
算法实现起来非常困难。它要为每个页面设置一个很长的计数器， 并且要选择一个
固定的时钟为每个计数器定时计数。在选择被替换页面时， 要从所有计数器中找出
一个固定的时钟为每个计数器定时计数。在选择被替换页面时， 要从所有计数器中
找出一个计数值最大的计数器。因此， 通常采用另外一种变通的办法， 就是下面的
LFU 算法。
④ 最久没有使用算法， 即 LFU 算法 ( Least Frequently Used algorithm )。这种
算法把近期最久没有被访问过的页面作为被替换的页面。它把 LRU 算法中要记录
数量上的“多”与“少”简化成判断“有”与“无”, 因此， 实现起来比较容易。
⑤ 最优替换算法， 即 OPT 算法( OPTimal replacemant algorithm)。在时刻 t 找
出主存储器中每个页将要用到的时刻 ti， 然后选择其中 ti - t 值最大的那一页作为被
替换的页。
要实现 OPT 算法， 惟一的办法是让程序先执行一遍， 记录下实际的页地址流情
况。根据这个页地址流才能找出当前要被替换的页面。显然， 这样做是不现实的。
因此， OPT 算法只是一种理想化的算法， 然而， 它也是一种很有用的算法。实际上，
经常把这种算法用来作为评价其他页面替换算法好坏的标准。在其他条件相同的情
况下， 哪一种页面替换算法的命中率与 OPT 算法最接近， 那么， 它就是一种比较好
的页面替换算法。
例 4.2 一个程序共有 5 个页面， 分别为 P1～ P5。程序执行过程中的页地址流

200
(即程序执行中依次用到的页面) 如下:
P1, P2， P1， P5, P4, P1, P3, P4， P2， P4
假设分配给这个程序 的主存 储器 共有 3 个 页面。图 4.24 为 FIFO， LFU 和
OPT 三种页面替换算法对这 3 页主存储器的使用情况， 包括调入、替换和命中等。
其中， 用“ * ”号标记下次将要被替换掉的页面。
从图 4.24 中可以看出， FIFO 算法的命中率最低， LFU 算法的命中率与 OPT 算
法很接近。这一结论具有普遍意义。因此， 在实际使用中， LFU 算法是一种比较好
的算法。目前， 许多机器的虚拟存储器都采用 LFU 算法。
 
图 4.24 三种页面替换算法对同一个页地址流的调度过程
在上面介绍的 5 种页面替换算法中， 随机算法的命中率比较低， 一般仅用于必须
用硬件实现， 而且对命中率要求不太高的场合。LRU 算法由于其实现起来特别困
难， 目前很少被采用。因此， 在虚拟存储器中， 实际上有可能被采用的页面替换算法
就只有 FIFO 和 LFU 两种。
下面说明一下堆栈型替换算法。
在主存储器页面的分配和调度过程中， 影响命中率的因素很多， 那么最主要的因
素是什么呢 ? 堆栈型替换算法就是研究主存储器的页面数与命中率的关系。弄清楚
了这个问题， 就不需要做大量的模拟工作， 就可能知道如何为程序分配主存页面数。

201
那么， 什么是堆栈型替换算法呢 ? 它的定义如下:
以任意一个程序的页地址流作两次主存页面数分配， 分别分配 m 个主存页面和
n 个主存页面， 并且有 m≤ n。如果在任何时刻 t, 主存页面数集合 Bt 都满足关系:
Bt( m)
Bt( n)
则这类算法称为堆栈型替换算法。
简单地说， 堆栈型替换算法的基本思想是: 随着分配给程序的主存页面数的增
加， 主存的命中率也提高， 至少不下降。
很容易证明， LRU 算法和 LFU 算法是堆栈型替换算法， OPT 算法也是堆栈型
替换算法。但是， FIFO 算法不是堆栈型替换算法。 FIFO 算法在主存页面数增加时
命中率反而下降， 如图 4.25 所示。
 
图 4.25 FIFO 算法在主存页面数增加时命中率反而下降
由于堆栈型替换算法的命中率随分配给该程序的主存页面增加而单调上升， 因
此， 在多道程序系统中， 可以采用一种被称为页面失效频率法 PFF ( Page Fault Fre-
quency)的动态页面调度方法。具体做法是: 根据各道程序在实际运行过程中页面失
效率的情况， 由操作系统动态高速分配给每道程序的主存页面数。当一道程序的命
中率低于某个限定值时就增加分配给该道程序的主存页面数， 以提高它的命中率。
而当命中率高于某个限定值时就减少分配给该道程序的主存页面数， 把节省出来的
主存页面分配给其他程序， 从而使整个系统的总的命中率和主存利用率都得到提高。
例 4.3 采用页式管理的虚拟存储器， 分时运行两道程序。其中， 程序 X 为
DO 50 I = 1, 3
 
B( I) = A( I) - C( I)
IF (B(I) ≤0) GOTO 40
D( I) = 2
* C( I) - A( I)
IF D( I) = 0 GOTO 50
40 E( I) = 0
50 CONTINUE
DATA: A = ( - 4, + 2, 0)
C = ( - 3, 0, + 1 )
每个数组分别放在不同的页面中; 而程序 Y 在运行过程中， 其数组将依次用到
程序空间的第 3, 5, 4, 2, 5, 3, 1， 3, 2, 5， 1, 3, 1， 5, 2 页。如是采用 LRU 算法替换， 实
存却只有 8 页位置可供存放数组之用。试问为这两道程序的数组分配多少实页最为
合理 ? 为什么 ?
解:由题意可知， 假若 X 程序中数组 A， B, C, D， E 分别存放在第 1, 2, 3, 4， 5 页。
运行 X 程序时， 出现的页地址流依次为 1, 3， 2, 2, 5, 1, 3， 2, 2， 3, 1, 4, 4, 5， 1, 3, 2, 2, 5
共 19 个页面地址。
使用堆栈处理法， X， Y 程序页地址流堆栈处理过程分别如图 4.26 和图 4.27 所
示。其中 N 为主存页面数
。
图 4.26 X 程序页地址流堆栈处理
综合 X, Y 两道程序分析并列于表 4.4 中。由此可知， 当系统分别给每个用户分
配 N = 4 个实页时， 系统命中率达到最大值 64.95% 。所以给两个程序各分配 4 个实
页较为合适。
 
图 4.27 Y 程序页地址流堆栈处理
表 4.4
 
### 4.页式虚拟存储器的工作全过程
页式虚拟存储器工作全过程， 如图 4.28 所示。
每当以虚地址访问主存时， 都必须查内页表①， 若装入位为 1 则形成主存实地址
②， 可访问主存③。若装入位为 0， 则产生页面失效故障 ( 异常) ④， 并直接经外部地
址变换⑤形成辅存实地址⑥， 经 I/ O 处理机调页至主存⑦。如果外页表查找失效，
则需访问海量存储器⑧。发生页面失效后， 由操作系统查找主存页面表， 以确定调进
的页存放在主存中什么位置⑨。若主存未满， 根据全相联映像法则， 调进的页可存放
在任何空页位置⑩。否则， 需通过替换算法寻找被替换掉的页面 1， 12 。不论是哪一
种情况， 最后将主存页面号送 I/ O 处理机 13， 由 I/ O 处理机完成调页⑦。替换时应
考虑已经被修改过的页重新送回辅存 14 。

204
图 4.28 页式虚拟存储器工作全过程
4.2.3 加快页式虚拟存储器地址变换的方法
从页式虚拟存储器的工作全过程可知， 多用户的虚地址变换成主存实地址， 可能
性只有三种:一是被访问的页已经装入主存 ( 命中 )， 多用户的虚地址经查内页表 ( 内
部地址变换)转成实际主存地址; 二是被访问的页不在主存( 不命中)， 但主存仍有可
调进新页的空间， 多用户的虚地址经查外页表 ( 外部地址变换 )， 由通道或 I/ O 处理
机完成调页过程;三是被访问的页不在主存， 且主存已经装满， 则多用户的虚地址经
查外页表完成调页， 同时， 还需根据某种替换算法， 完成新旧页面的替换。
在以上三种情况中， 第一种出现的概率远高于后两者之和。根据 Amdahl 定律，
为了提高整个虚拟存储器地址变换速度， 关键在于提高查内页表 (内部地址变换) 的
速度。具体方法如下:

205
1.目录表法
多用户的虚存空间要比实际主存空间大得多， 即虚存页面数 ( 2
U + P 页)。远大于
实际主存页面数(2
P 页)， 内页表中装入位为“0”的项有 (2
U + P - 2
P )个存储字。为此，
可将内页表压缩为已经装入主存中的虚页与实页的对应关系， 去掉装入位为“0”的存
储字， 并用相联存储器构成压缩后的内页表， 页表中的每一个存储字包括虚页号、实
页号、修改位和访问方式等， 不再设置装入位， 我们把这种相联目录表简称为目录表。
采用目录表法的虚拟存储器， 其地址变换过程如图 4.29 所示。为了把多用户虚
页号变换成主存实页号， 要把多用户虚地址中的多用户虚页号 ( U 与 P 拼接起来) 与
相联存储器中的多用户虚页号字段逐个进行比较。如果有相等的， 表示要访问的这
个页面已装入到主存储器中了。这时， 读出该单元中的其他字段， 其中， 实页号字段
中存放的就是与多用户虚页号相对应的主存实页号。只要把这个实页号 p 与多用户
虚地址中的页内偏移 D 直接拼接起来就成了要访问的主存实地址。如果没有相等
的， 则表示要访问的那个页面还没有装入到主存储器中， 这时， 发出页面失效请求， 从
磁盘存储器中把要访问的那一个页面调入主存储器
。
图 4.29 目录表法的地址变换过程
由于目录表是采用高速度小容量存储器实现的， 与把页表放在主存储器中的方
法相比， 查表的速度要快得多。
然而， 随着主存储器容量的增加， 目录表的容量也随之增加。当主存储器的容量
增加到一定数量后， 目录表的造价就会很高， 查表的速度也会降低。

206
2.快慢表法
由于程序在执行过程中具有局部性， 因此， 对页表中各存储字的访问并不是完全
随机的。也就是说， 在一段时间内， 对页表的访问只是局限在少数几个存储字内。根
据这一特点， 可将页表由快表和慢表共同构成。慢表是全表， 仍然存放在主存储器
中， 快表是慢表的一个副本， 一般是由十几个存储字的相联存储器构成， 访问速度与
CPU 内部寄存器相当。
查表时快表和慢表同时进行， 若快表命中， 则其访问时间很短， 慢表访问无效。
若快表失效， 则慢表访问时间即为等效查表时间。实际上快表与慢表也构成了一个
由两级存储器构成的存储系统。当快表装满时， 则要采用某种替换算法， 替换掉某一
个存储字。由快慢表法构成的虚拟存储器地址变换过程如图 4.30 所示
。
图 4.30 采用快慢表的地址变换过程
由于快表的查表速度非常快， 与主存储器的一个存储周期相比几乎可以忽略不
计。因此， 只要快表的命中率很高， 那么， 虚拟存储器的访问速度就能与主存储器的
工作速度很接近。
3.散列变换法
在采用快慢表结构的虚拟存储器中， 要提高快表的命中率， 最直接的办法是增加
快表的容量。快表的容量越大， 命中率就越高。但是， 由于快表是按相联方式访问
的， 当快表的容量增加时， 它的查表速度就会降低。那么， 能不能让快表不采用相联
方式访问， 而采用普通的按地址来访问呢 ?
如果要在一个按地址访问的存储器中查找一个信息， 可以使用顺序查找法、对分
查找法和散列查找法等。其中， 散列 ( Hashing) 查找方法的速度最快。对于快表来

207
说， 就是要把多用户虚页号 PV 变换成快表的地址 Ah, 其函数关系是:
Ah = H ( PV )
散列函数的种类很多。由于快表中的散列函数必须用硬件来实现， 因此， 通常采
用一些简单的函数关系。图 4.31 是一种折叠按位加散列函数， 把 15 位多用户虚地
址 PV (内容) 散列变换成 6 位的快表地址 Ah。
由于是把一个大的多用户虚页号 PV 散列变换成了一个小的快表地址 Ah, 因
此， 必然会有很多个多用户虚页号 PV 都散列变换到相同的快表地址 Ah 中， 这种现
象称为散列冲突。例如， 在图 4.31 中， 平均会有 2
15 ÷2
6 = 2
9， 即 512 个多用户虚页
号全部被散列变换成同一个快表地址。
为了避免因散列冲突而发生查快表时的错误， 必须把多用户虚页号也加入到快
表中去， 并且与主存实页号存放在同一个快表存储字中。另外， 还要用一个比较器，
把从快表中读出来的多用户虚页号与多用户虚地址中的多用户虚页号进行比较
。
图 4.31 一种用硬件实现的散列函数
采用散列变换实现快表按地址访问的虚拟存储器如图 4.32 所示。地址变换的
过程是这样的:首先把多用户虚地址中的多用户虚页号 PV (由 U 和 P 拼接而形成)
送入硬件的散列变换部件， 经散列变换后得到快表的地址 Ah。然后用地址 Ah 访问
快表， 读出主存实页号 p 和多用户虚页号 PV′。把主存实页号 p 送入主存储器的地
址寄存器， 与页内偏移 d 直接拼接起来形成主存地址， 并且用这个地址立即去访问主
存储器。同时， 把读出的多用户虚页号 PV′与多用户虚地址中多用户虚页号 PV 在相
等比较器中进行比较。如果比较结果相等， 就继续刚才的访问主存储器的操作， 否
则， 立即终止访问主存储器的操作。比较结果不相等表示发生了散列冲突， 这时， 需
要去查存放主存储器中的慢表。
由于快表按地址访问， 在保证访问速度的前提下， 其存储容量可以比用相联存储

208
图 4.32 采用散列变换实现快表按地址访问
器实现的快表大很多倍。虽然也有一次相等比较， 但相等比较可以与访问存储器的
操作同时进行。因此， 这种快表按地址访问的快慢表结构， 与上面介绍的采用相联存
储器作快表的快慢表结构相比， 快表的命中率要高很多， 而且查表的速度也很快。
4.虚拟存储器举例
IBM 370/ 168 计算机的虚拟存储器快表结构及地址变换过程， 如图 4.33 所示，
虚拟地址共长 36 位。其中， 页面大小为 4K 字节， 占 12 位。每个用户( 或每道程序)
最多允许占用 4K 个页面， 因此， 虚页号也占 12 位。最多允许 16G 个用户(或 16G 道
程序)同时上机， 用户号占 24 位， 但是， 实际上在一段时间内同时上机的用户数一般
不超过 6 个。
快表按地址访问， 快表的地址由多用户虚页号经硬件的散列变换部件压缩后生
成。快表地址共 6 位， 因此， 快表容量为 64 个存储字。
IMB 370/ 168 计算机的虚拟存储器采用了两项新的措施: 第一项措施是在快表
的每一个存储字中存放两对多用户虚页号与主存实页号， 并采用两个相等比较器。
只要其中有一个比较器的比较结果相等， 就认为快表命中。这时， 立即把命中的实页
号 p 送到主存地址寄存器中， 与地址寄存器中的页内偏移拼接成主存实地址。只有
当两个比较器的比较结果都不相等时， 才认为快表没有命中， 需要到慢表中去查主存
实页号 p。
第二项措施是用一个由 6 个寄存器组成的相联寄存器组把 24 位的用户号 U 压
缩成 3 位的 ID, 把这个 ID 与虚页号直接拼接起来作为散列变换部件的输入。这样
做能够减少散列部件的输入与输出位数的差， 从而降低散列冲突。

209
图 4.33 IBM 370/ 168 计算机的虚拟存储器快表结构
在地址变换开始时， 把多用户虚地址中用户号 U 与相联寄存器组中的 6 个用户
号 U1～U6 逐个比较。如果有相等， 就读出对应的 3 位 ID, 并把这 3 位 ID 与多用户
虚地址中的 12 位虚页号 P 直接拼接成 15 位， 用这 15 位作为散列变换部件的输入。
这样， 在快表中可以同时保留 6 个用户 (或 6 道程序 )的常用页表。在 6 个用户或程
序之内切换时， 仍能保持很高的快表命中率。如果用户号 U 与 6 个相联寄存器的比
较结果都不相等。则表示有 6 个之外的新用户进入。这时， 需要用替换算法把一个
不常进入的用户替换出相联寄存器组。只要替换算法好， 就能保证经常进入的用户
或系统服务任务被一直保留在相联寄存器组中。
目前， 许多计算机系统的虚拟存储器都采用与 IBM 370/ 168 计算机类似的方
法， 包括相联寄存器组、硬件的散列压缩、快慢表结构和多个相等比较器等， 而且， 所
有这些措施对应用程序员来说都是透明的。
4.2.4 提高主存命中率的方法
影响主存命中率的主要因素有如下 5 个:

210
● 程序在执行过程中的页面地址流分布情况;
● 所采用的页面替换算法;
● 页面大小;
● 主存储器的容量;
● 所采用的页面调度方法。
在这些因素中， 页面地址流的分布情况是由程序本身决定的， 系统设计人员一般
无能为力。页面替换算法在上一节中已经介绍过， 目前， 多数计算机都采用 LFU 算
法， 它是一种堆栈型替换算法。在当前看来， 已经是一种比较好的算法了。下面， 对
影响主存命中率的另外三个因素作简单的分析。
1.页面大小的选择
页面大小的选择对于主存命中率的影响分析比较复杂， 它取决于程序的访存地
址流以及主存空间的大小。当页面的大小 Sp 改变时， 命中率 H 受到两方面因素的
制约。当 Sp 比较小时， H 随 Sp 的增大而增大。然而， 当 Sp 超过某一值时， H 将随
Sp 的增大而下降， 如图 4.34 所示
。
图 4.34 页面大小与主存命中率的关系
在设计一个虚拟存储器时， 页面大小的选择一般要通过对典型程序的模拟实验
来确定。早期的许多计算机系统， 页面大小一般为 1KB。目前， 大多数计算机的页
面大小都取 4KB,8KB 或 16KB。
2.主存容量
主存命中率 H 随着分配给该程序的主存容量 S 的增加而单调上升， 如图 4.35
所示。在 S 比较小的时候， H 提高得非常快。随着 S 的逐渐增加， H 提高的速度逐
渐降低。当 S 增加到某一个值后， H 几乎不再提高。
在页面替换算法中有这样一个结论， 对于堆栈型替换算法， 命中率随着分配给程
序的页面数的增加而提高。当分配给程序的主存容量增加时， 如果页面大小是一定

211
的， 那么， 页面数就会增加， 因此， 命中率也将提高。如果不是堆栈型算法， 命中率虽
然不会单调上升， 在局部可能会有下降， 但总的趋势还是上升的
。
图 4.35 主存命中率 H 与主存容量 S 的关系
从图 4.35 中可以得到这样一个启发， 在为一道程序分配主存空间时， 对主存命
中率的要求不能过分。当主存容量增加到某一个值之后， 命中率提高得非常慢。这
时， 主存储器中不活跃部分所占的比例很大， 主存资源的利用率就会很低。
实际上， 操作系统在为程序分配主存空间时， 是以页为单位分配的。因此， 图
4.35所示的不应该是一条平滑的曲线， 而是台阶型的。在分配给程序的主存容量比
较小的时候， 台阶非常陡， 随着主存容量的增加， 台阶越来越平缓。
3.页面调度方式
在操作系统中， 页面调度通常有两种方式。一种是分页式， 这种方式在程序装入
主存储器之前对程序进行链接装配， 并且要在把整个程序都调入到主存储器中之后
才能开始运行。另一种方式是请求页式， 这种方式只在发生页面失效时， 才把要访问
的页面进行链接装配， 并调入到主存储器中。
前一种方式的主存命中率可以达到 100%， 但是， 主存利用率比较低， 这是因为
主存储器中不活跃部分所占的比例比较大。而且， 当主存剩余空间小于程序所需要
的主存空间时， 这个程序将无法装入到主存储器中运行。
目前， 大多数计算机采用请求页式调度方式。这种方式虽然具有主存利用率高
等优点， 但是， 在程序执行过程中经常要发生页面失效， 而且处理页面失效需要比较
长的时间。特别是在程序刚开始运行时， 页面失效很频繁。只有当调入的页面数比
较多时， 命中率才开始上升。因而就产生了一种折衷页面调度方案， 即所谓的预取式
调度方式。
预取式调度方式根据程序的局部性特点， 在程序被挂起之后又重新开始运行之
前， 先把上次停止运行前一段时间内用到的页面先调入到主存储器， 然后才开始运行
程序。这样， 在程序一开始运行时， 主存储器中就已经装入了一定数量的页面， 从而

212
可以避免在程序刚开始运行时， 频繁发生页面失效的情况。
4.2.5 虚拟存储器的保护技术
以上各小节的介绍中尚未考虑多用户共享系统资源的情况， 在多用户的情况下，
存储系统应防止因一个用户的错误操作或者程序出错而破坏系统中的其他用户程序
和数据， 还要防止用一个用户不合法的访问主存中其他存储区域而对系统造成的破
坏。对于多道程序系统和多用户系统这是必不可少的。
多道程序设计引出了进程的概念， 进程的分时处理引出了进程切换或上、下文切
换的概念， 进程的切换必须保证进程的正确运行不受影响， 保证进程的正确和安全运
行是系统设计员和操作系统程序员共同的责任。保护的手段主要是对存储区域的保
护， 使一个进程的信息不被另一个进程修改。除了对存储区域的保护外， 多道程序还
要求进程间共享数据， 使进程间进行数据通信。
存储系统的保护分存储区域的保护和访问方式的保护:
为实现区域保护， 对于不是虚拟存储器的主存系统可采用界限寄存器的方式， 由
系统软件设置用户进程访存地址的上、下界， 禁止越界访问， 用户程序不能改变上、下
界的值， 因此也就不能破坏其他用户及系统程序的存储空间， 但对于虚拟存储器系
统， 用户程序的访问空间映像到主存中将不是一个连续的地址空间， 而将分布在主存
中各个页面， 因而不适合采用这种保护方式。
对虚拟存储器的保护方式有映像表保护法、键保护法和环式保护法等。
映像表保护法是段式和段页式管理利用映像表的映像关系， 限制用户程序的访
问地址空间， 用户程序不能访问映像表上找不到的主存页面， 从而起到保护作用， 如
在段表中的每行都设一个段长项。若访存地址超出该段的地址范围， 则产生越界中
断， 或者将程序运行时的进程标识符作为虚地址的最高位， 使不同的进程对应不同的
段， 以防止越段访问。但进程之间一般需要共享存储区域以实现数据通信， 上述方法
不支持存储区的共享。解决的方法是将进程地址空间分成系统区域和用户区域， 系
统区域是各进程共享的存储空间， 用户区域是进程占有的存储空间， 两个区域的地址
分别对应不同的页表。因为各进程的系统区域是共享的， 它们对应同一个主存空间，
因此可以只因一个页表为系统区变换地址。在段式管理中， 通常在段表中设置访问
许可信息。一个段可设置为只读、只可执行或者只可由系统访问。多个进程共享的
段可对每个进程都设置不同的访问许可。
键保护法是由操作系统按当时主存的分配情况， 给主存的每一页分配一个键， 称
为存储键， 它相当于一把锁， 每个用户进程在主存中的各页面都有一个相同的存储
键。进程访问这些页面， 需要一个访问键， 相当于一把钥匙。用户进程的访问键都由
操作系统给定， 存放在处理机的程序状态字或控制寄存器中。IBM 370 系统就采用
这种方法， 它的保护键有 4 位， 分别赋给已调入主存的 16 个活跃进程。
环式保护法是将系统程序和用户程序按访问权限分层， 如图 4.36 所示。最内的

213
几层是系统程序层， 其外面几层是用户程序层， 级别由里向外逐层降低。程序各页的
环号由操作系统给定， 并置入页表， 每个程序都规定了一个上限环号， 即可访问的最
内层的环号。环式保护法既能保护用户程序的出错而不破坏系统程序的工作， 也能
使同一用户程序的外层部分的出错不致破坏其内层部分
。
图 4.36 环式保护的分层
上述保护方法都由硬件支持， 因而有较高的可靠性和速度， 从系统结构上应对存
储保护提供如下手段:
① 提供两种以上的工作状态， 分别表示当前运行的进程是用户进程还是操作系
统进程。
② 提供一些 CPU 状态， 使用户进程可读但不可写。这些状态包括上、下界寄存
器、用户状态/ 系统状态位、中断许可位等。
③ 提供一种在用户状态和系统状态间转换的机制， 通常用户程序可通过系统调
用实现状态的转换， 系统调用时保存现场并使工作状态变为操作系统状态， 系统状态
返回用户状态通常由子程序返回的方式恢复原先状态。
4.2.6 `Pentium` 微处理器的虚拟存储器
作为虚拟存储器管理的典型例子， `Pentium` 微处理器虚拟存储器管理方式， 一方
面继承了过去只有在大、中型计算机系统上才能实现的管理技术， 另一方面又优于这
些大、中型系统最初采用的策略。因为在研制 `Pentium` 微处理器时， 就以支持多种操
作系统为其目标之一。

214
1.`Pentium` 微处理器的工作模式
`Pentium` 微处理器支持三种工作模式:实地址模式、受保护的虚拟地址模式和虚
拟 8086 ( V86 )模式。
(1 )实模式
实模式， 即为实地址模式， 这是自 8086 一直延续继承下来的 16 位模式。逻辑地
址形式为段、偏移， 二者均是 16 位。将段名所指定的段寄存器的内容乘以 16 (即左
移 4 位)， 得到 20 位段基址， 加上 16 位偏移即得 20 位物理地址。
实模式使用 A19 ～A0 的 20 根地址线， 最大物理地址空间为 1MB。最高物理地
址为 FF FFFH， 若段基址加上偏移计算出的物理地址超过 20 位， 则超出位被放弃，
即出现地址环绕现象。例如 F FFF : FFF F 计算机的地址为 10FFEF， 实际送出的物
理地址为 0F FEF。
MS-DOS 操作系统、运行于实模式时的 Windows 3.x 和它们的 16 位应用程序
采用实模式。
(2 )保护模式
保护模式即为受保护的虚拟地址模式， 这是 80386 才具备并一直延续下来的 32
位模式。在这种模式下 `Pentium` 的存储管理部件 MMU 设有分段部件 SU 和分页部
件 PU， 允许 SU， PU 单独工作或同时工作。于是保护模式又细分为如下三种模式:
① 分段不分页模式(段式管理)
此时虚拟地址(或逻辑地址)， 由一个 16 位的选择符(Selector )和一个 32 位的偏
移组成。选择符的最低 2 位与保护机构打交道， 高 14 位用于指定具体的段。一个进
程可拥有的最大虚拟地址空间是 2
14 + 32 = 2
46 = 64 TB。
由 SU 将二维的分段虚拟地址转换成一维的 32 位线性地址。对于分段不分页
模式， 这也就是它的物理地址。分段不分页的好处是， 无需访问页目录和页表， 地址
转换速度快。另外， 对段提供的一些保护定义可以一直贯通到段的单个字节级。
② 分段分页模式(段页式管理)
这是一种在分段基础上添加分页存储管理的模式， 即将 SU 转换后的 32 位线性
地址看成是页目录、页表和页内偏移三个字段所组成的， 由 PU 完成两级页表的查找
将其转换成 32 位物理地址。此模式下一个进程可拥有的最大虚拟地址空间， 同于分
段不分页模式， 也是 64TB。
这是一种兼顾分段分页两种优点的虚拟地址模式， 受到 UNIX System V 和 OS/
2 操作系统的偏爱。
③ 不分段分页模式(页式管理)
这种模式下 SU 不工作， 只是 PU 工作。逻辑地址中无 16 位选择符， 以寄存器
提供的 32 位地址被看成是由页目录、页表和页内偏移三个字段组成。由 PU 完成虚
拟地址到物理地址的转换。进程所拥有的最大虚拟地址空间是 2
3 2 = 4GB, 与上述两

215
种模式相比， 虽然虚拟空间减小了， 但也够用。
这种纯分页的虚拟地址模式， 也称为平展地址模式。它也能提供保护机制， 而且
将虚拟存储器看成是线性分页地址空间， 比分段模式具有更大的灵活性。Windows
N T, Windows 95 操作系统采用了这种模式来支持 32 位应用程序的运行。
(3 )虚拟 86 模式
这是一种在 32 位保护模式下支持 16 位实模式应用程序运行的特别保护模式，
简称 V86 模式。自 80386 开始并一直延续到 `Pentium`, 在这种模式下系统可建立多
个 8086 虚拟机， 每个虚拟机都认为自己是惟一运行的机器， 安全地运行以实模式编
写的 16 位应用程序。这样在 32 位保护模式的操作系统管理下， 系统可同时运行 32
位应用程序和 16 位应用程序。当然， 这种“同时”是由 CPU 切换完成的。 CPU 中
EFLAG 寄存器的 VM( b1 7 位) 即为 V86 模式位， 已经工作在保护模式下的 CPU， 若
VM = 1， 则 CPU 运行 V86 模式， 否则运行一般保护模式。这种相互切换由任务转换
或中断来完成。
V86 模式是将段寄存器的内容乘以 16 作为段的基地址， 再加上 16 位偏移量而
得到访问存储器的线性地址， 这与实模式形成物理地址的方式相同。但此时没有实
模式的地址环绕现象， 即允许 10FFEF 这样的线性地址出现。换句话说， V86 模式具
有 1MB + 64KB 的线性存储空间。另外要注意， V86 模式是一种具有最低特权级( 级
3) 的保护模式。
`Pentium` 除了上述三种主要工作模式外， 还从 80486 继承下来一种称为系统管
理模式 SMM (System Management Mode) 的新模式。通过软件或测到某种硬件条
件时， 可由其他模式进入 SMM。SMM 对其他模式总是隐藏的， 从而允许处理器在
SMM 模式下以软件完成某种功能， 而这些对应用软件甚至对操作系统都是隐藏的。
最早引进这个模式是为了笔记本电脑的电源管理模式。在 CPU 没有实质工作进行
时系统降低电源功耗， 此时就是以 SMM 模式来保护现场。现在 SMM 又增添了新
功能， 能对实际不在系统的硬件予以虚拟化。
2.保护模式下的分段地址变换
在这种方式下的虚拟地址(逻辑地址) 由 16 位段选择符和 32 位偏移量组成。选
择符中的最低两位是请求特权级 RPL( b1 b0 )其余 14 位用于索引表， 相当于“段号”。
`Pentium` 微处理器将逻辑地址变换成线性地址， 变换过程描述如图 4.37 所示。
若在不分页的情况下线性地址即为物理地址。
`Pentium` 微处理器将 8 字节( 64 位) 长的段表项称之为描述符(Descriptor)， 因此
段表被称为描述符表。描述符的一般模式示于图 4.37 中， 它包括 32 位段线性基址，
20 位的段界限， 2 位的描述符特权级 DPL, 1 位的出现位 P ( 表示该段是否已在主
存)， 以及类型位和粒度位 G 等。20 位的段界限指定段的最大长度， G 位指定长度的
单位， G = 0 表示以字节为单位， G = 1 表示以 4KB( 页面大小) 为单位， 即段的最大长

216
图 4.37 `Pentium` 的段表及其地址变换过程
度可达 4GB。
`Pentium` 的保护模式支持多任务环境。每个任务有自己的代码段 ( CS)、数据段
(DS)， 还可有一个或多个附加数据段 ( ES, FS， GS) 以及堆栈段( SS) 等。这些段的描
述符组成局部描述符表 LDT。各任务公用的代码段、数据段的描述符， 以及系统段
(如 LDT、任务状态段 TSS 等 )的描述符组成全局描述符表 GDT。全系统只有一个

217
GDT， 有多个 LDT。GDT 由 GDTR 指向， 48 位的 GDTR 包括 32 位的 GDT 的基地
址和 16 位的表界限( GDT 不超过 64KB) 。当前任务使用的 LDT 由 LDTR 寄存器
指向， 但 LDTR 是用户不可见的。当任务发生切换时由操作系统访问 GDT 取得此
任务的 LDT 描述符， 将表基址、表界限、属性等装入 LDTR。
因此， 一个任务可 使用两级段表: 一个是全系 统各任务共同的全 局描述符 表
GDT ;另一个是任务自己的局部描述符表 LDT。当前具体使用哪个段表由选择符的
TI 位指示， TI 位 = 0 使用 GDT, TI 位 = 1 使用 LDT。
需要说明的是， 全系统还有一个中断描述符表 IDT。系统中所用的每类中断在
IDT 中都有一个描述符， 最多可有 256 个描述符。每个描述符也是 8 字节， 包含相应
的中断服务程序入口地址和特性。通过 INT 指令、外部中断向量和 CPU 内部的异
常来访问 IDT。
3.保护模式下的分页地址转换
无论是分段分页模式下经 SU 送来的 32 位线性地址， 还是不分段分页模式下由
程序直接给出的 32 位线性地址， 都经分页部件 PU 转换成 32 位物理地址。
`Pentium` 有两种分页方式。一种是 4KB 的页， 使用页目录表、页表两级页表进
行地址转换， 这是从 80386/ 80486 继承下来的分页方式。另一种是 `Pentium` 新增加
的分页方式， 页为 4MB 大小， 使用单级页表进行地址转换。
(1 )4KB 分页方式
32 位的线性地址， 基地址空间为 2
32 = 4GB, 页面大小为 4KB( 2
12 )， 则会有 1M
个页面。若是使用单级页表，1M 个页表项的页表规模太庞大了。 `Pentium` 采用两级
页表方式， 将线性地址相邻接的 1K 个页面组成一组， 使用一个 1K 个表项的页表;这
一组页面， 在页目录表中有一对应的页目录项， 页目录表有 1K 个表项。
页目录表项和页表项都是 4 字节(32 位)， 其结构如图 4.38 所示。这样， 页目录
表和页表都是 4KB 长， 即页框的大小， 访问主存寻找页目录表和页表都很方便。
相应地， `Pentium` 将 32 位线性地址看成是由三个字段组成: 高 10 位为页目录
(号)， 中间 10 位为页面(号)， 最低 12 位为页内字节偏移。
不使用物理地址扩充方式(即 32 位地址方式 )时， 全系统只有一个页目录表， 由
CPU 控制寄存器 CR3 指向此表的起始地址。CPU 首先以线性地址的页目录号部分
为索引(×4 )查找页目录表， 由相应的页目录表项得到其页表的基址; 再以线性地址
的页面号部分为索引(×4 )查找该页表， 由相应的页表项才得到分配给此页面的主存
页框基地址。由页框基地址(20 位)与线性地址中的页内偏移 (12 位)相拼接， 最终得
到所需要的 32 位物理地址。地址转换涉及到两次访问主存， 其过程见图 4.38。
(2 )4MB 分页方式
页面大小为 4MB 的分页方式使用单级页表， 减少了一次主存访问， 地址转换过
程加快了。此方式下，32 位线性地址分为高 10 位的页面 ( 号) 和低 22 位的页内偏移

218
其中 : P = 出现 位， US = 用户/ 监督 位， PCD = 页 `Cache` 禁 止位， D =“ 脏”位， RW = 读/ 写 位,
PWT = 页写直达位， A = 访问过位， AVL = 系统程序员可用位。
图 4.38 `Pentium` 4KB 分页方式地址转换
两个字段。32 位地址模式下， 全系统只一张页表， 由控制寄存器 CR3 指向。此页表
有 1K 个表项， 每项 4 字节(32 位)。
注意， 此时页表项的 b7 位为 1, 此位称为页大小 PS( Page Size) 位， 为 0 表示是
4KB 页。CPU 以线性地址高 10 位为索引( ×4 ) 查找 CR3 指向的表时， 若读取表项
内容的 b7 位为 0， 知道这是一个页目录表， 需要第二次访问主存才能得到 4KB 页的
页框基地址。
4MB 分页方式的地址转换过程如图 4.39 所示。
我们看到， 除存取控制位之外， 两种分页方式的页表项中都有 P， A， D 三位。 P
位为出现位， 若该位为 1, 表示此页面已装入主存; 若该位为 0, 对此页的访问将引发
缺页(或称页故障) 。A 位为访问过位， 此页装入主存之后被访问过， 置 A 位为 1, 否
则该位为 0, D 位为“脏”位， 即修改过位， 该页被替换时， 若 D 位为 1, 则需将此页写回
磁盘， 否则弃之即可。
另外， 页表项中还有 PCD( 页 `Cache` 禁止)和 PW T (页写直达 )两位， 用于页级的
是否禁止 `Cache` 以及采 用的是写 直达 法还是 写回 法的控 制 ( 有关 此内 容请参 见

219
其中 : P = 出现位， RW = 读/ 写位， US = 用户/ 监督位， PWT = 页写直 达位， PCD = 页 `Cache`
禁止位， A = 访问过位 D =“脏”位。
图 4.39 `Pentium` 4MB 分页方式地址转换
`Cache` 存储器部分 )。`Pentium` 有两个输出引脚 PCD 和 PWT， 其生成逻辑如图 4.40
所示。
这两个信号既用于对片外( L2 ) `Cache` 的控制， 也在 CPU 内部使用， 以控制片内
( L1 )`Cache` 的状态转换以及写修改方式
。
图 4.40 PCD、PWT 信号生成逻辑
4.3 高速缓冲存储器(`Cache`)
1967 年 Gibson 提出高速缓冲存储器( `Cache`) 技术， 1969 年首先在 IBM 360/ 80
计算机上得以实现。现在， 这一技术不仅为大、中型计算机而且也为小型、微型计算
机广泛采用。
一般的处理机中只有一级 `Cache`, 它与主存储器构成一个两级的存储系统。一
些高性能的处理机都采用两级 `Cache`, 第一级 `Cache` 在 CPU 内部， 容量很小， 速度很
快;第二级 `Cache` 在主板上， 容量较大， 速度比第一级要低 5 倍左右。也有部分高性
能的处理机采用三级 `Cache`, 前两级在 CPU 内部。本节主要介绍由一级 `Cache` 与主
存构成的 `Cache` 存储系统( 以下简称 `Cache`) 。
## 4.3.1 `Cache` 工作原理
前面已经提及 `Cache` 与主存储器相比容量较小， 它所保存的信息只是主存内容
的一个子集。特别要注意的是， CPU 与 `Cache` 之间的信息交换是以“字”为单位， 而
`Cache` 与主存之间的信息交换是以“块”为单位， 一个块由若干字组成， 是定长的。块
的大小通常取一个主存周期所访问到的字节数。例如， 在 IBM370/ 168 计算机中， 主
存储器采用低位交叉存取方式， 即主存共有四个存储体， 每个存储体字长为 8 字节
(32 位)。因而相应块的大小为 32 字节。`Cache` 主存结构示意图如图 4.41 所示
。
图 4.41 `Cache`-主存系统结构示意图
当 CPU 试 图读取 主存 一个字 时， 发 出此字 内存地 址到 `Cache` 和 主存， 此 时
`Cache` 控制逻辑依据地址进行判断此字当前是否在 `Cache` 中。若是， 此字立即递交
给 CPU， 否则， 要用主存读取周期把这个字从主存读出送到 CPU， 与此同时把含有

221
这个字的整个数据块从主存读出送到 `Cache` 中。由于程序的存储器访问具有局部
性， 当为满足一次访问需求而取来一数据块时， 下面的多次访问很可能读取此块中的
其他字。
4.3.2 地址映像与地址变换
与页式虚拟存储器类似， `Cache` 存储系统中也有地址映像与地址变换、替换算法
等问题。而地址映像与地址变换是紧密相关的， 采用什么样的映像规则， 就必然有与
之相关的地址变换方式。因此， 必须将它们放在一起介绍。
与页式虚拟存储器的显著区别是， `Cache` 存储系统的地址映像与变换、替换算法的
实现等全部由硬件实现， 因此， 它不仅对应用程序员透明, 而且对系统程序员也透明。
在由 `Cache`—主存储器组成的 `Cache` 存储系统中， 将主存储器分成 n 块， 块号用
Bj 表示(j = 0，1，2， ⋯， n - 1 )， 将 `Cache` 存储器分成 m 行， 行号用 Li 表示 (i = 0, 1， 2,
⋯， m - 1) 。`Cache` 的行大小与主存的块大小相等， 即行的字节数和块的字节数等
长， 但是 mn n。结构图如图 4.42 所示。图中 `Cache` 共有 n 行， 每行可存放 k 个字，
标记( Tag)用于存放对应主存块地址
。
图 4.42 `Cache`—主存结构示意图

222
下面以 `Cache` 大小为 8 行、主存的大小为 256 块为例， 分别介绍三种主要的地址
映像和地址变换过程。
1.全相联映像与变换
全相联映像( Fully Associative-Mapping) 常简称为相联映像， 这种方式是将一个
主存块的地址(块号) 与块的内容一起都存于 `Cache` 行中。块地址保存于 `Cache` 行的
标记( Tag)部分中。这种带着全部地址一起保存的做法， 直接结果是一个块可以拷
贝到 `Cache` 的任意一行上， 极其灵活。全相联映像关系举例如图 4.43 ( a) 所示。由
于主存共有 256 块， 故 `Cache` 行中的标记必须用 8 位指示。
地址变换过程如下:
1.对于一个指定的内存地址将其块号与 `Cache` 所有行的标记同时比较;
2.若某行标记与块号相等， 则命中， 再以字地址 W 检索到指定字单元;
3.若所有标记都不相等， 即失效， 就用主存地址访问主存。
全相联映像方式的主要缺点是比较器电路难以设计与实现， 尤其是 `Cache` 的行
数较多时。一般是将全部标记用一个相联存储器实现， 全部数据用一个普通 RAM
实现， 即全相联 `Cache` 由一个相联存储器和一个 RAM 组成。相联存储器价格贵、容
量小。全相联映像方式只适合于小容量 `Cache` 采用。
2.直接映像与变换
直接映像(Direct-Mapping )方式虽然也是多对一的映像关系， 但一个主存块只
能拷贝到 `Cache` 的一个特定行位置上去。块号 j 与能保存此块的行号 i 有如下关系:
i = jmod m ( m 是 `Cache` 总行数)
此方式是将 s 位的块地址分成两部分， 低序的 r 位作为 `Cache` 的行地址， 高序的
s-r 位作为标记( Tag)与块数据一起保存在该行。直接映像举例如图 4.44 ( a) 所示，
由于 `Cache` 为 8 行， 主存 256 块，256÷8 = 32, 所以， `Cache` 标记位只用于存放 32 组
中的任一组号， 仅用 5 位。
直接映像地址变换检索过程如下:
● 以主存地址中的 r 位行号， 找到此 `Cache` 行。
● 取出 `Cache` 行中的标记字与主存地址中的标记作相等比较。
● 若比较相等， 则命中。以主存地址中的最低 W 位查找访问指定单元内容。
● 若比较不相等， 则失效。用主存地址直接访问主存。
直接映像地址检索过程如图 4.44 ( b) 所示。
直接映像方式的优点是硬件简单， 成本低; 缺点是每个主存块只有一个固定的行
位置可存放。如果块号相距 m 整数倍的两个块， 要存于同一 `Cache` 行时， 就要发生
冲突。此时， `Cache` 其他位置即使有空行也用不上。发生冲突时就要将原先已存入
的块换出 `Cache`, 但很可能过一段时间又要换入， 频繁换入、换出会使 `Cache` 效率降

223
图 4.43 `Cache` 带标记的全相联地址变换
低。直接映像 `Cache` 适合于需要大容量 `Cache` 的场合， 更多的行数也可以减小冲突
的机会。

224
图 4.44 `Cache` 带标记的直接映像方式地址变换

225
3.组相联映像与变换
上述两种映像方式的优缺点正好相反。从存放位置的灵活性以及命中率来看，
全相联映像方式要好;就比较电路简单以及硬件投资少来看， 直接映像方式要优。若
有一种方式能适度地兼有两者优点又尽量避免两者缺点就太好了， 这个折衷方案就
是组相联映像方式(Set-Associative Mapping)。
这种方式是将 `Cache` 分成 u 组， 每组 v 行。主存块存放到哪个组是固定的， 至于
存放到该组哪个行是随意的。组间直接， 组内相联， 即有如下关系:
n = u×v, 组号 q = jmod u
块内存地址中 s 位块号划分成两部分， 低序的 d 位 ( 2
d = u ) 用于表示 `Cache` 组
号， 高序的 s-d 位作为标记( Tag)， 与块数据一起位于此组的某行中。
组相联映像方式举例如图 4.45 (a)所示。其中， `Cache` 8 行分成 4 组， 每组 2 行。
即 u = 4, v = 2, 对于指定的主存块号 j( 0, 1， ⋯， 255)， 可以映像到 `Cache` 相应的组号
(组内任意行) 如表 4.5 所示。
表 4.5
 
组相联的地址变换(检索) 过程如图 4.45 ( b) 所示。变换过程描述如下:
① 以主存块号地址低位( d 位)检索到 `Cache` 相应组。
② 以主存块号地址高位(s-d )位与该组 u 行中的所有标记， 同时进行比较 (相联
比较)。
③ 若相等， 则相等行命中， 以主存地址的 W 位去检索该行的指定字， 即完成对
指定单元的R/ W操作。
④ 若全不相等， 则 `Cache` 访问失效。以主存地址直接访问主存储器， 完成对字
的访问和信息块的调入。
组相联映像方式中的每组行数比一般取值都比较小， 典型值是 2, 4 或 8, 最大为
16。这是因为 u 值较小时在设计上容易实现， 而且为了强调比较的规模和存放的灵
活程度， 常称为 u 路组相联 `Cache`。
全相联和直接映像是组相联的两种极端情况。因为 m = u×v, 若组数 u = 1， 全
部 `Cache` 行为一大组， 即为全相联映像方式; 若行数 v = 1, 每组只有一行， 即为直接
映像。在设计中， 根据具体情况， 调整 u 和 v 的值， 可适当兼顾两者的优点。
## 4.3.3 `Cache` 替换算法及其实现
与页式虚拟存储器相比， `Cache` 存储器也存在行调用和行替换及其替换算法。

图 4.45 `Cache` 带标记的 u 路组相联映像与变换过程

所不同的是， 由于 `Cache` 速度很高， 替换算法必须全部由硬件实现。
替换算法与 `Cache` 的组织方式紧密相关。对于直接映像方式的 `Cache` 来说， 因
为主存块只有一个特定的行位置可存放， 所以只需把此特定行位置上的原主存块换
出 `Cache` 即可。对于全相联和组相联的 `Cache` 来说， 就要从允许存放新主存块的若
干特定行中选取一行换出。从原理上讲， 虚拟存储器中的替换算法， 在 `Cache` 中都能
适用， 但由于 `Cache` 的特殊性， 使用较多的是 LR U ( LFU ) 替换算法。下面介绍这种
算法的几种实现方法。
### 1.计数器法
这种实现方法是在 `Cache` 的每行中设置一个计数器， 计数的位数与 `Cache` 组内
行数相关。如 `Cache` 每组为 4 行， 则计数器有两位二进制计数。
计数器的使用及管理规则是:
① 初始化:各计数器清零。
② 调进:新调进块的行计数器清零， 其余加 1。
③ 替换:被替换的行计数器清零， 其余加 1。
④ 命中: 被命中的行计数器清零。凡计数值小于命中行计数值则加 1, 其余计数
值不变。
例如在 IBM 370/ 165 机中的 `Cache` 采用组相联映像方式。每组 4 行， 每行设置
有一个 2 位计数器。在访问 `Cache` 的过程中， 主存块的装入、命中及替换时， 以及计
数器的工作情况， 如表 4.6 所示。
表 4.6
计数器实现 LRU 过程
 
LRU 算法硬件实现不是非常困难， 特别是对于两路组相联的 `Cache` 而言， 情况
会大为简化。因为一个主存块只能在一个特定组的两行中做出选择， 完全不需要计
数器， 一组内的两行只需一个二进位即可。如果规定一组中的 A 行拷贝进新数据则
置二进位。另一行(B 行 )拷贝进新数据将此位置零。那么当需要替换时， 只需检查

228
此二进位(乒乓位) 的状态即可， 为 0 换出 A 行， 为 1 换出 B 行， 实现了保护新内容的
原则。后面将看到， `Pentium` 处理器内的数据 `Cache` 是一个两路组相联结构， 采用的
是 LR U 替换策略。
2.堆栈法
在页式虚拟存储器中曾经介绍过， LRU 算法是堆栈型替换算法， 对于 LRU 算
法， 堆栈 St 中由栈顶到栈底的各项 (行 ) 恒反映出在 t 时刻， 实存中各页被访问过的
近远次序， 以及每访问一页， 堆栈 St 中各项的变化过程。结果是此堆栈的栈顶恒存
放近期最近访问过的页的页号， 而栈底恒存放近期最久未访问过的页的页号， 即准备
被替换掉的页的页号。那么在 `Cache` 存储器中完全可按此思想组成一个实际的硬件
堆栈。对于组相联映像， 每组只需设置一个容量等于组内行数的堆栈， 如图 4.46 所
示。每次把刚访问的 `Cache` 行号与堆栈中的各个行号相联比较。如果没有相符的，
将此行号压入堆栈成为栈顶项， 原已在堆栈中的各项都顺次下移一行， 如果有相符
的， 将此行号从堆栈中取出再压入堆栈成新的栈顶， 并使原先存放该行号的项到栈顶
的那些项均下移一行， 直到堆栈被全部装满( 即 `Cache` 各行位置全被占用 )后又发生
失效时， 栈底项存放的行号就作为被替换的 `Cache` 行号
。
图 4.46 LRU 算法经堆栈实现 ( 需有相联比较功能 )
由于这种硬件堆栈既要有相联比较的功能， 又要有能全部下移、部分下移和从中
间取出一项的功能， 成本较高， 因此只适用于组相联且组内块数较少的 LR U 算法替
换场合。
为了避免栈中各行内容要同时下移， 以节省成本， 也可采用另一种变形， 让存放
行号的寄存器的几何位置与 `Cache` 中的行号对应， 用寄存器存放值的大小表示该块
已被访问过的远近次序。以组相联映像为例， 每组均使用如图 4.47 那样的一个寄存
器组， 由 2
v 个寄存器组成， 每个寄存器为 v 位宽， 可以存放表示从 0-2
v-1 的次序值。

229
如果让愈是最近访问的， 其次序值愈小， 则替换块的确定就只需通过相联比较求最大
值， 即可找到该最大值所在的寄存器号， 也就是对应 `Cache` 中应被替换行的行号
。
图 4.47 组相联 LRU 算法经寄存器实现
( 每组一个，需有相联比较功能)
3.比较对法
堆栈法需要硬件有相联比较的功能， 因此其速度较低， 也比较贵。那么， 能否不
用相联比较， 只用一般的门、触发器来实现 LRU 替换算法呢 ? 比较对法就是其中的
一种。
比较对法的基本思路是让各行成对组合， 用一个触发器的状态表示该比较对内
两行访问的远近次序， 再经门电路就可找到 LRU 行。如有 A, B, C 三行， 组成 AB,
AC, BC 三对。各对内行的访问顺序分别用“对触发器”T AB， T A C， TBC 表示。 T AB 为
“1”, 表示 A 比 B 更近被访问过; T A B 为 0, 表示 B 比 A 更近被访问过。 TA C， TBC 也类
似此定义。这样， 当访问过的次序为 ABC, 即最近被访问过的为 A， 最久未被访问的
是 C, 则这三个触发器状态是 TA B = 1， TA C = 1, TBC = 1。如果访问过的次序为 BAC,
C 为最久未被访问过， 则有 TA B = 0， TA C = 1， TBC = 1。因此 C 作为最久未被访问过的
替换块， 用布尔代数式必有
CLR U = T A B ·T A C ·TBC + T AB · TA C · TBC = TA C · TBC
同理可得
BL R U = T AB · TBC
ALR U = T A B ·T A C
因此， 完全可以用与门、触发器等硬件组合实现， 如图 4.48 所示。
显然， 每次访问某行时， 应改变与该行有关的比较对触发器的状态。以上述 A，
B, C 三行为例， 每次访问 A 后需改变与 A 有关的比较对触发器的状态， 置 T AB， T AC
为 1, 以反映 A 比 B 更近、A 比 C 更近访问过; 访问 C 后， 置 TA C， TBC 为 0。据此可定
出各个触发器的输入控制逻辑， 如图 4.48 所示。

230
图 4.48 用比较对法实现 LRU 算法
现在来分析比较对法所用的硬件。由于每行均可能作为 LRU 行， 其信号需用
与门产生， 所以有多少行， 就得有多少个与门; 每个与门接收与它有关的对触发器来
的输入， 例如 AL R U 与门要有从 TA B， T A C 来的输入， BL R U 要有从 T AB， TBC 来的输入， 而
与每块有关的对触发器数为块数减 1, 所以与门的输入端数是行数减 1。若 P 为行
数， 两两组合， 比较对触发器数为 C
2
p = P·( P - 1 )/ 2。表 4.7 列出了比较对法行数 P
与门数、门的输入端数及比较对触发器数的关系。
表 4.7
比较对触发器数、门数、门的输入端数与行数的关系
行数
 
从 4.7 表可以看出， 比较对触发器的个数会随块数增多以极快的速度增加， 门的
输入端数也线性增加， 这在工程实现上会带来麻烦， 所以比较对法只适用于组内行数
较少的组相联映像 `Cache` 存储器。在行数少时， 它比前述堆栈法易于实现。若组内
行数超过 8, 则所需比较对数就多到不能承受了。不过这时也还可以用多级状态位
技术来减少所用的比较对数。
4.3.4 `Cache` 一致性与写策略
在由 `Cache` 和主存储器共同构成的 `Cache` 存储系统中， 从工作原理可知， CPU
只对 `Cache` 某行信息进行修改， 而主存储器内容却没有修改， 而其他的主控者 (处理

231
器、I/ O 控制器等) 全由主存储器得到过时的信息。同样， 若其他主控者修改主存储
器信息， 而 `Cache` 却没有得到修改相应行的通知， CPU 会由 `Cache` 得到过时的信息。
这两方面都会导致 `Cache` 与主存内容不一致， 也就是 `Cache` 的一致性问题。
为了维护 `Cache` 的一致性必须从两个方面入手， 一方面涉及到处理器所采用的
`Cache` 写策略， 另一方面涉及到处理器所采用的 `Cache` 一致性协议。
1.写直达法 (Write-Through)
这一策略的中文译名不尽相同， 有的称全写法， 有的称写贯通法。顾名思义， 它
的做法是当 `Cache` 写命中时， `Cache` 与主存同时发生写修改。这种策略显然较好地
维护了 `Cache` 与主存的内容一致性， 但这并不等于说全部解决了一致性问题。例如
在多处理器系统中各 CPU 都有自己的 `Cache`， 一个主存块若在多个 `Cache` 中都有一
份拷贝的话， 某个 CPU 以写直达法来修改它的 `Cache` 和主存时， 其他 `Cache` 中的原
拷贝就过时了。即使在单处理器系统中， 也有 I/ O 设备不经过 `Cache` 向主存写入的
情况。总之， 仍要关注一致性问题。
当 `Cache` 写失效时有写分配与写不分配之分。写分配是指完成了对主存修改
后， 将修改行装入 `Cache`， 即为写失效的 `Cache` 行分配一个新行。写不分配是指仅对
存储器修改， 而再无其他动作。
写直达法是写 `Cache` 与写主存同步进行， 其优点是 `Cache` 每行无需设置一个修
改位以及相应的判测逻辑。80486 处理器内的 `Cache` 采用的就是写直达法， 这也可
从其组织结构中无修改位看出。写直达法的缺点是， `Cache` 对 CPU 向主存的写操作
无高速缓冲功能， 降低了 `Cache` 的功效。
2.写回法 (Write-Back)
使用这种策略， 当 CPU 对 `Cache` 写命中时， 只修改 `Cache` 的内容不立即写入主
存， 只当此行被换出时才写回主存。这种策略使 `Cache` 在 CPU-主存之间， 不仅在读
方向而且在写方向上都起到高速缓存作用。对一 `Cache` 行的多次写命中都在 `Cache`
中快速完成修改， 只是需被替换时才写回主存， 减少了访问主存的次数从而提高了效
率。为支持这种策略， 每个 `Cache` 行必须配置一个修改位， 以反映此行是否被 CPU
修改过。当某行被换出时， 根据此行修改位为 1 还是为 0, 决定是将该行内容写回主
存还是简单地弃之而不顾。
当 `Cache` 写失效时， 写回法也有写分配与写不分配。写分配是指由主存读取此
行(失效行)， 调入 `Cache` 后再完成对此行的修改 (主存对应块没有修改 )。写不分配
是指将处理器 的写 请求 递交 给主 存， 在 主存 中 完成 修 改， 修 改 后的 块 也不 调 入
`Cache`。
一般而言， 写直达法多采用不分配法， 而写回法多采用写分配法。

232
3.写一次法 (Write-Once)
写一次法是一种基于写回法又结合了写直达法的写策略， 即写命中和写未命中
的处理与写回法基本相同， 只是第一次写命中时要同时写入主存。这种策略主要用
于某些处理器的片内 `Cache`, 例如 `Pentium` 处理器的片内 `Cache` 采用的就是写一次
法。因为片内 `Cache` 写命中时， 写操作就在 CPU 内部高速完成， 若没有内存地址及
其他指示信号送出， 就不便于系统中的其他 `Cache` 监听。采用写一次法， 在第一次片
内 `Cache` 写命中时， CPU 要在总线上启动一个存储写周期。其他 `Cache` 监听到此主
存块地址及写信号后， 即可把它们各自保存的该块拷贝及时作废( 无效处理 )。而后
若有对片内 `Cache` 此行的再次或多次写命中， 则按回写法处理， 无需再送出信号了。
这样虽然第一次写命中时花费了一个存储周期， 但对维护系统全部 `Cache` 的一致性
有利， 而大多数的 `Cache` 写操作不涉及到片外， 对指令流水执行有利。
4.MESI 协议
当代多处理机系统中， 每个处理机都有自己各自的 `Cache`, 各节点通过总线、交
叉开关等互连机构连在一起， 如图 4.49 所示。同一主存的拷贝能同时存于不同的
`Cache` 中， 若允许各 个处理 器各 自独立 地修 改自 己的 `Cache`， 就 会出 现修 改后 的
`Cache` 与主存内容不一致的问题。解决多处理机系统中 `Cache` 一致性方法的协议，
分为两类
:
图 4.49 多处理器系统中的 `Cache`/ 主存结构
目录协议 ( Directory Protocol) : 它 由位 于 主存 的 目录 来 保存 有 关各 个 局 部
`Cache` 的全局性状态信息， 并由一个集中式的主存-`Cache` 控制器来维护 `Cache` 的一
致性。
监听协议(Snop Protocol) : 它是将维护 `Cache` 一致性的责任分散到各个 `Cache`
控制器。每个控制器必须识别出它的 `Cache` 中哪些块是与其他 `Cache` 共享的。当修

233
改一个共享块时必须在系统中广播有关信息， 其他 `Cache` 控制器监听到此信息时予
以响应。根据广播的信息以及反应的不同， 监听协议又分为写—修改协议和写—无
效协议两种方式。
写-修改(Write-Update)协议是， 某处理器要修改它的 `Cache` 中一个共享块时要
广播具体的修改字及地址， 容纳有此共享块的各个 `Cache` 同时予以修改。写-无效
(Write-Invalidate)协议是， 某处理器要修改它的 `Cache` 中的一个共享块时， 无需广播
具体的修改字， 只需给出块地址和其他必要的指示信息， 令其他 `Cache` 中的此块变为
无效， 然后处理器对其 `Cache` 的此块完成一次本地写操作。
MESI 协议状态转换规则:
MESI 协议是一种采用写—无效方式的监听协议。它要求每个 `Cache` 行有两个
状态位， 用于描述该行当前是位于修改态( M )、专用态 ( E)、共享态(S)或者无效态( I)
中的哪种状态， 从而决定它的读/ 写操作行为。这四种状态的定义是:
● 修改态( Modified)， 此 `Cache` 行已被修改过( 脏行)， 内容已不同于主存并且为
此 `Cache` 专有。
● 专有态( Exclusive)， 此 `Cache` 行内容同于主存， 但不出现于其他 `Cache` 中。
● 共享态(Shared)， 此 `Cache` 行内容同于主存， 但出现于其他 `Cache` 中。
● 无效态( Invalid )， 此 `Cache` 行内容无效(空行) 。
MESI 协议适合以总线为互连机构的多处理器系统。各 `Cache` 控制器除负责响
应自己 CPU 的内存读/ 写操作 (包括读/ 写命中与未命中 ) 外， 还要负责监听总线上
的其他 CPU 的内存读/ 写活动(包括读监听命中与写监听命中 )， 并对自己的 `Cache`
予以相应的处理。所有这些处理过程要维护 `Cache` 一致性， 必须符合图 4.50 所示的
MESI 协议状态转换规则。
下面由图的四个顶点出发， 介绍转换规则:
① 状态为 I 的 `Cache` 行是内容和标记都无效的空行， 没有监听命中与否的问
题， 只有在 CPU 对 `Cache` 读/ 写未命中时用来分配给新行。当读未命中时， 启动了一
个存储读总线周期将读取的主存块填入特定位置的空行中并建标记， 还要依据其他
`Cache` 返回的有/ 无监听命中指示， 相应建立 S/ E 状态。当写未命中时， 也要由主存
读入含欲修改字的块， 然后在 `Cache` 内完成写修改并建新状态 M。然而此时有三点
要特别注意:第一， 在写未命中时虽然 CPU 启动的是存储读总线周期， 但它的 `Cache`
控制逻辑也同时送出一个“读是用于写”信号 RWITM ( Read-With-Intent-To-Modi-
fy)， 通知其他 `Cache` 将此周期作为写周期来监听。第二， 若其他某个 `Cache` 发生监
听命中， 而且命中行是 M 态， 则这个 `Cache` 要暂时中止“先读后写”活动， 取得总线控
制权将此 M 态行写回主存， 然后放弃控制权让原先的写请求重新开始先读后写操
作。第三， M 态行写回主存后， 其状态变为 I; 但是若原先的写请求是一种猝发式， 即
CPU 写入 `Cache` 及主存的是一个完整的新行， 则此写监听命中的 M 态行没有写回
主存的必要， 只简单作废即可。
图 4.50 MESI 协议状态转换规则
② S 状态行的读命中或读监听命中都不改变其状态， 只是读监听命中时要发出
监听命中指示， 以使其他 `Cache` 在读未命中时填入的新行建状态为 S。写监听命中
时要将该行作废(状态变为 I) 。CPU 对 S 态行的写命中， `Cache` 在判测的同时将此
写请求通知到总线上， 以使其他 `Cache` 同此共享行发生写监听命中而作废， 这称为写
无效处理， 然后 CPU 对此 S 态行完成 `Cache` 内部写修改并进入 M 态。
③ CPU 对其 `Cache` E 态行的读命中不改变其状态， 写命中也只是在 `Cache` 内部
完成写修改后进入 M 态， 无需它者监听。E 态行的读监听命中， 表示总线上别的
`Cache` 正在读同地址的主存块以建立新行， 此时除它的状态要改为 S 外， 还要发出读
监听命中指示， 以使别的 `Cache` 也将填入新行建 S 态。E 态行的写监听命中， 表示别
的 `Cache` 由于写未命中而访问同地址的主存块， 此 E 态行的内容将是过时的， 故将
其作废即可。
④ CPU 对其 `Cache` M 态行的读/ 写命中， 在完成相应的读/ 写修改操作后不改
变其状态， 也是无信号送到总线上无需他者监听。M 态行的写监听命中处理已在①
中介绍了， 它最后进入 I 态被作废。注意， 在收到 RWITM 信号后， 有此 M 态行的
`Cache` 要抢占总线先行将 M 态作废。注意， 在收到 RWITM 信号后， 有此 M 态行的
`Cache` 要抢占总线先行将 M 态行的内容写回主存， 因为它含有此主存块修改过的信
息而且那个“先读后写”的修改字不一定能覆盖此 M 态行的全部修改过的位置。当
然， 若原是写整个新行 ( 猝发式写 ) 就没有把此 M 态行抢先写回主存的必要了。 M 态行的读监听命中， 也要抢先将其行内容写回主存， 以使发生读未命中的 `Cache` 填入
的新行是最新的而不是过时的。此后， 它变为 S 态同时也发出一个读监听命中指示，
以使他者 `Cache` 将填入的新行建状态为 S。
由上述分析可以看出， 虽然各 `Cache` 控制器随时都在监听系统总线， 但能监听到
的只有读未命中、写未命中以及共享行写命中三种情况。读监听命中的有效行都要
进入 S 态并发出监听命中指示， 但 M 态行要抢先写回主存; 写监听命中的有效行都
要进入 I 态， 但收到 RWI TM 时的 M 态行要抢先写回主存。总之监控逻辑并不复
杂， 增添的系统总线传输开销也不大， 但 MESI 协议却有力地保证了主存块脏拷贝在
多 `Cache` 中的惟一性， 并能及时写回保证 `Cache`-主存存取的正确性。
## 4.3.5 `Cache` 性能分析
1.`Cache` 系统的加速比
假设 `Cache` 的访问时间为 tc， 主存储器的访问时间为 tm， `Cache` 存储系统的等效
访问时间为 ta， `Cache` 命中率为 Hc， 那么 `Cache` 存储系统的等效访问时间为:
ta = tc · Hc + (1 - Hc ) tm
则 `Cache` 系统的加速比 Sp 可定义为:
Sp = tm

由此可以看出， `Cache` 系统的加速比 Sp 是命中率 H 和主存访问时间与 `Cache`
访问时间比值的函数。在 `Cache` 系统中， 主存储器和 `Cache` 的访问时间由于受器件
条件的限制， 一般为一定值。只有提高 `Cache` 系统的命中率 Hc ( 即降低失效率)， 才
是提高加速比 Sp 的最好途径。
### 2.降低 `Cache` 的失效率
有人对 1989～1995 年发表的论文进行过检索， 对其中有关 `Cache` 主题 1 600 多
篇文章进行综述后， 提出了一个有关 `Cache` 优化和改进 `Cache` 技术的基本性能公式。
平均存储器访问时间 = 命中时间 + 失效率×失效开销
按照产生失效的原因不同， 可以将失效分为三类( 简称为“3C”) :
● 强制性失效(Compulsory miss) :当第一次访问一个块时， 它不在 `Cache` 中， 需
从下一级存储器中调入 `Cache`, 这就是强制性失效。也称为冷启动失效或首
次访问失效。
● 容量失效(Capacity miss) : 如果程序在执行时所需的块不能全部调入 `Cache`
中， 则当某些块被替换后， 若又重新被访问， 这种失效称为容量失效。
● 冲突失效(Conflict miss) : 在组相联或直接映像的 `Cache` 中， 若太多的块映像到同一组(块) 中， 则会出现该组中某个块被别的块替换， 然后又被重新访问的
情况， 这就是冲突失效， 也 称为碰撞失效 (Conllision ) 或 干扰失效 ( Interfer-
ence) 。
下面简要介绍减少失效率的几种方法:
(1 )增加 `Cache` 块大小
降低 `Cache` 失效率最简单的方法是增加块大小。在图 4.51 中给出了一组不同
容量的 `Cache` 失效率的关系曲线图， 表 4.8 中给出了具体数据， 从中可以看出
:
图 4.51 失效率随块大小变化的曲线
表 4.8
各种块大小情况下 `Cache` 的失效率
 
① 对于给定的 `Cache` 容量， 当块大小增加时， 失效率开始是下降的， 后来反而上
升了。
② `Cache` 容量越大， 使失效率达到最低的块大小就越大。例如在表 4.8 中块大
小分别为 1KB,4KB, 16KB,64KB 和 128KB 时， 使失效率达到最低的块大小分别为
32B, 64B, 64B,128B 和 128B(或 256B)。
导致上述失效率先下降后上升的原因， 在于增加块大小会产生双重作用。一方
面它减少了强制性失效， 因为程序的局部性原理包括时间上和空间上的局部性， 增加
块大小利用了空间局部性;另一方面， 由于增加块大小会减少 `Cache` 中块的数目， 所
以也可能会增加冲突失效， 在 `Cache` 容量较小时甚至会增加容量失效。刚开始增加块大小时， 由于块大小还不是很大， 上述的第一种作用超过了第二种作用， 从而使失效率下降， 但等到块大小增加到较大时， 第二种作用超过了第一种， 使失效率反而下降。
(2 )提高相联度
提高相联度可使失效率下降， 这一点可从表 4.9 中看出。表 4.9 中所列数据是
在 DEC station 5 000 上使用 SPEC92 测得的， 并假设 `Cache` 块大小为 32 字节， 采用
LRU 替换算法。
表 4.9
在不同容量不同相联度情况下， `Cache` 总失效率及“3C”所占的比例
 
从表中我们可以得出两条经验规则。第一， 对于表中所列出的 `Cache` 容量， 从实
际应用的角度来看， 8 路组相联在降低失效率方面的作用已经和全相联一样有效。
也就是说， 采用相联度超过 8 的方法实际意义不大。第二， 2∶1 `Cache` 经验规则， 它
是指容量为 N 的直接映像 `Cache` 的失效率和容量为 N/ 2 的两路组相联 `Cache` 的失
效率差不多相同。
许多例子都说明， 改进平均访存时间的某一方面是以损失另一方面为代价的。
增加块大小的方法会在降低失效率的同时增加失效开销， 而提高相联度则是以增加
命中时间为代价的。Hill 曾发现， 当分别采用直接映像和两路组相联时， 对于 T TL
或 ECL 板级 `Cache`, 命中时间相差 10% ; 而对于定制的 CMOS `Cache`, 命中时间相差
2% 。所以， 为了实现很高的处理器时钟频率， 就需要设计结构简单的 `Cache`; 但时钟
频率越高， 失效开销就越大( 所需的时钟周期数就越多)。为了减少失效开销， 又要求
提高相联度。
(3 )牺牲者 `Cache`
利用增加 `Cache` 块大小和提高相联度来降低失效率， 这是被系统结构设计者已
经采用了的经典方法。
所谓牺牲者 `Cache` 是指在 `Cache` 和它的下一级存储器的数据通道之间增设一个
全相联的小 `Cache`, 称为牺牲者 `Cache`, 如图 4.52 所示。
牺牲者 `Cache` 中存放由于失效而被丢弃( 替换)的那些块( 牺牲者)。每当发生失
效时， 在访问下一级存储器之前， 先检查牺牲者 `Cache` 中是否有所需的块。如果有就
将该块与 `Cache` 中 的某个 块作 交换。 Jouppi 于 1990 年发 现， 含 1 ～ 5 项 牺牲 者
`Cache` 对减少冲突失效很有效， 尤其是对于那些小型的直接映像 `Cache` 更是如此。
对于不同的程序， 一个项数为 4 的牺牲者 `Cache` 能使一个 4KB 直接映像数据 `Cache`
的冲突失效减少 20% ～90% 。

239
图 4.52 牺牲者 `Cache` 在存储层次中的位置
(4 )伪相联 `Cache`
伪相联又称为列相联， 这种方法既能获得多路组相联 `Cache` 的低失效率， 又能保
持直接映像 `Cache` 的命中速度。在命中情况下， 伪相联 `Cache` 访问过程与直接映像
`Cache` 访问过程相同。在失效时， 也即在访问下一级存储器之前， 通过检查另外一个
`Cache` 存储块， 看看是否在那里命中。一个简单的确定方法是对索引域中的最高位
求反， 然后按照新的索引去寻找“伪相联组”中的对应块， 如果这一块标识匹配， 则发
生了“伪命中”。否则， 只好访问下一级存储器。
由以上分析可知， 伪相联 `Cache` 有两种命中时间， 分别对应于正常命中和伪命中
的情况。图 4.53 给出了它们的对应关系。使用伪相联 `Cache` 时存在一种危险:如果
直接映像 `Cache` 里的许多快速命中在伪相联 `Cache` 中变成慢速命中， 那么这种优化
措施反而会降低整体性能。因此， 要能够指出同一组中的两个块哪个为快速命中， 哪
个为慢速命中， 这是很重要的。一种简单的方法就是交换两个块的内容。
(5 )指令和数据的预取技术
牺牲者 `Cache` 和伪相联 `Cache` 都保证在失效率性能的同时， 不影响处理器的时
钟频率。预取技术也能实现这一点。指令和数据都可在处理器提出访问请求之前进
行预取。预取内容可以直接放入 `Cache`, 也可以放在一个访问速度比主存快的外部
缓冲器中。
指令预取通常是在 `Cache` 之外的硬件中完成的。例如， AXP 21064 微处理器在
发生指令失效的时候取两个块:被请求的指令块和与其地址相邻的下一块。被请求

240
图 4.53 正常命中时间、伪命中时间和失效开销时间之间的关系
的指令块装入到指令 `Cache` 中， 而预取的指令块被装入到指令流缓冲区中。如果被
请求的块在指令流缓冲区中找到， 则原 `Cache` 请求被取消， 块被从指令流缓冲区中读
入， 然后下一个预取请求被发出。在 AXP 21064 指令流缓冲区中每个块的大小不超
过 32 字节。Jouppi 在 1990 年研究发现， 对于容量为 4KB、块大小为 16 字节的直接
映像指令 `Cache` 来说， 单个指令流缓冲区可以捕获到 15% ～25 % 的失效。在指令流
缓冲区中保存 4 个块， 命中率提高大约 50%， 保存 16 个块提高 72 % 。
相似的方案可以应用到数据访问中。 Jouppi 发现单个数据流缓冲区， 可以捕获
到容量为 4KB 直接映像 `Cache` 的大约 25% 的失效。在数据 `Cache` 外可以有多个流
缓冲区， 每一个都可以按不同的地址预取。Jouppi 发现 4 个数据流缓冲区可以使数
据命中率提高到 43% 。
另外， 预取技术依赖于存储器带宽的利用。
(6 )编译控制的预取技术
一个替代硬件预取指令和数据的技术是利用编译器来插入预取指令， 提前发出
数据请求。它可以有几种预取的方法:
● 寄存器预取(Register Prefetch ) :把数据预取到寄存器中。
● `Cache` 预取 (`Cache` Prefetch) :只将数据预取到 `Cache` 中， 而不是寄存器中。
这两种预取技术既可以是故障性的( Faulting)， 也可以是非故障性的( Nonfault-
ing )。故障性预取是指在预取时， 若出现虚地址故障或违反保护权限， 就会发生异
常。而非故障性预取在遇到这种情况时则不发生异常。按照这种说法， 一条正常的
Load 指令应该被认为是故障性寄存器预取指令。非故障性预取如导致异常就转变
为空操作。最有效的预取对程序是“语义上是不可见的”: 它既不会改变指令各数据
之间的各种逻辑关系或存储单元的内容， 也不会造成虚拟存储器故障。本节假定
`Cache` 预取都是非故障性的， 也叫做非绑定( Nonbinding) 预取。
只有在预取数据的同时处理器还能继续执行的情况下， 预取才是有意义的。这
就要求 `Cache` 在等待预取数据返回的同时还能继续提供指令和数据。这种灵活的
`Cache` 称为非阻塞 (Nonblocking )`Cache` 或非锁定 ( Lockup-Free)`Cache`。
和硬件控制的预取一样， 编译器控制预取的目的也是要执行指令和读取数据能

241
重叠执行。循环是预取优化的主要目标， 因为它们易于进行预取优化。如果失效开
销较小， 编译器只要简单地将循环体展开一次或两次， 并调度好预取和执行的重叠。
如果失效开销较大， 编译器就将循环体展开多次， 以便为后面较远的循环预取数据。
然而， 发出预取指令需要花费一条指令的开销， 因此， 要注意保证这种开销不超过预
取所带来的收益。编译器可以通过把重点放在那些可能会导致失效的访问， 使程序
避免不必要的预取， 从而较大程度地改善平均访存时间。
(7 )编译优化技术
这种方法就是通过对软件的优化来降低失效率。这也许是硬件设计者最喜欢的
解决方案。处理器和主存之间越来越大的性能差距促使编译器的设计者们更仔细地
研究存储层次行为， 以期能通过编译时的优化来改进性能。这项研究同样也分为减
少指令失效和减少数据失效两个方面。
我们能很容易地重新组织程序而不影响程序的正确性。例如， 把一个程序中的
几个过程重新排序， 就可能减少冲突失效， 从而降低指令失效率。McFarling ( 1989)
研究了如何使用记录信息来判断指令组之间可能发生的冲突， 并将指令重新排序以
减少失效。他发现， 这样可将容量为 2KB、块大小为 4 字节的直接映像指令 `Cache` 的
失效率降低 50% ;对容量为 8KB 的 `Cache`， 可将失效率降低 75% 。他还发现， 当能够
使基本指令根本就不进入 `Cache` 时， 可以得到最佳性能。但即使不这么做， 优化后的
程序在直接映像 `Cache` 中的失效率也低于 未优化程序在同样大 小的 8 路 组相联
`Cache` 中的失效率。数据对存储位置的限制比指令对存储位置的限制还要少， 因此
更便于调整顺序。我们对数据进行变换的目的是改善数据的空间局部性和时间局部
性。例如， 可能把对数据的运算改为对存放在同一 `Cache` 块中的所有数据进行操作，
而不是按照程序员原来随意书写的顺序访问数组元素。
① 合并数组( Merging Arrays)
合并数组主要是通过提高空间局部性来减少失效次数。一些程序按相同的下
标， 对多个维数相同的数组同时进行访问。这些访问会彼此影响， 从而导致冲突失
效。这种影响可 以通过把 这些独 立的 矩阵合 并成 一个复 合数组 来消 除， 使一 个
`Cache` 块可以包含所需要的所有元素。
/ * 修改前 */
int val[ SIZE] ;
int key[SIZE] ;
/ * 合并后 */
struct merge{
int val;
int key;
};
struct merge merged_ [SIZE ] ;

242
这个例子一个有趣的特性是， 使用记录数组的正确编程策略， 可以获得与这种优
化策略相同的收益。
② 循环交换( Loop Interchange)
有些程序带有嵌套循环， 它们访问存储器中的数据是非顺序性的。简单的交换
嵌套循环可以使得代码按照存储顺序来访问数据。这个技术通过空间局部性来减少
失效， 通过代码的重新排序使得块在被替换之前能够最大限度地利用 `Cache` 块中的
数据。
/ * 修改前 */
for (j = 0 ; j < 100 ; j = j + 1)
for (i = 0; i < 5000 ; i = i + 1 )
x[i] [ j] = 2 * x[i] [j] ;
/ * 修改后 */
for (i = 0; i < 5000; i = i + 1)
for (j = 0; j < 100; j = j + 1 )
x[i] [ j] = 2 * x[i] [j] ;
原先的代码 以 100 个 字的跨 距访问 存储 器， 而修 改后 的程 序在 访问 了一 个
`Cache` 块中的所有字后才去访问下一个 `Cache` 块。这种优化策略是在不影响指令数
的前提下提高了 `Cache` 的性能。
③ 循环融合( Loop Fusion)
有些程序有分立的代码段， 这些代码按照相同的循环访问相同的数组， 对相同的
数据进行不同的计算。通过“融合”这些代码到一个循环中， 使得装入到 `Cache` 中的
数据在被替换之前可以被重复利用。因此， 同前两种技术相比较， 这个优化策略的目
标是通过提高时间局部性来减少失效。
/ * 修改前 */
for (i = 0; i < N; i = i + 1 )
for (j = 0; j < N; j = j + 1 )
a[i] [j] = 1/ b[i] [ j] * c[i] [j] ;
for (i = 0; i < N; i = i + 1 )
for (j = 0; j < N; j = j + 1 )
d[i] [j] = a[i] [j] + c[i] [j] ;
/ * 修改后 */
for (i = 0; i < N; i = i + 1 )
for (j = 0; j < N; j = j + 1 )
{
a[i] [j] = 1/ b[i] [j] * c[i] [j] ;
d[i] [j] = a[i] [j] + c[i] [ j] ;

243
}
原先的代码在访问数组 a 和 c 时将发生两次失效， 一次在第一个循环中， 另一次
是在第二个循环中。在融合的循环中， 第二个语句很自然地利用了第一个语句对
`Cache` 的访问结果。
④ 分块
这种优化措施可能是在各种 `Cache` 优化策略中最著名的， 它同样是通过提高时
间局部性来减少失效。我们又一次要处理多个数组， 有些是按行访问的， 有些是按列
访问的。若以行为主或以列为主存放数组并不能解决问题， 因为在每一次循环中既
有按行访问也有按列访问的。这种正交关系的访问意味着以前的变换(如循环交换)
都是没有用的。
分块算法并不是对数组中的整行或整列进行操作， 而是对子矩阵或矩阵块进行
操作。目的是在被调入到 `Cache` 中的块被替换之前最大限度地利用它。下面是矩阵
的代码例子， 有助于对这种优化的理解。
/ * 修改前 */
for (i = 0; i < N; i = i + 1 )
for (j = 0; j < N; j = j + 1 )
{r = 0;
for ( k = 0 ; k < N; k = k + 1) {
r = r + y [i] [ k] * z[ k ] [j] ; };
x [i] [j] = r;
};
两个内层循环读取了矩阵 z 的所有 N×N 个元素， 并对矩阵 y 一行中的 N 个元
素进行重复地访问， 然后对矩阵 x 一行中的 N 个元素进行写操作。图 4.54 给出了
一个访问 3 个数组的访问情况， 深色阴影部分表示一次最近的访问， 浅色阴影表示一
次较早的访问， 白色表示还没有被访问到
。
图 4.54 当 i = 1 时，对 x, y, z 三个数组的访问情况
容量失效数显然依赖于 N 和 `Cache` 的容量。如果它能够包含所有 3 个 N× N

244
矩阵， 那么情况还好， 但前提是不发生冲突失效。如果 `Cache` 能包含一个 N×N 矩阵
以及一行的 N 个元素， 那么至少 y 的第 i 行以及数组 z 可以保留在 `Cache` 中。若
`Cache` 的容量比这还要小， 则对于 x 和 z 都会有失效发生。在最坏的情况下， N
3 次
操作会有 2N
3 + N
2 次失效。
为了保证要访问的元素都能在 `Cache` 中命中， 要对源代码进行改变， 两个内部循
环按步长 B 计算， 而不是从 x 到 z 的开始一直到结束来计算， 从而使其在一个 B×B
的子矩阵上计算。B 称为分块因子(Blocking Factor )。
/ * 修改后 */
for (jj = 0 ; jj < N; jj = jj + B)
for ( kk = 0 ; kk < N; kk = kk + B)
for (i = 0; i < N; i = i + 1 )
for (j = jj; j < min(jj + B - 1, N ) ; k = k + 1) {
r = 0;
for ( k = kk; k < min( kk + B - 1, N) ; k = k + 1 ){
r = r + y[i] [ k ] * z[ k] [j] ;
}
x [i] [j] = x [i] [j] + r;
};
图 4.55 显示了用分块的方法来访问 3 个数组的情况。仅仅观察容量失效， 总共
访问的存储器字符为 2N
3/ B + N
2， 大约提高了一个因子 B。因此， 分块充分利用了访
问的空间局部性和时间局部性。y 从空间局部性中受益， 而 z 从时间局部性中受益
。
图 4.55 访问数组 x，y, z 的时间
虽然我们的目标是降低 `Cache` 失效率， 但是分块也有助于寄存器分配。通过采
用一个小的分块使得块能够被装入到寄存器中， 可以使程序中取和存操作的数量最
小化。
传统上， 若简单地假定冲突失效很小， 或者能够因 `Cache` 相联度高而消除， 则分

245
块的目的是减少容量失效。因为分块减少了给定时间内在 `Cache` 中活动的字数， 而
选择比容量小的分块也可以减少冲突失效。
3.减少 `Cache` 的失效开销
`Cache` 性能公式告诉我们， 减少 `Cache` 失效开销与降低 `Cache` 失效率一样， 能够
带来 `Cache` 性能的提高。在所有的方法中， 采用两级 `Cache` 技术最受欢迎。
CPU 和主存之间的性能差距给体系结构设计者们提出了以下问题: 为了克服这
个越来越大的性能差距， 使存储器和 CPU 的性能匹配， 是应该把 `Cache` 做得更快， 还
是应该把 `Cache` 做得更大 ? 答案是: 二者兼顾。通过在原有 `Cache` 和存储器之间增
加另一级 `Cache`, 构成两级 `Cache`。可以把第一级 `Cache` 做得足够小， 使其速度和快
速 CPU 的时钟周期相匹配， 而把第二级 `Cache` 做得足够大， 使它能捕获更多本来需
要到主存去的访问， 从而降低实际失效开销。
尽管增加一级存储层次在概念上直观、简单， 但性能分析却变得复杂了。有关第
二级 `Cache` 的定义不太好理解。用下标 L1 和 L2 分别表示第一级和第二级 `Cache`,
原有的公式就变为:
平均访存时间 = 命中时间L 1 + 失效率L1 ×失效开销L1
失效开销L 1 = 命中时间L2 + 失效率L2 ×失效开销L 2
所以，
平均访存时间 = 命中时间L 1 + 失效率L1 ×( 命中时间L 2 + 失效率L2 ×失效开销L2 )
在这个公式里， 第二级 `Cache` 的失效率是以在第一级 `Cache` 中不命中而到达第二级
`Cache` 的访存次数为分母来计算的。为避免二义性， 对于第二级 `Cache` 系统采用以
下术语:
(1 )局部失效率
对于某一级 `Cache` 来说， 局部失效率 = 该级 `Cache` 的失效次数/ 到达该级 `Cache`
的访存次数。对于第二级 `Cache` 来说， 就是上面的失效率L 2 。
(2 )全局失效率
对于某一级 `Cache` 来说， 全局失效率 = 该级 `Cache` 的失效次数/ CPU 发出的访
存总次数。使用上面公式中的变量， 第二级 `Cache` 的全局失效率就是:
全局失效率L 2 = 失效率L1 ×失效率L2
因为访存 都要 经 过第 一 级 `Cache`， 所 以 它的 局 部失 效 率比 较 大。对于 两 级
`Cache`， 全局失效率是一种比局部失效率更有用的衡量指标， 它指出了在 CPU 发出
的访存中， 究竟有多大比例是穿过各级 `Cache` 最终到达存储器的。
例 4.4 假设在 1 000 次访存中， 第一级 `Cache` 失效 40 次， 第二级 `Cache` 失效 20
次。试问:在这种情况下， 该 `Cache` 系统的局部失效率和全局失效率各是多少 ?
解:第一级 `Cache` 的失效率(全局和局部 ) 是 40/ 1 000， 即 4% ; 第二级 `Cache` 的
局部失效率是 20/ 40, 即 50%， 第二级 `Cache` 的全局失效率是 20/ 1 000, 即 2% 。

246
请注意， 上述公式是针对读写操作混合而言的， 而且假设第一级 `Cache` 采用写回
法。当采用写直达法时， 第一级 `Cache` 将不仅把失效， 而且还把所有的写访问都送往
第二级 `Cache`, 另外还会使用一个写缓冲器。
对于第二级 `Cache`, 我们有以下结论:
① 在第二级 `Cache` 比第一级 `Cache` 大得多的情况下， 两级 `Cache` 的全局失效率
和容量与第二级 `Cache` 相同的单级 `Cache` 的失效率非常接近， 这时可以利用前面关
于单级 `Cache` 的分析和知识。
② 局部失效率不是衡量第二级 `Cache` 的一个好指标， 因为它是第一级 `Cache` 失
效率的函数， 可以通过改变第一级 `Cache` 而使之变化， 而且不能全面反映两级 `Cache`
体系的性能。因此， 在评价第二级 `Cache` 时， 应用全局失效率这个指标。
下面考虑第二级 `Cache` 的参数。第一级 `Cache` 和第二级 `Cache` 之间首先要区别
的是第一级 `Cache` 的速度会影响 CPU 的时钟频率， 而第二级 `Cache` 的速度只影响第
一级 `Cache` 的失效开销。因此， 对于第二级 `Cache`, 在设计时可以有更多的考虑空
间， 许多不适合 于 第一 级 `Cache` 的方 案对 于第 二级 `Cache` 却可 以使 用。第二 级
`Cache` 的设计只有两个问题需要权衡: 它能否降低 CPI 中的平均访存时间部分 ? 它
的成本是多少 ?
首先， 研究第二级 `Cache` 的容量。因为第一级 `Cache` 中的所有信息都会出现在
第二级 `Cache` 中， 第二级 `Cache` 的容量应比第一级大许多。如果第二级 `Cache` 只是
稍大一点， 局部失效率将很高。因此， 第二级 `Cache` 的容量一般很大， 和过去计算机
的主存一样大 ! 大容量意味着第二级 `Cache` 可能实际上没有容量失效， 只剩下一些
强制性失效和冲突失效。现在的问题是: 相联度 ( 组相联中的路数 n ) 对于第二级
`Cache` 的作用是否会更大 ?
例 4.5 给出有关第二级 `Cache` 的以下数据:
① 两路组相联使命中时间增加 10% ×CPU 时钟周期;
② 对于直接映像， 命中时间L2 = 10 个时钟周期;
③ 对于直接映像， 局部失效率L2 = 25% ;
④ 对于两路组相联， 局部失效率L2 = 20% ;
⑤ 失效开销L 2 = 50 个时钟周期。
试问第二级 `Cache` 的相联度对失效开销的影响如何 ?
解:对一个直接映像的第二级 `Cache` 来说， 第一级 `Cache` 的失效开销为
失效开销直接 映像， L 1 = 10 + 25 % ×50 = 22.5 个时钟周期
对于两路组相联第二级 `Cache` 来说， 命中时间增加了 10% ( 0.1 ) 个时钟周期， 故
第一级 `Cache` 的失效开销为:
失效开销两路 组相 联， L1 = 10.1 + 20% ×50 = 20.1 个时钟周期
在实际机器中， 第二级 `Cache` 几乎总是和第一级 `Cache` 以及 CPU 同步操作。相
应地， 第二级 `Cache` 的命中时间必须是时钟周期的整数倍。如果幸运的话， 可以把该

247
命中时间取整为 10 个时钟周期， 否则就只好取整为 11 个时钟周期， 但不管怎样， 都
比直接映像第二级 `Cache` 好:
失效开销两路 组相 联， L1 = 10 + 20% ×50 = 20.0 个时钟周期
失效开销两路 组相 联， L1 = 11 + 20% ×50 = 21.0 个时钟周期
可以利用减少第二级 `Cache` 的失效率， 从而达到减少失效开销的目的。提高相
联度和伪相联方法都值得考虑， 因为它们对第二级的命中时间影响很小， 而且平均访
存时间中很大一部分是由于第二级 `Cache` 失效而产生的。虽然较大容量的第二级
`Cache` 通过把数据分布到更多的 `Cache` 块中消除了一些冲突失效， 但它同时也减少
了容量失效， 所以在直接映像的第二级 `Cache` 中， 冲突失效所占的比例依然很大。
同样可以采用增加第二级 `Cache` 块大小的方法来减少失效。前面已经得出这样
的结论:增加 `Cache` 块的大小也增加了小容量 `Cache` 的冲突失效次数( 因为可能没有
足够的位置来存放数据)， 导致失效率上升。但对于大容量的第二级 `Cache` 来说， 这
一点并不成为问题， 而且由于访存时间相对较长， 所以 64 字节、128 字节， 甚至 256
字节的块大小都是第二级 `Cache` 经常使用的。图 4.56 给出了在存储器总线宽度为
相对较窄的 32 位时， CPU 执行时间随第二级 `Cache` 块大小的变化而改变的情况
。
图 4.56 相对执行时间和第二级 `Cache` 块大小的关系
需要考虑的另一个问题是第一级 `Cache` 中的数据是否总是同时存在于第二级
`Cache` 中。如果是的话， 则第二级 `Cache` 具有多级包容性 ( Multilevel Inclusion Prop-
erty)。多级包容性是我们所希望的， 因为它便于实现 I/ O 和 `Cache` 之间内容一致性
的检测。
为了减少平均访存时间， 可以让容量较小的第一级 `Cache` 采用较小的块， 而让容
量较大的第二级 `Cache` 采用较大的块。在这种情况下， 仍可实现包容性， 但在处理第
二级 `Cache` 失效时要做更多的工作:替换第二级 `Cache` 中的块时， 必须作废所有映像
到该块的第一级 `Cache` 中的块。这样不但会使第一级 `Cache` 失效率有所增加， 而且
会造成不必要的作废。如果结合使用其他一些性能优化技术 ( 如非阻塞的第二级

248
`Cache`)， 包容性会进一步增加复杂度。
综合上述考虑， `Cache` 设计的本质是在快速命中和减少失效次数这两个方面进
行权衡。大部分优化措施都是在改进一方的同时损害另一方。对于第二级 `Cache` 而
言， 由于它的命中次数比第一级 `Cache` 少得多， 所以重点就转移到了减少失效次数
上。这就导致了更大容量、更高相联度和块更大的 `Cache` 的出现。
4.减少命中时间
到目前为止， 我们已经讨论了通过减少失效次数和减少失效开销改进 `Cache` 性
能的办法， 现在我们来讨论减少命中时间的技术， 它也是平均访存时间的三个组成部
分之一。
命中时间的重要性在于它影响到处理器的时钟频率。在当今的许多机器中， 往
往是 `Cache` 的访问时间限制了处理器的时钟频率， 即使在把访问 `Cache` 分为几个时
钟周期来完成的机器中也是如此。因此减少命中时间不仅对减少平均访存时间很重
要， 而且对其他许多方面也是非常重要的。本节先讨论两种减少命中时间的通用技
术， 然后论述一个适用于写命中的优化措施。
(1 )容量小、结构简单的 `Cache`
采用容量小而且结构简单的 `Cache`, 可以有效地提高 `Cache` 的访问速度。用地
址的索引部分访问标识存储器、读出标识并与地址进行比较， 是 `Cache` 命中过程中最
耗时的部分。我们在前面已经指出， 硬件越简单， 速度就越快。小容量 `Cache` 对减少
命中时间当然有益， 而且应使 `Cache` 足够小， 以便可以与处理器做在同一芯片上， 以
避免因芯片外访问而增加时间开销， 这一点是非常重要的。
某些设计采用了一种折衷方案:把 `Cache` 的标识放在片内， 而把 `Cache` 的数据存
储器放在片外， 这样既可以实现快速标识检测， 又能利用独立的存储芯片来提供更大
的容量。另一个方案是要保持 `Cache` 结构简单， 例如采用直接映像 `Cache`。直接映
像 `Cache` 的主要优点是可以让标识检测和数据传送重叠进行， 这样可以有效地减少
命中时间。所以， 为了得到高速的时钟频率， 第一级 `Cache` 应选用容量小且结构简单
的设计方案。
(2 )虚拟 `Cache`
在采用虚拟存储器的机器中， 每次访存都必须进行虚地址到实地址的变换， 即将
CPU 发出的虚地址转换为物理地址。即便是容量小、结构简单的 `Cache`, 也必须解
决这个问题。
与 `Cache` 失效相比， `Cache` 命中发生的频率要高得多。按照“加快经常性事件”
实现的指导思想， 应在 `Cache` 中使用虚拟地址。这样的 `Cache` 称为虚拟 `Cache`， 而物
理 `Cache` 则是指那些使用物理地址的传统 `Cache`。
直接用虚拟地址访问 `Cache`, 在命中时消除了用于地址转换的时间。然而， 人们
在设计时并非都采用虚拟 `Cache`。其原因之一是每当进行进程切换时， 由于新进程

249
的虚拟地址所指向的物理空间有可能与原进程地址不同， 故需要清空 `Cache`。图
4.57说明了这种清空对失效率的影响。解决这个问题的一种方法是在地址标识中增
加一个进程标识符字段( PID)， 这样多个进程的数据可以混和存放于一个 `Cache` 中，
由 PID 指出 `Cache` 中各块的数据是属于哪个程序的。为减少 PID 的位数， PID 经常
是由操作系统指定。对于一个进程， 操作系统从循环使用的几个数字中指定一个作
为其 PID。进程切换时， 仅当某个 PID 被重用 ( 即该 PID 以前已被分配给了某个进
程， 现又把它分配给另一个进程) 时， 才需清空 `Cache`
。
图 4.57 一个程序在三种不同方式下， 虚地址 `Cache` 不同容量的失效率
图 4.57 说明了采用 PID 所带来的失效率上的改进， 同时给出了在以下三种情
况下各种容量的虚拟 `Cache` 的失效率: 没有进程切换(单进程)， 允许进程切换并使用
进程标识符( PIDs)， 允许进程切换但不使用进程标识符 ( purge)。从图中可看出: 和
单进程相比， PIDs 的绝对失效率增加 0.3 % ～0.6 % ; 而和 purge 相比， PIDs 的绝对
失效率减少 0.6% ～4.3% 。图中的数据是在 VAX 机上针对 Ultrix 操作系统统计
的， 并假设 `Cache` 采用直接映像， 块大小为 16 字节。
虚拟 `Cache` 没有流行起来的一个原因是操作系统和用户程序对于同一个物理地
址可能采用两种以上不同形式的虚拟地址来访问， 这些地址称为同义( Synonym ) 或
别名( Alias)。它们可能会导致同一个数据在虚拟 `Cache` 中存在两个副本。如果其
中一个被修改， 那么再使用另一个数据就是错误的。这种情况在物理 `Cache` 中是不
会发生的， 因为这些访问首先会把虚拟地址转换到同一物理地址， 从而找到同一个物
理 `Cache` 块。有一种用硬件解 决这个问题的方法， 叫做 反别名法， 它 保证每一 个
`Cache` 块对应于惟一的一个物理地址。

250
如果强行要求别名的某些地址位相同， 就可以用软件很容易地解决这一问题。
例如， SUN 公司的 UNIX 要求所有使用别名的地址最后 18 位都相同， 这种限制被称
为页着色。这一限制使得容量不超过 2
1 8 字节 ( 256KB) 的直接映像 `Cache` 中不可能
出现一个 `Cache` 块有重复物理地址的情况。所有别名将被映像到同一 `Cache` 块位
置。
对于虚拟地址， 最后还应考虑 I/ O。I/ O 通常使用物理地址， 所以为了与虚拟
`Cache` 打交道， 需要把物理地址映像为虚拟地址。另一种实现快速命中的技术是把
地址转换和访问 `Cache` 这两个过程分别安排到流水线的不同级中， 从而使时钟周期
加快， 但这同时也增加了命中所需的时间。这种方法增加了访存的流水线级数， 增加
了分支预测错误时的开销， 而且使得从 Load 指令流出到数据可用之间所需的时钟
周期数增加。
还有一种方法， 既能得到虚拟 `Cache` 的好处， 又能得到物理 `Cache` 的优点。它直
接用虚地址中的页内位移 ( 页内位移在 虚—实地址的变换中保持 不变 ) 作 为访问
`Cache` 的索引， 但标识却是物理地址。CPU 发出访存请求后， 在进行虚—实地址变
换的同时， 可并行进行标识的读取。在完成地址变换后， 再把得到的物理地址与标识
进行比较。
这种虚拟索引、物理标识方法的局限性， 在于直接映像 `Cache` 的容量不能超过页
的大小。AXP21064 采用了这种方法， 其 `Cache` 容量为 8KB, 最小页为 8KB, 所以可
以直接从虚地址的页内位移部分中得到 8 位的索引(块大小为 32 字节)。
为了既能实现大容量的 `Cache`, 又能使索引位数比较少， 以便能直接从虚拟地址
的页内位移部分得到， 我们可以采用提高相联度的方法， 这一点可以从下面的公式中
看出:
2
index =
`Cache` 容量
块大小×相联度
下面举一个极端的例子———IBM3033 的 `Cache`。虽然研究结果已表明 8 路以上
的组相联对减少失效率没多大好处， 但 IBM3033 的 `Cache` 仍采用了 16 路组相联， 其
主要好处是可以采用更大的 `Cache`。尽管 IBM 体系结构限制页的大小为 4KB, 但 16
路组相联却可以用物理索引对 64KB( 16×4KB)的 `Cache` 进行寻址。图 4.58 给出了
索引和页内位移的关系。页大小为 4 KB 意味着地址的最后 12 位不必进行转换， 因
此其中某些位可以用做访问 `Cache` 的索引。
31
页地址
12 11
页码内位移
0
地址标识
索引
块内位移
图 4.58 IBM3033 的 `Cache` 中索引和页内位移的关系
我们也可以不采用提高相联度的方法， 而由操作系统实现页着色。操作系统通

251
过使虚页地址和物理页地址的最后几位相同来实现这一点。采用这种方法时， 索引
的位数可以比先前的页内位移方法的索引位数多， 并且仍然是对物理地址进行比较。
另一种方法是用一小块硬件来猜测虚页地址的后几位映像到什么样的物理地
址。这块硬件可以是一个小表格， 它对虚页地址进行散列变换。由此得到的猜测结
果和地址的物理部分(页内位移) 一起构成访问 `Cache` 的索引。用此索引读出相应的
标识， 并与经地址转换得到的物理地址进行比较， 判断是否匹配。如果标识匹配， 则
发生了一次命中。如果不匹配， 则要么就是数据不在 `Cache` 中， 要么就是关于虚页地
址最后几位的映像的猜测是错的。这时 `Cache` 一般会用正确的索引重新判断这次访
存究竟是命中还是真的失效。
上述采用容量小且结构简单的 `Cache` 以及避免地址转换延迟的技术不仅能提高
写命中的速度， 而且能提高读命中的速度。
(3 )写操作流水化
写命中通常比读命中花费更多的时间， 因为在写入数据之前必须先检测标识， 否
则就有可能将数据写到错误的单元中。我们可以通过把写操作流水化来提高写命中
的速度。AlphaAXP21064 和其他一些机器采用了这种技术。图 4.59
是说明流水化
图 4.59 流水化写的硬件组织结构
写的硬件结构框图。这里， 标识和数据是分开存放的， 因而能分别独立地访问。每个
写操作的工作被分为两个阶段来完成:第一阶段进行标识比较， 并把标识和数据存入
延迟写缓冲器中;第二阶段再进行数据的写入 ( 若命中的话 )。这两个阶段按流水方

252
式工作。这样， 当前“写”的标识比较就可以和上一个“写”的数据写入并行起来， 实现
每个时钟周期完成一个写操作 ( 从 CPU 的角度)。该流水线与读操作无关， 因为读
操作的标识比较与数据读出本来就可以并行进行， 所以无需专门的硬件支持。
5.`Cache` 优化技术小结
在前面讨论中论述的减少 `Cache` 失效率、失效开销和命中时间的技术通常会影
响平均访存时间公式的其他组成部分， 而且会影响存储层次的复杂性。表 4.10 对这
些技术作了小结， 并估计了它们对复杂性的影响。表中“ + ”号表示这一技术改进了
相应指标，“ - ”号表示它使该指标变差， 而空格栏则表示它对该指标无影响。从表中
可以看出， 没有什么技术能同时改进两项或三项指标。表中关于复杂性的衡量是主
观化的，0 表示最容易， 3 表示最复杂。
表 4.10
`Cache` 优化技术小结
 
## 4.3.6 `Pentium` PC 的 `Cache`
`Pentium` PC 目前仍是一个单处理器系统， 它采用两级 `Cache` 结构。安装在主板

253
上的级 2 `Cache` ( L2 )， 其 容量是 256KB 或 512KB( P Ⅱ/ P Ⅲ 级 2 `Cache` 容量达 到
2MB 或更高)， 采用的两路组相联映像方式， 每行可以是 32, 64 或 128 字节。集成在
`Pentium` 处理器内的级 1 `Cache`( L1 )其容量是 16KB, 采用的也是两路组相联映像方
式， 每行是 32 字节。L2 的内容是主存的子集， L1 又是 L2 的子集， 从而使 L1 未命中
处理时间大为缩短， 为 L1 的高速使用提供了支持。
`Pentium` PC 的 `Cache` 另一特点是， 它将 16KB 的 L1 分为 8KB 的指令 `Cache` 和
数据 `Cache`(PⅡ/ PⅢ的 L1 分为 16KB 指令 `Cache` 和 16KB 数据 `Cache`)。实践证明
将指令 `Cache` 与数据 `Cache` 分开是有好处的。指令 `Cache` 是只读的， 单端口 256 位
(32 字节)向指令预取缓冲器提供指令代码。数据 `Cache` 必须提供读和写操作， 双端
口， 每端口 32 位(4 字节 )， 向两条流水线的整数运算单元和寄存器提供数据或接收
数据， 两个端口还可组合成一个 64 位端口与浮点运算单元相接。两个 `Cache` 与 64
位数据、32 位地址的 CPU 内部总线相连。
下面分别介绍 `Pentium` 级 1 `Cache` 的组织和一致性的实现。因指令 `Cache` 是只
读的， 没有写操作也就没有一致性问题。这里只介绍数据 `Cache`。
1.`Pentium` 级 1 `Cache` 的组织结构
8KB 的数据 `Cache` 采用两路组相联的组织方式， 分成 128 组， 每组 2 行， 每行 32
字节(8 个双字， 1 个双字为 32 位)。每行有一个 20 位的标记和 2 位的 MESI 的状态
位， 这 22 位构成该行的目录项。采用 LR U 替换策略， 一组两行共用一个 LR U 位，
如规定一组中的 A 行拷贝进新数据将此位置 1, 另一 B 行拷贝进新数据将此位置 0。
那么当需要替换时只需检查此位状态即可， 为 0 换出 A 行， 为 1 则换出 B 行， 实现了
保护新行的原则。这样 L1 数据 `Cache` 呈现出如图 4.60 所示的数据结构， 只是不再
是 2 位状态位而是 1 位有效位。
存取 `Cache` 使用 32 位物理地址。级 1 指令 `Cache` 和数据 `Cache` 每个都有一个
变换后援缓冲器 TLB( T ranslation Lookaside Buffer )， 用于在虚拟存储方式下将线
性地址变换为物理地址。
数据 `Cache` 可以在一个处理器时钟周期内存取两个数据， 数据可以是字节、字( 2
字节)和双字( 4 字节)。这两个数据分别通过两个 32 位端口被 U， V 两条指令流水
的 ALU 单元、寄存器所存取。 `Pentium` 处理器的时钟频率在它刚推出时是 66M Hz,
现在一般已是 180MHz, 200M Hz, 而新一代的 `Pentium` 处理器目前已有 300MHz
了。可以想见， 若没有片内 `Cache` 的支持， 高速的指令流水必将经常停滞不前， 更不
用说两路流水的超标量结构了。
`Pentium` 处理器内数据 `Cache` 的工作方式受控制寄存器 CR0 中的 `Cache` 禁止
CD(`Cache` Disable)位和非写直达 NW ( Not-Write-through ) 位两位控制， 如表 4.11
所示。

254
图 4.60 `Pentium` 级 1 数据 `Cache` 结构

255
表 4.11
`Pentium` 片内数据 `Cache` 工作方式
CD
NW
新行填入
写直达
使无效
0
0( 最佳 )
允许
允许
允许
1
0
禁止
允许
允许
1
1(复位后 )
禁止
禁止
禁止
对表 4.11 的理解应该注意， `Pentium` 已对 CR0 控制寄存器中的 CD 和 NW 位
重新定义， 不同于 80486 中的定义。CD = 1, NW = 1 是复位后的状态， 而 CD = 0,
NW = 0 已是最佳使用状态。这是一种在写回法的基础上允许某些情况下写直达的
写策略， 下面将会看到这实际上就是写一次法。
`Pentium` 处理器外部总线的数据宽度是 64 位。当片内 `Cache` 行填入或行写回
时， 启动的是猝发式内存读写周期( CHACE
# 引脚为低电平， 读时还要求 KEN
# 引脚
为低电平)， 一次完成 256 位的串传送， 即一次完成整行的填入或读出。
为维护 `Cache` 的一致性， 级 2 `Cache` 和级 1 数据 `Cache` 都采用的是 MESI 协议。
鉴于级 1 数据 `Cache` 采用的是写一次法， 其 MESI 协议做了一些简化。为支持监听
片外内存访问活动， `Pentium` 为片内数据 `Cache` 提供了一个监听窗口。在监听期间，
`Pentium` 浮起它的地址输出引脚， 而允许片外输入地址， 以使片内数据 `Cache` 能判测
是否监听命中。并有如下一些处理器引脚: INV(输入， 使无效 )， WB/ W T
# ( 输入， 写
回/ 写直达)， HIT
# (输出， 监听命中)， HIT M
# ( 输出， 修改状态行监听命中 )等， 这些
信号或者协调片内 `Cache` MESI 协议的状态转换， 或者输出监听命中指示以使片外
`Cache` 能判测并完成相应的状态转换。
2.`Pentium` 级 1 数据 `Cache` 的 MESI 协议
下面介绍 `Pentium` 级 1 数据 `Cache`( L1 )的 MESI 协议， 以及它如何与级 2 `Cache`
( L2 )相配合来维护一致性并能充分支持 `Pentium` 高速运行的特点。经上节介绍可
给出图 4.61 所示的 L1, L2 和主存之间工作环境的框图。
`Pentium` CPU 与外部数据交换的存储读写总线周期主要有两大类: 一类是前面
介绍的 256 位猝发式传送， 用于 L1 的行填入和行写出; 另一类是不经 L1 的 64 位传
送， 此时 CHACE
# 信号为高电平， 在 Intel 数据手册中称此为“不可超高速缓存”式传
送。
由于 L1 位于 CPU 内部， 它的内容又是 L2 内容的子集， 因此 L1 与 L2 的监听对
象不同。L2 监听系统总线上其他系统主控者和其他 `Cache` 的访问主存活动; L1 监
听 L2, 采样 L2 发出的 WB/ W T
# 信号和 INV 信号以完成相应的行状态转换， 并有监
听命中信号 HIT
# 和 HIT M
# 送至 L2。L2 可发出 AHOLD 信号， 命 CPU 的地址引
脚改变为输入方向， 强制 CPU 的 L1 进入监听期间， Intel 数据手册中称此为询问期

256
图 4.61 `Pentium` 两级 `Cache` 工作环境
间， 它的活动情况完全同于监听期间情况。由此可见， L2 负责整个系统的 `Cache`-主
存的一致性; L1 负责响应 L2, 与 L2 一起维护 L1-L2 一致性。
L2 采用的是写回法， 并遵循 MESI 协议。L1 基本上是采用写回法， 但在 CD =
0, NW = 0 的最佳设置情况下允许结合一些写直达操作， 这里的写直达是既向片内
L1 写入又向片外启动一个存储器写总线周期。下面将会看到这种情况出现在对未
修改行的第一次写操作时， 故它是写一次法。而后对此修改行的再次或多次写命中
采用的都是写回法策略， 不向片外写， 只在该行被换出或读/ 写监听命中时才写回。
L1 遵循 MESI 协议， 但它将 E 态重新定义为第一次写命中后的修改态， 实际上
L1 绝不会有同于主存而又不出现于 L2 的专有态行。图 4.62 给出了 L1 的 MESI 协
议状态转换图， 该图将与 L1 有效行同内存 ( 块 ) 地址的 L2 有效行可能有的状态列
出， 以帮助理解此图。
① 当 L1 读未命中时要启动一个存储读总线周期， 由片外读入一行填入空行( 若
没有空行， 先以 LRU 算法换出一行)。此周期首先引起 L2 判测是否读命中， 若读命
中， L2 递交同地址的有效行并返回 WB/ W T
# 信号。若 L1 新行拷贝的是 L2 的 S 态
行或 E 态行(WB/ WT# 为低电平)， 新行状态为 S;若 L1 新行拷贝的是 L2 的 M 态行
(WB/ WT# 为高电平)， 新行状态为 E。若 L2 读未命中， 则由主存读取此地址的数据
块同时拷贝到 L2 和 L1, L2 的新行状态为 E 或 S, L1 的新行状态为 S, 逻辑上仍可看
做 L1 的新行是由 L2 拷贝而来。
② 对 L1 的 S 态行发生写命中， 除此行在片内完成写修改并进入 (特殊的 ) E 态
外， 还启动了一个片外的存储写周期， 这就是前述的写一次操作。它必然引起 L2 的
写命中， L2 的 E 态行或 S 态行完成写修改进入 M 态。此时注意， 若是 I 上的 S 态行

257
图 4.62 `Pentium` L1 的 MESI 状态转换图
写命中， 还要引发一个无效处理过程 (见图 4.50 )， 使系统中其他 `Cache` 的同此地址
的共享行无效， 这正是 L1 采用写一次法的原因。它将广播通知其他 `Cache` 无效处
理的工作交由 L2 控制逻辑完成， 也是它的巧妙之处。
③ L1 写未命中时， `Pentium` 只是将内存地址和具体修改字送出片外， 即启动一
个存储写总线周期， L1 不分配新行。此时 L2 可能发生写命中， 完成其有效行的写修
改并进入或保持在 M 态;若是 L2 也是写未命中， 则要读取内存块至 L2 再修改 ( 见
图 4.50 中的由 I→M 操作)。L1 将这种读内存再修改的耗时工作又交给 L2 去完成
了。当然， L1 也要为此做出一点牺牲， 即它不容许有这个最近存取过的拷贝， 但此拷
贝已在 L2， 下次读取时很快就可得到。这样， `Pentium` 启动一个存储写周期后就可
立即进行片内其他操作， 支持了指令流水执行。
④ 前面已经说明 MESI 协议维护一致性的关键在于， 修改过的 `Cache` 行在临界
情况下及时写回主存以保证它者使用的正确性。L2 监听系统总线上的其他主控者
或其他 `Cache` 的访问主存活动。那么， 我们来分析 L2 的 M 态行的 L1 同地址行有
哪些状态: ( a) L1M～L2M, 这是 L1 至少两次写修改的情况， 最新数据在 L1M 行;
( b ) L1E～L2M, 这是 L1 写一次情况或是 L1 拷贝 L2M 行的情况， 两行内容相同;
(c) L1I～L2M, 这是上面③所述的 L1 写未命中的情况， 实际上 L2 的 M 态行此时在
L1 没有同地址行。换句话说， L2M 态行包含了 L1 的 M 态行和 E 态行， 而且 L2 的
M 态行与 L1 的 M 态行存在不一致性。
因此， 当 L2 的 M 态行读/ 写监听命中时， L2 要以 A HOLD 信号有效强行令 L1

258
进入监听期间， 来查询 L1 是否也监听命中。如果 L1 返回的是 HIT M
# 和 HIT
# 信
号都为有效， 表明这是 L1M～L2M 情况， L1 的 M 态行读/ 写监听命中要以猝发方式
将此行写到主存， 然后该行相应地进入 S/ I 态。如果 L1 返回的是 HI TM
# 无效而
HIT
# 有效， 表明这是 L1E～L2M 情况， L1 的 E 态行读/ 写监听命中只是相应地进入
S/ I 态， 由 L2 将它的 M 态行写回到主存( 见图 4.50 的 M→S 与 M→I )。如果 L1 返
回的是 HITM
# 和 HIT
# 都无效， 表明这是 L1I～L2M 情况， 一样也是由 L2 将它的
M 态行写回到主存， L1 无动作。
综上所述， L1 和 L2 的密切配合既保证了整个系统的 `Cache`
- 主存的一致性， 又简
化了 L1 的控制逻辑并对 CPU 的高速运行提供了有力支持。
