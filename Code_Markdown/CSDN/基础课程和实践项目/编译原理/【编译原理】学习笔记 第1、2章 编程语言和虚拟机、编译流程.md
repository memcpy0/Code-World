@[toc]

---
# 1.1 编程语言的发展
目前存在着很多种编程语言，它们的工作原理各不相同。根据和硬件平台的远近关系，可以粗略分为：
- **以汇编语言为代表的低级语言**：是一系列的语言助记符，几乎与CPU指令一一对应；能够直接和硬件平台提供的寄存器、内存、IO端口、外部设备打交道，**功能强大，汇编程序员对代码有绝对的控制权**。但是汇编语言**表达能力不强，开发效率低下**。早期操作系统镜像的加载 `load` 和初始化往往使用汇编来实现。
- **以C++、Java为代表的高级语言**：C语言是通往高级语言的重要一步，它保留了内嵌汇编的能力，能够通过链接器将汇编语言开发的模块与C语言开发的模块链接在一起；同时，C语言的指针也保留了汇编语言中内存操作的能力。作为一门承上启下的语言，大多数操作系统都是使用C语言开发的。

	不过随着应用软件的规模越来越大，面向对象的编程思想开始流行，面向对象的语言也产生了，典型的是C++。面向对象能够让开发者以**模块化、对象化**的思想进行设计和开发，大大提高了编程语言的抽象能力。迄今为止，**面向对象编程是主流的编程方法**。

当然，由于**C++内存管理的复杂性、跨平台能力的缺乏**（C/C++属于静态编译语言，编译之后形成可执行程序，其中的代码段内容与平台直接相关。对于同样的C/C++代码，不同的平台和系统会产生不同的机器指令；不同版本的编译器和操作系统也会产生不同的代码；运行时库的影响、动态链接库可能不兼容），带有虚拟机的编程语言如Java就应运而生。

---
# 1.2 编程语言虚拟机 
## 1. 屏蔽硬件差异
**为了实现跨平台的能力，虚拟机需要屏蔽硬件之间的差异**。以Java为例，Java源代码会被 `Javac` 编译成 `.class` 文件，`.class` 文件的内容是固定的，其代码段中全都是Java字节码。无论硬件平台怎样，同样的代码生成的都是相同的字节码，得到的执行结果一定是相同的。多个 `.class` 文件可以集中，生成一个 `.jar` 文件（事实上，一个模块会被压缩为一个 `.jar` 文件），应用程序会以 `.jar` 包的方式分发和部署。

由于字节码的设计一般类似于CPU指令或汇编语言，有自己定义的数值运算、位操作、比较操作、跳转操作等，因此这种**专门为某类编程语言设计和开发的字节码及其解释器**被合起来称为**编程语言虚拟机**。

以下列代码为例认识一下Java虚拟机：
```java
public class Byte {
	public void foo() {
		int a = 2;
		int b = 3;
		int c = a + b;
	} 
}
```
用 `javac` 编译 `Byte.java` 后得到 `Byte.class` 文件。此时可使用 `jd-gui.exe` 程序打开，或者用IDE打开，不过显示的 `Byte.class` 文件是被反编译过的，基本和原 `.java` 文件一样，不是我们想要看的格式。这时使用 `javap -c Byte.class` ，可以在命令提示符窗口里看到需要的字节码文件：
```java
Compiled from "Byte.java"
public class Byte {
  public Byte();
    Code:
       0: aload_0
       1: invokespecial #1                  // Method java/lang/Object."<init>":
()V
       4: return

  public void foo();
    Code:
       0: iconst_2
       1: istore_1
       2: iconst_3
       3: istore_2
       4: iload_1
       5: iload_2
       6: iadd
       7: istore_3
       8: return
}
```
Java字节码的执行过程是由栈来实现的，不必关心CPU的具体体系结构：
```cpp
①
| a |   |  
| b |   |  |   |  
|_c_|___|  |___| 
②
| a |   | iconst2
| b |   |  | 2 | 
|_c_|___|  |___| 
③
| a | 2 | istore1
| b |   |  |   | 
|_c_|___|  |___| 
④
| a | 2 | iconst3
| b |   |  | 3 | 
|_c_|___|  |___| 
⑤ 
| a | 2 | istore2
| b | 3 |  |   | 
|_c_|___|  |___| 
⑥
| a | 2 | iload_1
| b | 3 |  | 2 | 
|_c_|___|  |___| 
⑦
| a | 2 | iload_2
| b | 3 |  | 3 | 
|_c_|___|  |_2_|
⑧
| a | 2 |  iadd
| b | 3 |  |   | 
|_c_|_5_|  |___|
```
Java的虚拟机中封装了**对字节码进行加载、分析、执行的所有逻辑**，在不同的硬件平台和不同的操作系统上，Java语言虚拟机的实现各不相同，但是**提供的字节码执行器的功能是完全相同的**。从而实现了 `Write Once, Run Everywhere` ，屏蔽了不同硬件的差异。

 
## 2. 自动内存管理
使用C++时必须万分小心，避免不合理的内存分配和内存泄漏。**如果能够自动对不被引用的内存进行回收和整理，就可以避免内存泄漏**。这就是垃圾回收机制。Java、Python、Go这些语言本身就带有垃圾回收机制，能够极大减轻程序员的心智负担，提高开发效率。

## 3. 编译和执行
除了Java字节码外，编程语言还有更多的实现方法：
- 以Java为代表的有字节码的虚拟机：**将源代码的编译和程序的执行相分离**；
- 以v8为代表的JavaScript虚拟机：由Google开发的、用于解释执行JavaScript的虚拟机。网页上的JavaScript代码，都是以源代码的形式由服务端发送到客户端，然后在客户端执行。特别的是，**v8不需要编译生成字节码，它直接将源代码翻译为抽象语法树**，然后v8的执行器通过后序遍历这棵树，在访问语法树上的不同结点时，执行该结点对应的操作，最终完成代码的解释执行。因此，**源代码的编译和程序的执行是统一的**；
- 以Go为代表的静态编译类型：Go在编译的时候直接将虚拟机与用户代码链接在一起，虽然可执行程序的体积较大，但是这种直接静态编译的做法**既能通过虚拟机实现对硬件平台和操作系统的屏蔽，又能提供很好的执行效率**。

可见，编译策略和执行方法的选择是十分多样的，开发者需要根据编程语言面临的场景以及要解决的问题来决定。

## 4. Python的策略
Python比较灵活，既有字节码的规定，能够编译为字节码 `.pyc` 文件；同时，也完全支持源代码的直接执行。实质上，**在Python虚拟机内部，也是将源代码先编译为字节码然后执行的，Python的编译器是Python虚拟机的一部分**。与Java不同，`Javac` 用于编译，与执行相互分离。Python的 `eval()` 函数，实质上就是调用了Python内置的编译器来对字符串进行编译。

除了CPython外，还有Jython（以Java实现的Python语言），它将 `.py` 源代码直接翻译为Java字节码组成的 `.class` 文件，抛弃了原生的Python字节码，然后能够直接在Java虚拟机上执行，无缝衔接和使用各种强大的Java类库。由此可见，仅使用编译技术，也能很好地实现执行Python代码的能力。 

---
# 1.3 开发环境
编译原理的学习和编译器的开发，学习曲线十分陡峭，很难入门。为此，在这里学习使用C++实现Python的编译和执行——**首先实现一个字节码文件的执行器**，小步快跑，持续改进，最后实现Python虚拟机。开发环境是纯粹的Windows，使用x86 64 Ubuntu也可以。


---
本章通过**一个小的类C语言**讲解编译的流程，这个流程和Python的编译流程是一样的，以此来了解编译的过程。无论是Java文件或者是Python文件，本质上都是一种文本文件。**编译过程**就是**把文本文件翻译成一个可以被Java虚拟机或者Python虚拟机打开、识别和执行的文件**。`.java` 文件通过 `javac` 翻译为 `.class` 文件，由Java字节码组成；而 `.py` 文件经过提前编译，生成 `.pyc` 文件，由Python字节码组成。所以 `.class, .pyc` 文件也被称为**字节码文件**。

# 2.1 Python字节码
开始大概了解一下Python字节码的设计。类似于Java字节码，**Python字节码的执行也是基于栈的**，它使用一个变量表和一个操作数栈来完成所有字节码的执行。在Git Bash上运行Python，交互式执行Python代码：
```py
>>> def foo():
...     a = 2
...     b = 3
...     c = a + b
...     return c
...
>>> import dis
>>> dis.dis(foo)
  2           0 LOAD_CONST               1 (2)
              2 STORE_FAST               0 (a)

  3           4 LOAD_CONST               2 (3)
              6 STORE_FAST               1 (b)

  4           8 LOAD_FAST                0 (a)
             10 LOAD_FAST                1 (b)
             12 BINARY_ADD
             14 STORE_FAST               2 (c)

  5          16 LOAD_FAST                2 (c)
             18 RETURN_VALUE
>>>
```
可以看到，Java和Python的字节码非常相似。这里 `dis` 模块的功能和 `javap` 一样，反编译源文件为字节码。上述例子中，用 `dis` 反编译了 `foo` 这个函数，其中的 `LOAD_CONST, STORE_FAST, LOAD_FAST` 就是带参数的字节码，`BINARY_ADD, RETURN_VALUE` 就是不带参数的字节码。
> **Python的字节码有两种类型**：带参数和不带参数。在真实的内存中，每个字节码有一个编号，或者称为操作码 `Operation Code` ，编号只占用 `1` 个字节。因此，**不带参数的字节码只有操作码**，大小就是 `1` 个字节；**带参数的字节码，最多带一个参数**，每个参数占用 `2` 个字节，所以带参数的字节码占用 `3` 个字节。
> <b></b>
> 当然，这是Python2时代的设计，现在的Python3则更加复杂：字节码指令的编码小于 `90` 的为无参数的，指令仅包含操作码自身，共 `1` 字节；大于等于 `90` 的，则每条指令在操作码之后还带有 `1` 个参数，参数长度为 `2` 字节，共 `3` 字节。 指令后的参数大于 `2` 个字节的情况，则见后面的指令含义介绍部分的 `EXTENDED_ARG(ext)` 。
> <b></b>
> 顺带一提，这部分也过时了，只局限于Python3.6之前。现在的Python3每条指令使用 `2` 字节。原话为：`Changed in version 3.6: Use 2 bytes for each instruction. Previously the number of bytes varied by instruction.` 。[详情和各字节码指令的含义见此处。](http://docs.python.org/3/library/dis.html)

如果想要查询Python3的字节码指令集：
```py
>>> import opcode
>>> for op in range(len(opcode.opname)):
...     print('0X%.2x(%.3d): %s' % (op, op, opcode.opname[op]))
...
0X00(000): <0>
0X01(001): POP_TOP
0X02(002): ROT_TWO
0X03(003): ROT_THREE
0X04(004): DUP_TOP
0X05(005): DUP_TOP_TWO
0X06(006): ROT_FOUR
0X07(007): <7>
0X08(008): <8>
0X09(009): NOP
0X0a(010): UNARY_POSITIVE
0X0b(011): UNARY_NEGATIVE
0X0c(012): UNARY_NOT
0X0d(013): <13>
0X0e(014): <14>
0X0f(015): UNARY_INVERT
0X10(016): BINARY_MATRIX_MULTIPLY
0X11(017): INPLACE_MATRIX_MULTIPLY
0X12(018): <18>
0X13(019): BINARY_POWER
0X14(020): BINARY_MULTIPLY
0X15(021): <21>
0X16(022): BINARY_MODULO
0X17(023): BINARY_ADD
0X18(024): BINARY_SUBTRACT
0X19(025): BINARY_SUBSCR
0X1a(026): BINARY_FLOOR_DIVIDE
0X1b(027): BINARY_TRUE_DIVIDE
0X1c(028): INPLACE_FLOOR_DIVIDE
0X1d(029): INPLACE_TRUE_DIVIDE
0X1e(030): <30>
0X1f(031): <31>
0X20(032): <32>
0X21(033): <33>
0X22(034): <34>
0X23(035): <35>
0X24(036): <36>
0X25(037): <37>
0X26(038): <38>
0X27(039): <39>
0X28(040): <40>
0X29(041): <41>
0X2a(042): <42>
0X2b(043): <43>
0X2c(044): <44>
0X2d(045): <45>
0X2e(046): <46>
0X2f(047): <47>
0X30(048): <48>
0X31(049): <49>
0X32(050): GET_AITER
0X33(051): GET_ANEXT
0X34(052): BEFORE_ASYNC_WITH
0X35(053): BEGIN_FINALLY
0X36(054): END_ASYNC_FOR
0X37(055): INPLACE_ADD
0X38(056): INPLACE_SUBTRACT
0X39(057): INPLACE_MULTIPLY
0X3a(058): <58>
0X3b(059): INPLACE_MODULO
0X3c(060): STORE_SUBSCR
0X3d(061): DELETE_SUBSCR
0X3e(062): BINARY_LSHIFT
0X3f(063): BINARY_RSHIFT
0X40(064): BINARY_AND
0X41(065): BINARY_XOR
0X42(066): BINARY_OR
0X43(067): INPLACE_POWER
0X44(068): GET_ITER
0X45(069): GET_YIELD_FROM_ITER
0X46(070): PRINT_EXPR
0X47(071): LOAD_BUILD_CLASS
0X48(072): YIELD_FROM
0X49(073): GET_AWAITABLE
0X4a(074): <74>
0X4b(075): INPLACE_LSHIFT
0X4c(076): INPLACE_RSHIFT
0X4d(077): INPLACE_AND
0X4e(078): INPLACE_XOR
0X4f(079): INPLACE_OR
0X50(080): <80>
0X51(081): WITH_CLEANUP_START
0X52(082): WITH_CLEANUP_FINISH
0X53(083): RETURN_VALUE
0X54(084): IMPORT_STAR
0X55(085): SETUP_ANNOTATIONS
0X56(086): YIELD_VALUE
0X57(087): POP_BLOCK
0X58(088): END_FINALLY
0X59(089): POP_EXCEPT
0X5a(090): STORE_NAME
0X5b(091): DELETE_NAME
0X5c(092): UNPACK_SEQUENCE
0X5d(093): FOR_ITER
0X5e(094): UNPACK_EX
0X5f(095): STORE_ATTR
0X60(096): DELETE_ATTR
0X61(097): STORE_GLOBAL
0X62(098): DELETE_GLOBAL
0X63(099): <99>
0X64(100): LOAD_CONST
0X65(101): LOAD_NAME
0X66(102): BUILD_TUPLE
0X67(103): BUILD_LIST
0X68(104): BUILD_SET
0X69(105): BUILD_MAP
0X6a(106): LOAD_ATTR
0X6b(107): COMPARE_OP
0X6c(108): IMPORT_NAME
0X6d(109): IMPORT_FROM
0X6e(110): JUMP_FORWARD
0X6f(111): JUMP_IF_FALSE_OR_POP
0X70(112): JUMP_IF_TRUE_OR_POP
0X71(113): JUMP_ABSOLUTE
0X72(114): POP_JUMP_IF_FALSE
0X73(115): POP_JUMP_IF_TRUE
0X74(116): LOAD_GLOBAL
0X75(117): <117>
0X76(118): <118>
0X77(119): <119>
0X78(120): <120>
0X79(121): <121>
0X7a(122): SETUP_FINALLY
0X7b(123): <123>
0X7c(124): LOAD_FAST
0X7d(125): STORE_FAST
0X7e(126): DELETE_FAST
0X7f(127): <127>
0X80(128): <128>
0X81(129): <129>
0X82(130): RAISE_VARARGS
0X83(131): CALL_FUNCTION
0X84(132): MAKE_FUNCTION
0X85(133): BUILD_SLICE
0X86(134): <134>
0X87(135): LOAD_CLOSURE
0X88(136): LOAD_DEREF
0X89(137): STORE_DEREF
0X8a(138): DELETE_DEREF
0X8b(139): <139>
0X8c(140): <140>
0X8d(141): CALL_FUNCTION_KW
0X8e(142): CALL_FUNCTION_EX
0X8f(143): SETUP_WITH
0X90(144): EXTENDED_ARG
0X91(145): LIST_APPEND
0X92(146): SET_ADD
0X93(147): MAP_ADD
0X94(148): LOAD_CLASSDEREF
0X95(149): BUILD_LIST_UNPACK
0X96(150): BUILD_MAP_UNPACK
0X97(151): BUILD_MAP_UNPACK_WITH_CALL
0X98(152): BUILD_TUPLE_UNPACK
0X99(153): BUILD_SET_UNPACK
0X9a(154): SETUP_ASYNC_WITH
0X9b(155): FORMAT_VALUE
0X9c(156): BUILD_CONST_KEY_MAP
0X9d(157): BUILD_STRING
0X9e(158): BUILD_TUPLE_UNPACK_WITH_CALL
0X9f(159): <159>
0Xa0(160): LOAD_METHOD
0Xa1(161): CALL_METHOD
0Xa2(162): CALL_FINALLY
0Xa3(163): POP_FINALLY
0Xa4(164): <164>
0Xa5(165): <165>
0Xa6(166): <166>
0Xa7(167): <167>
0Xa8(168): <168>
0Xa9(169): <169>
0Xaa(170): <170>
0Xab(171): <171>
0Xac(172): <172>
0Xad(173): <173>
0Xae(174): <174>
0Xaf(175): <175>
0Xb0(176): <176>
0Xb1(177): <177>
0Xb2(178): <178>
0Xb3(179): <179>
0Xb4(180): <180>
0Xb5(181): <181>
0Xb6(182): <182>
0Xb7(183): <183>
0Xb8(184): <184>
0Xb9(185): <185>
0Xba(186): <186>
0Xbb(187): <187>
0Xbc(188): <188>
0Xbd(189): <189>
0Xbe(190): <190>
0Xbf(191): <191>
0Xc0(192): <192>
0Xc1(193): <193>
0Xc2(194): <194>
0Xc3(195): <195>
0Xc4(196): <196>
0Xc5(197): <197>
0Xc6(198): <198>
0Xc7(199): <199>
0Xc8(200): <200>
0Xc9(201): <201>
0Xca(202): <202>
0Xcb(203): <203>
0Xcc(204): <204>
0Xcd(205): <205>
0Xce(206): <206>
0Xcf(207): <207>
0Xd0(208): <208>
0Xd1(209): <209>
0Xd2(210): <210>
0Xd3(211): <211>
0Xd4(212): <212>
0Xd5(213): <213>
0Xd6(214): <214>
0Xd7(215): <215>
0Xd8(216): <216>
0Xd9(217): <217>
0Xda(218): <218>
0Xdb(219): <219>
0Xdc(220): <220>
0Xdd(221): <221>
0Xde(222): <222>
0Xdf(223): <223>
0Xe0(224): <224>
0Xe1(225): <225>
0Xe2(226): <226>
0Xe3(227): <227>
0Xe4(228): <228>
0Xe5(229): <229>
0Xe6(230): <230>
0Xe7(231): <231>
0Xe8(232): <232>
0Xe9(233): <233>
0Xea(234): <234>
0Xeb(235): <235>
0Xec(236): <236>
0Xed(237): <237>
0Xee(238): <238>
0Xef(239): <239>
0Xf0(240): <240>
0Xf1(241): <241>
0Xf2(242): <242>
0Xf3(243): <243>
0Xf4(244): <244>
0Xf5(245): <245>
0Xf6(246): <246>
0Xf7(247): <247>
0Xf8(248): <248>
0Xf9(249): <249>
0Xfa(250): <250>
0Xfb(251): <251>
0Xfc(252): <252>
0Xfd(253): <253>
0Xfe(254): <254>
0Xff(255): <255>
```
粗略了解了Python的字节码后，学习 `.py` 文件如何被翻译为这些字节码。

---
# 2.2 词法分析
把文本文件翻译成字节码的第一个步骤就是：**从文本文件中逐个字符读取内容，然后把字符识别为变量、数字、字符串、操作符和关键字等**。这些变量、数字和字符串是组成程序的基本元素，或称 `token` 。把文件文件中的一串字符识别为一串 `token` ，就是要解决的第一个拦路虎。

下面是一个文本文件，里面有一行表达式，由 `5` 个 `token` 组成：数字 `12` ，乘号 `*` ，数字 `48` ，加号 `+` ，数字 `59` 。
```
12 * 48 + 59 
```
仅针对这个文本文件，写一个程序，读入字符识别 `token` 是很简单的：
```cpp
#include <iostream>
#include <fstream>
#include <cstdio>
using namespace std;

#define INIT 0
#define NUM 1
int main() { 
	ifstream ifs; //FILE *fp = fopen("test_token.txt", "r");
	ifs.open("test_token.txt", ifstream::in); //char ch;
	int state, num = 0; 
	while (ifs.good()) { //while ((ch = getc(fp) != EOF) 
		char c = ifs.get();
		if (c == ' ' || c == '\n' || c == EOF) {
			if (state == NUM) { //之前状态为数字 
				printf("token NUM : %d\n", num);
				state = INIT;
				num = 0;
			}
		}
		else if (c >= '0' && c <= '9') {
			state = NUM;
			num = num * 10 + c - '0';
		}
		else if (c == '+' || c == '-' || c == '*' || c == '/') {
			if (state == NUM) { //之前状态为数字
				printf("token NUM : %d'n", num);
				state = INIT;   //此时状态为其他  
				num = 0;
			} 
			printf("token operator : %c\n", c);
			state = INIT;
		}
	}
	ifs.close(); //fclose(fp);
	return 0;
}
```
相当于一个小型的自动机，有两个状态 `NUM, INIT` ：
- 遇到 `'0' - '9'` 时进入 `NUM` 状态，进行转换并累计数字；
- 遇到 `' ', '\n', '+', '-', '*', '/'` 等时先判断之前状态是否是数字，是则输出，然后转变 `state` 变量为 `INIT` ，标识数字字符已经结束；
- 其中，遇到加、减、乘、除时，还需要直接输出这个操作符，并标识 `state = INIT` 。

运行结果如下，有效识别出了各个 `token` ：
<img src="https://img-blog.csdnimg.cn/20200929212721947.png" width="65%">

词法分析的思路大体如此。除了**数字**和**字符串**外，`token` 的类型还包含**关键字**、**标识符**和各种**操作符**等，因此一个完整的词法分析程序是一件技术含量中等偏下、但是十分繁琐的事。为了保持热情，不被琐碎的事情分心，我们将使用Python中的词法分析模块 `tokenize (The tokenize module provides a lexical scanner for Python source code, implemented in Python)` 完成词法分析的任务。

代码如下：
```py
import tokenize

f = open("test_token.txt")
tk = tokenize.generate_tokens(f.readline)
# token type; token string; (srow, scol); (erow, ecol); physical line
for toknum, tokval, _, _, _ in tk:
    print(toknum, tokval)
```
执行后的结果如下：
```py
2 12
54 *
2 48
54 +
2 59
4 

0 
```
如果要查看 `toknum` 的定义，会发现：
```py
ENDMARKER : 0
NAME : 1
NUMBER : 2
STRING : 3
NEWLINE : 4
INDENT : 5
DEDENT : 6
LPAR : 7
RPAR : 8
LSQB : 9
RSQB : 10
COLON : 11
COMMA : 12
SEMI : 13
PLUS : 14
MINUS : 15
STAR : 16
SLASH : 17
VBAR : 18
AMPER : 19
LESS : 20
GREATER : 21
EQUAL : 22
DOT : 23
PERCENT : 24
LBRACE : 25
RBRACE : 26
EQEQUAL : 27
NOTEQUAL : 28
LESSEQUAL : 29
GREATEREQUAL : 30
TILDE : 31
CIRCUMFLEX : 32
LEFTSHIFT : 33
RIGHTSHIFT : 34
DOUBLESTAR : 35
PLUSEQUAL : 36
MINEQUAL : 37
STAREQUAL : 38
SLASHEQUAL : 39
PERCENTEQUAL : 40
AMPEREQUAL : 41
VBAREQUAL : 42
CIRCUMFLEXEQUAL : 43
LEFTSHIFTEQUAL : 44
RIGHTSHIFTEQUAL : 45
DOUBLESTAREQUAL : 46
DOUBLESLASH : 47
DOUBLESLASHEQUAL : 48
AT : 49
ATEQUAL : 50
RARROW : 51
ELLIPSIS : 52
COLONEQUAL : 53
OP : 54
AWAIT : 55
ASYNC : 56
TYPE_IGNORE : 57
TYPE_COMMENT : 58
ERRORTOKEN : 59
COMMENT : 60
NL : 61
ENCODING : 62
N_TOKENS : 63
NT_OFFSET : 256
```
所以，`12, 48, 59` 对应的 `toknum` 是 `2` ，而 `*, +` 对应的 `toknum` 是 `54` 。

---
# 2.3 语法分析
从文本文件中分析出程序的基本元素——`token` 后，编译器尝试去理解这些 `token` 之间的内在逻辑关系。比如：加法符号的前后必须是一个可执行加法操作的目标，数字或者一个变量，绝不能是一个乘号。编译器在语法分析这个阶段所做的，就是分析 `token` 组成的序列是否有意义。

语法分析有两大类算法：
- 自顶向下的分析方法：简单直接，易于理解和编写，也称为**递归下降的分析方法**；
- 自底向上的分析方法；

## 1. 拆分化简问题
语法分析的自顶向下方法，实质上就是把一个大的问题分解为各个小的问题。最顶部的任务是计算一个表达式 `expression` ，一个由多个项求和得到的多项式：
```cpp
expression := term + term + ... + term
```
等式右边的 `term` 是一个求和表达式中的各个加数，如 `2 + 3 * 4 + 5` 可以被看做 `2, 3 * 4, 5` 的和，其中 `2, 3 * 4, 5` 分别是一个 `term` 。继续拆分 `term` ，`term` 可以被看做多个因子的积，化简 `term` 的规模如下：
```cpp
term := factor * factor * ... * factor
```
左边的 `term` 是一个规模比较大的积，右边的一个 `factor` 代表一个因子。这样就把 `term` 结构拆分为规模更小的因子了，因子又该如何拆分呢？
```cpp
factor := NUMBER | (expression)
```
因子 `factor` 被定义为一个整数或一个表达式，即一个 `factor` 可以是一个整数，也可以是一个包含在括号里的表达式。或者说，一个整数可以被认定为一个 `factor` ，用括号括起来的表达式也是一个 `factor` 。

emmm，解构来解构去，使用 `term` 拆分 `expression` ，使用 `factor` 拆分 `term` ，却发现 `factor` 还需要用 `expression` 去解构，又绕回来了。**这种用自己的定义来定义自己的情况就是递归**。当然，递归需要终止条件，递归的完整定义如下：
- ① 子问题必须和原问题同样性质，且规模更小，更简单；
- ② 不能无限制调用自己，必须有一个递归出口，能够直接处理。

这里的出口就是 `factor` 的定义，**将问题拆分到只有一个整数时，递归就终止了。**

## 2. 转换为代码
定义三个函数 `expr, term, factor` ，`expr` 表示对表达式求值，`term` 表示对表达式中的某一项求值，`factor` 表示对某一个因子求值。即分别匹配表达式、加数、因子：
```py
import sys
import tokenize

class Token:
    def __init__(self, tok_num, tok_value):
        self.toknum = tok_num
        self.tokvalue = tok_value

global current_token

def current():
    global current_token
    return current_token

def next(tk):  # generate the next token from tk
    toknum, tokvalue, _, _, _ = tk.__next__()
    global current_token
    current_token = Token(toknum, tokvalue)

def expr(tk):
    s1 = term(tk) # get a term
    value = s1

    toknum = current().toknum
    tokvalue = current().tokvalue
    
    while tokvalue == "+" or tokvalue == "-":
        print("expr tokvalue is %s" % tokvalue)

        next(tk)      # get the next token
        s2 = term(tk) # get the next term
        
        if tokvalue == "+":
            value += s2
        elif tokvalue == "-":
            value -= s2

        toknum = current().toknum
        tokvalue = current().tokvalue

    print("expr value is %s" % value)
    return value

def term(tk):
    f1 = factor(tk) # get a factor
    value = f1
    
    toknum = current().toknum
    tokvalue = current().tokvalue

    while tokvalue == "*" or tokvalue == "/":
        print("term tokvalue is %s" % tokvalue)

        next(tk)
        f2 = factor(tk) # get the next factor
        
        if tokvalue == "*":
            value *= f2
            print("term value is %s" % value)
        elif tokvalue == "/":
            value /= f2
            print("term value is %s" % value)

        toknum = current().toknum
        tokvalue = current().tokvalue

    print("term return is %s" % value)
    return value

def factor(tk):
    if current().toknum == tokenize.NUMBER: # is a number
        value = current().tokvalue    		# get the number value
        next(tk)
    elif current().tokvalue == "(":         # NUMBER | (expression)
        next(tk)
        f = expr(tk)                        # call expr() recursively
        if (current().tokvalue != ")"):                     
            print("parse error! value = %s" % current().tokvalue)
        value = f
        next(tk)
    # curent().tokvalue == ")"
    return int(value)

if __name__ == "__main__":
    f = open(sys.argv[1])                   # open the given filename
    tk = tokenize.generate_tokens(f.readline)  # token list
    next(tk)
    print(expr(tk))
```
针对只有一句表达式 `(12 * 48) + (59 / 42)` 的文件 `test_token.txt` 运行，结果如下：
```py
term tokvalue is *
term value is 576
term return is 576
expr value is 576
term return is 576
expr tokvalue is +
term tokvalue is /
term value is 1.4047619047619047
term return is 1.4047619047619047
expr value is 1.4047619047619047
term return is 1
expr value is 577
577
```

这段程序中，`tk` 是 `token` 序列的生成器，每次从其中取出一个 `token` ，然后按照 `expr->term->factor` 的顺序递归调用分析它：
- `expr(tk)` 中的主要结构是 `while` 循环，用于处理多个加号和减号的情况，此时先打印 `+ or -` ，然后匹配下一个 `term` 。最后返回 `expr` 的值；
- `term(tk)` 中的主要结构是 `while` 循环，用于处理多个乘号和除号的情况，结构和 `expr()` 一致，先打印 `* or /` ，然后匹配下一个 `factor` 。最后返回 `term` 的值；
- `factor(tk)` 使用分支结构，表示数字和小括号两种情况。

这一过程中，从 `expr` 下降到 `term` ，再下降到 `factor` ，明显是自上而下的解析过程，因此被称为**自上而下的递归下降式文法分析**。

---
# 2.4 抽象语法树
上一节中进行语法分析的时候，也把表达式的值求了出来，但是这不是我们的目标。**我们想把这种表达式的运算翻译为字节码，而不是把它的值计算出来。** 为此需要使用一种中间数据结构——抽象语法树 `AST, (Abstract Syntax Tree)` ，通过它方便地产生字节码。

**对于编译器而言，抽象语法树意义非凡**。多数编译器都会实现抽象语法树这个数据结构，因为**抽象语法树在表达程序结构方面非常直观**：
```cpp
										+
									   / \
									  /   \
									 *    59
									/ \
								   /   \
								  12   48
```
而且抽象语法树作用众多，可以直接**后序遍历AST来对表达式进行求值**，也可以**在AST上做很多编译器的优化**，还可以**通过AST生成字节码**。

## 2.4.1 构建AST
在语法构建的过程中，**如果不直接计算，而将每一个分析结果转换为一个AST中的内部节点**，就可以构建一棵AST。

