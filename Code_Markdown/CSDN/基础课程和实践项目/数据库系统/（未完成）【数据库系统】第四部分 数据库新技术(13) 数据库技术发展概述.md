> 本文属于「数据库系统」系列文章之一，这一系列着重于「数据库系统知识的学习与实践」。由于文章内容随时可能发生更新变动，欢迎关注和收藏[数据库系统系列文章汇总目录](https://memcpy0.blog.csdn.net/article/details/119996493)一文以作备忘。需要特别说明的是，为了透彻理解和全面掌握数据库系统，本系列文章中参考了诸多博客、教程、文档、书籍等资料，限于时间精力有限，这里无法一一列出。部分重要资料的不完全参考目录如下所示，在后续学习整理中还会逐渐补充：
> - 数据库系统概念 第六版 `Database System Concepts, Sixth Edition` ，作者是 `Abraham Silberschatz, Henry F. Korth, S. Sudarshan` ，机械工业出版社
> - 数据库系统概论 第五版，王珊 萨师煊编著，高等教育出版社


@[toc]
 
---
**数据库技术从理论研究到原型开发与技术攻关，再到实际产品研制和应用，形成了良性循环，成为计算机领域的成功典范**，也吸引了学术界和工业界众多的科技人员，使得数据库研究日新月异，新技术、新系统层出不穷，科技队伍也不断壮大。

本系列文章之前主要关注**关系数据库的学习使用**。这里则以「数据模型、数据库应用、数据库管理系统开发技术」三个方面为主线，概述数据库的发展历程，展示数据库在「理论、应用、系统开发」等研究和应用领域的主要内容与成就，目的在于==提供一个宏观、总体的视图，以了解数据库技术的发展过程、数据库分支的基本内容以及这些分支之间的相互联系==（13.1~13.3）。同时也简单介绍当前大数据时代下，数据管理技术遇到的挑战、以及数据管理新技术的发展与展望（13.4）。

# 本章参考文献
![在这里插入图片描述](https://img-blog.csdnimg.cn/11feb04d5acc4932a722bd910998df6f.png)

 

# 13.1 数据库技术发展历史回顾
数据库技术产生于20世纪60年代中期，至今仅仅50年的历史，已经历了三代演变，造就了 `C. W. Bachman, E. F. Codd, James Gray` 三位图灵奖得主，发展了以**数据建模和数据库管理系统核心技术**（如物理和逻辑独立性、描述性查询、基于代价的优化等）为主、内容丰富的一门学科，带动了一个巨大的软件产业，这50年可谓成就辉煌。更重要的是，这些技术的进步使第一代智能应用成为可能，并为现在的大数据管理和分析奠定了基础。

==数据库技术是计算机科学技术中发展最快的领域之一，也是应用最广的技术之一==，它已成为计算机信息系统与智能应用系统的核心技术和重要基础。

当今数据库系统是一个大家族，数据模型丰富多样，新技术内容层出不穷，应用领域广泛深入。**初学者步入数据库领域时，面对众多复杂的数据库技术和系统，难免产生迷惑和混乱**。下面通过一个三维视图，从数据模型、相关技术、应用领域三个方面，描述了数据库系统的发展历史、特点和相互关系。
![在这里插入图片描述](https://img-blog.csdnimg.cn/db9688fc0f134191b300e03dea39b59c.png)

---
# 13.2 数据库发展的三个阶段
==**数据模型是数据库系统的核心和基础**==。依赖数据模型的进展，数据库技术可以相应地分为三个发展阶段，即第一代的网状、层次数据库系统，第二代的关系数据库系统，以及新一代的数据库大家族。
## 13.2.1 第一代数据库系统
==层次模型、网状模型都是格式化模型。它们从体系结构、数据库语言到数据存储管理均具有共同特征，是第一代数据库系统==。这一代数据库系统有如下两类代表：
- 1969年由IBM公司研制的**层次模型数据库管理系统IMS**；
- 美国数据库系统语言研究会 `CODASYL` 下属的数据库任务组 `DBTG` ，对数据库方法进行了系统的研究和探讨，于20世纪60年代末70年代初提出了若干报告，称为DBTG报告。**DBTG报告**确定并建立了数据库系统的许多概念、方法和技术。DBTG所提议的方法是基于网状结构的，是**网状模型数据库系统**的典型代表。

这两类数据库系统具有以下几个共同特点：
（1）支持**三级模式**（外模式、模式、内模式）的体系结构。模式之间具有转换（或称为映射）功能。
（2）用**存取路径**来表示数据之间的联系。这是数据库系统和文件系统的主要区别之一。**数据库不仅存储数据，而且存储数据之间的联系**。数据之间的联系在层次和网状数据库系统中，**都是**用存取路径来表示和实现的。
（3）**独立的数据定义语言**。层次和网状数据库系统有独立的数据定义语言，用以描述数据库的三级模式以及相互映像。诸模式一经定义，就很难修改。
（3）**导航的数据操纵语言**。层次和网状数据库的数据查询、数据操纵语言，是**一次一个记录的、导航式的过程化语言**。这类语言通常嵌入某一种高级语言，如COBOL、FORTRAN、PL/1、C语言中。导航式数据操纵语言的优点是**按照预设的路径存取数据，效率高**；缺点是**编程繁琐，应用程序的可移植性较差，数据的逻辑独立性也较差**。


## 13.2.2 第二代数据库系统
支持关系数据模型的关系数据库系统是第二代数据库系统。1970年，IBM公司San Jose研究室的研究员 `E. F. Codd` 发表了题为《大型共享数据库数据的关系模型》论文，提出了数据库的关系模型，开创了数据库关系方法和关系数据理论的研究，为关系数据库技术奠定了理论基础。

20世纪70年代是关系数据库理论研究和原型开发的时代，经过大量高层次的研究和开发，取得了以下主要成果：
（1）奠定了**关系模型的理论基础**，给出了人们一致接受的关系模型的规范说明。
（2）研究了**关系数据语言**，包括关系代数、关系演算、SQL及QBE等，确立了SQL为关系数据库语言标准。==由于不同数据库都使用SQL作为共同的数据语言和标准接口，使不同数据库系统之间的互操作有了共同的基础，为数据库的产业化和广泛应用打下基础==。
（3）研制了**大量的关系数据库管理系统原型**，其中以IBM San Jose研究室开发的System R和Berkeley大学研制的INGRES为典型代表，攻克了系统实现中查询优化、事务管理、并发控制、故障恢复等一系列关键技术。这不仅大大丰富了数据库管理系统实现技术和数据库理论，更促进了数据库的产业化。

第二代关系数据库系统具有模型简单清晰、理论基础好、数据独立性强、数据库语言非过程化和标准化等特色。

## 13.2.3 新一代数据库系统
第一、二代数据库系统的数据模型，虽然描述了现实世界数据的结构和一些重要的相互联系，但是仍不能捕捉和表达「数据对象所具有的丰富而重要的语义」。

新一代数据库系统以更丰富多样的数据模型和数据管理功能为特征，满足广泛复杂的新应用的要求。新一代数据库技术的研究和发展导致了众多不同于第一、二代数据库的系统诞生，构成了当今数据库系统的大家族。

这些新的数据库系统，无论是基于**面向对象模型**还是基于**对象关系 `OR` 数据模型**，是分布式、客户机-服务器体系结构，还是混合式体系结构，是在SMP还是在MPP并行机上运行的并行数据库系统，乃至是应用于某一领域（如工程、统计、地理信息系统）的工程数据库、统计数据库、空间数据库等，都可以广泛地称为新一代数据库系统。

1990年，高级DBMS功能委员会发表了《第三代数据库系统宣言》的文章（简称《宣言》），提出了**第三代DBMS应具有的三个基本特征**（或三条基本原则），并从它们导出了 $13$ 个具体的特征和功能（称为 $13$ 个命题）：
（1）==第三代数据库系统应支持**数据管理**、**对象管理**和**知识管理**==。除了提供传统的数据管理服务外，第三代数据库系统将支持更加丰富的对象结构和规则，应集数据管理、对象管理和知识管理为一体。第三代数据库系统不像第二代那样，有一个统一的关系模型，《宣言》认为**无论该数据库系统支持何种复杂的、非传统的数据模型，它都应该具有面向对象模型的基本特征**。
（2）==第三代数据库系统必须保持和继承第二代数据库系统的技术==。第三代数据库系统应继承第二代数据库系统已有的技术；保持第二代数据库系统的**非过程化数据存取方式**和**数据独立性**，这不仅能很好地支持对象管理和规则管理，而且能更好地支持原有的数据管理，支持多数用户需要的即席查询等。
（3）==第三代数据库系统必须对其他系统开放==。数据库系统的开放性表现在**支持数据库语言标准**；在网络上**支持标准网络协议**；系统具有良好的可移植性、可连接性、可扩展性和可互操作性等。

---
# 13.3 数据系统发展的特点
下面从数据模型、相关技术、应用领域三个方面，描述数据库系统发展的特点和相互关系。
## 13.3.1 数据模型的发展
==数据库的发展，集中表现在数据模型的发展上==。从最初的层次、网状数据模型发展到关系数据模型，数据库技术产生了巨大的飞跃。==关系模型的提出是数据库发展史上具有划时代意义的重大事件==。关系理论研究和关系数据库管理系统研制的巨大成功，进一步促进了关系数据库的发展，使关系数据模型成为具有统治地位的数据模型。

随着数据库应用领域的扩展、数据对象的多样化，传统关系数据模型开始暴露出许多弱点，如**对复杂对象的表示能力较差**，**语义表达能力较弱**，**缺乏灵活丰富的建模能力**，**对文本、时间、空间、声音、图像和视频等数据类型的处理能力差**等。为此，人们提出并发展了许多新的数据模型。下面介绍继关系模型之后几种重要的数据模型。
### 1. 面向对象数据模型
==将语义数据模型和面向对象程序设计方法结合起来，用面向对象观点来描述现实世界实体（对象）的逻辑组织、对象间限制、联系等的模型==。一系列面向对象核心概念构成了**面向对象数据模型** `Object Oriented Data Model, OODM` 的基础，主要包括以下一些概念：
1. 现实世界中任何事物都被建模为对象，每个对象具有一个**唯一的对象标识** `OID` 。
2. **对象是其状态和行为的封装**，其中状态是对象属性值的集合，行为是变更对象状态的方法集合。
3. 「具有相同属性和行为的对象的全体」构成了类，类中的对象称为**类的实例**。
4. 类的属性的定义域也可以是类，从而构成了**类的复合**。类具有继承性，一个类可以继承另一个类的属性与方法，被继承类和继承类也称为**超类**和**子类**。类与类之间的复合与继承关系，形成了一个有向无环图，称为**类层次**。
5. **对象是被封装起来的，它的状态和行为在对象外部不可见**，从外部只能通过对象显示定义的消息传递，对对象进行操作。

面向对象数据库 `OODB` 的研究始于20世纪80年代，有许多面向对象数据库产品相继问世，较著名的有Object Store、O2、ONTOS等。==与传统数据库一样，面向对象数据库系统对数据的操纵包括数据查询、增加、删除、修改等，也具有并发控制、故障恢复、存储管理等完整的功能==。不仅能支持传统数据库应用，也能支持非传统领域的应用，包括CAD/CAM、OA、CIMS、GIS以及图形、图像等多媒体领域、工程领域和数据集成等领域。

尽管如此，由于面向对象数据库的操作语言过于复杂，没有得到广大用户特别是开发者的认可，加上面向对象数据库企图完全替代关系DBMS的思路，增加了企业系统升级的负担，客户不接受，面向对象数据库产品终究没有在市场上获得成功。

==对象关系数据库系统 `Object Relational DataBase System, ORDBS` 是关系数据库与面向对象数据库的结合==，它保持了关系数据库系统的非过程化数据存取方式和数据独立性，继承了关系数据库系统已有的技术，支持原有的数据管理，又能支持OO模型和对象管理。各数据库厂商都在原来的产品基础上进行了扩展。

**1999年发布的SQL标准（即SQL99）中，增加了 `SQL/Object Language Binding` ，提供了面向对象的功能标准**。SQL99对ORDBS标准的制定，滞后于实际系统的实现，所以各个ORDBS产品在支持对象模型方面，虽然思想一致，但是所采用的术语、语言语法、扩展的功能都不尽相同。
### 2. XML数据模型
随着互联网的迅速发展，Web上各种半结构化、非结构化数据源已经成为重要的信息来源，可扩展标记语言 `eXtended Markup Language, XML` 已成为网上数据交换的标准和数据界的研究热点，人们研究和提出了**表示半结构化数据的XML数据模型**。

==XML数据模型由「**表示XML文档的结点标记树**」、**结点标记树之上的操作**和**语义约束**组成==。XML结点标记树中，包括不同类型的结点——其中，文档结点是树的根结点，XML文档的根元素作为该文档结点的子结点；元素结点对应XML文档中的每个元素；子元素结点的排列顺序，按照XML文档中对应标签的出现次序；属性结点对应元素相关的属性值，元素结点是它的每个属性结点的父结点；命名空间结点描述元素的命名空间字符串。==结点标记树的操作，主要包括「树中子树的定义」、「树和树之间的转换」==。XML元素中的 `ID/IDref` 属性提供了一定程度的语义约束的支持。

XML数据管理的实现，可以采用纯XML数据库系统的方式。纯XML数据库基于XML结点树模型，能够较自然地支持XML数据的管理，但是需要解决传统关系数据库管理所面临的各种问题，包括查询优化、并发、事务、索引等。==目前，很多商业关系数据库通过扩展的关系代数，支持XML数据的管理，扩展的关系代数不仅包含传统的关系数据操作，而且支持XML数据特定的投影、选择、连接等运算==。传统的查询优化机制也加以扩展，以满足新的XML数据操作的要求。通过关系数据库查询引擎的内部扩展，XML数据管理能够更加有效的利用「现有关系数据库成熟的查询技术」。
### 3. RDF数据模型
由于万维网上的信息没有统一的表示方式，给数据管理带来了困难。如果网络上的资源，在创建之初就使用标准的元数据来描述，则可以省去很多麻烦。为此，W3C提出了**资源描述框架** `Resource Discription Framework, RDF` ，用它来描述和注解万维网中的资源，并向计算机系统提供理解和交换数据的手段。

==RDF是一种用于描述Web资源的标记语言，其结构就是由（主语，谓词，宾语）构成的三元组==，这里的主语通常是网页的URL；谓语是属性，如Web页面的标题、作者、修改时间、Web文档的版权和许可信息等；宾语是具体的值或者另一个数据对象。然而，将Web资源这一概念一般化后，**RDF可用于表达任何数据对象及其关系**，例如关于一个在线购物机构的某项产品的信息（规格、价格和库存等信息）。**因此，RDF也是一种数据模型，并被广泛作为语义网、知识库的基础数据模型**。

==谓词在RDF模型中具有特殊的地位，其语义是由谓词符号本身决定的==。因此，在使用RDF建模时，需要一个词汇表或者领域本体，用来描述这些谓词之间的语义关系。

RDF模型可以有如下的形式化描述。RDF三元组 `RDF triple` ：给定一个URL集合 $R$ 、空节点集合 $B$ 、文字描述集合 $L$ ，一个RDF三元组 $t$ 是形如 $(s, p, o)$ 的三元组，其中 $s \in R \cup B,\  p \in R,\ o \in R\cup B\cup L$ 。这里的 $s$ 通常称为**主语** `subject` 、**资源** `resource` 或**主体**，$p$ 称为**谓词** `predicate` 或**属性** `property` ，$o$ 称为**宾语** `object` 、**属性值** `value` 或**客体**。

`Simple Protocol and RDF Query Language, SPARQL` 是W3C提出的RDF数据的查询标准语言，也是目前被广泛采用的一种RDF上的查询语言。当前的大多数RDF系统都支持SPARQL查询。SPARQL共有四种查询方式，分别为 `SELECT, CONSTRUCT, DESCRIBE, ASK` 。目前最常用的是 `SELECT` 查询方式，它与SQL的语法相似，用来返回满足条件的数据。一些研究者在SPARQL的基础上进行了修改，提出了 `nSPARQL, SPARQL-DL` 等对 `SPARQL` 语法进行扩充，增强 `SPARQL` 的查询表达功能。
## 13.3.2 数据库技术与相关技术相结合
==数据库技术与其他计算机技术相结合，是数据库技术的一个显著特征==，随之也涌现出各种数据库系统，例如：
- 数据库技术与分布处理技术相结合，出现了分布式数据库系统；
- 数据库技术与并行处理技术相结合，出现了并行数据库系统；
- 数据库技术与人工智能技术相结合，出现了演绎数据库、知识库、主动数据库系统；
- 数据库技术与多媒体技术相结合，出现了多媒体数据库系统；
- 数据库技术与模糊技术相结合，出现了模糊数据库系统等；
- 数据库技术与移动通信技术相结合，出现了移动数据库系统等；
- 数据库技术与Web技术相结合，出现了Web数据库等。

这里以分布式数据库、并行数据库为例，说明**数据库技术如何吸收、结合其他计算机技术，从而形成数据库领域新的分支和研究课题**。事实上，这种做法极大地丰富和发展了数据库技术。
### 1. 分布式数据库系统
分布式数据库系统是在「集中式数据库系统」和「计算机网络」的基础上发展起来的，它是分布式数据处理的关键技术之一。==分布式数据库由一组数据组成，这组数据分布在计算机网络的不同计算机上，网络中的每个结点具有独立处理的能力（称为场地自治），可以执行局部应用。同时，每个结点也能通过网络通信系统执行全局应用==。

这一定义强调了分布式数据库系统的**场地自治性**以及**自治场地之间的协作性**。这就是说，==每个场地是独立的数据库系统，它有自己的数据库、自己的用户、自己的服务器，运行自己的DBMS，执行局部应用，具有高度的自治性==。同时，各个场地的数据库系统又相互协作，组成一个整体。这种整体性的含义是，==对于用户来说，一个分布式数据库系统逻辑上看，如同一个集中式数据库系统一样，用户可以在任何一个场地执行全局应用==。

因此，**分布式数据库系统不是简单地把集中式数据库连网就能实现的，它具有自己的性质和特征**。集中式数据库的许多概念和技术，如数据独立性、数据共享和数据冗余、并发控制、完整性、安全性和恢复等，在分布式数据库系统中都有了新的更加丰富的内容。

分布式数据库系统的**本地自治性** `local autonomy` 是指，==局部场地的数据库系统可以自己决定本地数据库的设计、使用以及与其他节点的数据库系统的通信==。分布式数据库系统的**分布透明性** `distributed transparency` 是指，==分布式数据库管理系统将数据的分布封装起来，用户访问分布式数据库就像与集中式数据库打交道一样，不必知道也不必关心数据的存放和操作位置等细节==。

分布式数据库系统在集中式数据库系统的组成基础上，增加了三个部分：**DDBMS、全局字典和分布目录、网络访问进程**。全局字典和分布目录为DDBMS提供了数据定位的元信息，网络访问进程使用高级协议来执行局部站点和分布式数据库之间的通信。

20世纪80年代是分布式数据库系统研究和开发的一个高峰时期，具有代表性的分布式数据库系统由SDD-1、POREL、R*、分布式INGRES系统、SIRIUS计划、ADA-DDM系统等。

近年来，Internet的发展和海量异构数据的应用需求，使得分布式数据库管理和分布式数据处理技术遇到了新的挑战。**根据 `CAP (Consistency, Availability, Partitions Tolerance)` 理论，在分布式系统中，数据一致性 `consistency` 、系统可用性 `availability` 、网络分区容错性 `partition tolerance` 三者不可兼得**，满足其中任意两项便会损害第三项。分布数据管理在Web海量数据搜索和数据分析中，可以适当减低对数据一致性的严格要求，以提高系统的可用性和系统性能。因此，对分布数据处理的研究和开发进入了新的阶段，即大数据时代的大规模分布处理。
### 2. 并行数据库系统
==并行数据库系统是在并行机上运行的、具有并行处理能力的数据库系统==，并行数据库系统能充分发挥多处理和I/O并行性，是数据库技术与并行计算技术相结合的产物。

并行数据库技术起源于20世纪70年代的数据库机 `database machine` 研究，数据库机研究的内容主要集中在「**关系代数操作的并行化**」和「**实现关系操作的专用硬件设计**」上，希望通过硬件实现关系数据库操作的某些功能，该研究没有如愿成功。20世纪80年代后期，并行数据库技术的研究方向逐步转到了通用并行机方面，研究的重点是并行数据库的物理组织、并行操作算法、查询优化和调度策略。20世纪90年代，随着处理器、存储、网络等相关基础技术的发展，开展了并行数据库在**数据操纵的时间并行性**和**空间并行性**方向的研究。

并行数据库研究主要围绕关系数据库进行，包括以下几个方面：
1. **实现数据库查询并行化的数据流方法**：关系数据是集合操作，许多情况下可分解为一系列对子集的操作，具有潜在的并行性。利用关系操作的固有并行性，可以较为方便地对查询作并行处理。此种方法简单有效，被很多并行数据库采用。
2. **并行数据库的物理组织**：研究如何把一个关系划分为多个子集合，并将其分布到多个处理节点上去（称为数据库划分），其目的是==使并行数据库能并行地读写多个磁盘进行查询处理，充分发挥系统的I/O并行性==。数据划分对于并行数据库的性能有很大影响，目前数据划分方法主要有一维数据划分、多维数据划分和传统物理存储结构的并行化等。
3. **新的并行数据操作算法**：研究表明，使用并行数据操作算法以实现查询并行处理，可以充分地发挥多处理机的并行性，极大提高系统查询处理的效率和能力。许多并行算法已被提出，主要是围绕连接操作的算法较多，它们有基于嵌套循环的并行连接算法、基于 `Sort-Merge` 的并行连接算法、并行 `Hash-Join` 算法。
4. **查询优化**：查询优化是并行数据库的重要组成部分。并行查询优化中的执行计划搜索空间庞大，研究人员研究了**启发式的方法**，对并行执行计划空间作裁剪，以减少搜索空间的代价。具有多个连接操作的复杂查询的优化，是查询优化的核心问题。不少学者相继提出了基于左线性树的查询优化算法、基于右线性树的查询优化算法、基于片段式右线性树的查询优化算法、基于浓密树的查询优化算法、基于操作森林的查询优化算法等。这些算法在搜索代价和最终获得的查询计划的效率之间有着不同的权衡。

比较著名的并行数据库系统有Arbre、Bubba、Gamma、Teradata及XPRS等。==并行数据库成本较高，扩展性有限，面对大数据分析需要巨大的横向扩展 `scale out` 能力，使并行数据库遇到了挑战==。Google公司提出的 `MapReduce` 技术，作为面向大数据分析和处理的并行计算模型，2004年公布后便引起了工业界和学术界的广泛关注。

## 13.3.3 面向应用领域的数据库新技术
数据库技术被应用到特定的领域中，出现了数据仓库、工程数据库、统计数据库、空间数据库、科学数据库等多种数据库（如图所示），使数据库领域的应用范围不断扩大。
![在这里插入图片描述](https://img-blog.csdnimg.cn/acbe8488d5264147a3ff01e695ff1bad.png)

这些数据库系统都明显地带有某一领域应用需求的特征，难以直接使用当前市场上销售的、通用的DBMS来管理和处理这些领域内的数据对象，因而，广大数据库工作者针对各个领域的数据库特征，探索和研制了各种特定的数据库系统，取得了丰硕的成果，不仅为这些应用领域建立了可供使用的数据库系统（有的已经实用化），而且为新一代数据库技术的发展做出了贡献。==面向特定应用领域的数据库系统，也称为**特种数据库系统**==[12]，这里举两个例子加以说明，数据仓库以及大数据时代的新型数据仓库则在(16)章专门讲解。

### 1. 工程数据库
==工程数据库 `Engineering Data Base, EDB` 是一种能存储和管理各种工程设计图形和工程设计文档，并能为工程设计提供各种服务的数据库==。工程数据库又称为CAD数据库、设计数据库、技术数据库、设计自动化数据库等，适合CAD/CAM、地理信息处理、军事指挥、控制、通信等工程应用领域。当数据库应用于工程领域时，发现传统的数据库对具有复杂结构和工程设计内涵的工程对象，以及工程领域中的大量“非经典”应用难以胜任。工程数据库正是针对工程应用领域的需求，而提出来的。

由于工程数据的数据结构复杂、相互联系紧密、数据存储量大，因此工程数据库管理系统的功能与传统DBMS有很大不同，主要应具有以下功能：
- 支持复杂对象（如图形数据、工程设计文档）的表示和处理；
- 可扩展的数据类型；
- 支持复杂多样的工程数据的存储和集成管理；
- 支持变长结构数据实体的处理；
- 支持工程长事务和嵌套事务的并发控制和恢复；
- 支持设计过程中多个不同数据版本的存储和管理；
- 支持模式的动态修改和扩展；
- 支持多种工程应用程序等

工程数据库系统主要有两种实现方式，一种是**在关系数据库系统的基础上加以扩充或改进**，另一种是**开发支持新数据模型的数据库管理系统**，其数据模型主要有语义数据模型、面向对象数据模型等。
### 2. 空间数据库
空间数据是用于表示空间物体的位置、形状、大小和分布特征等诸方面信息的数据，适用于描述所有二维、三维和多维分布的关于区域的现象。

空间数据的特点是，不仅包括物体本身的空间位置及状态信息，还包括表示物体的空间关系（即拓扑关系）的信息。属性数据为非空间数据，用于描述空间物体的性质，对空间物体进行语义定义。==空间数据库系统 `Spatial Data Base System, SDBS` 是描述、存储和处理空间数据及其属性数据的数据库系统==。

空间数据库的研究始于地图制图、遥感图像处理领域，其目的是**为了有效地利用卫星遥感资源，迅速绘制出各种经济专题地图**。由于传统数据库在空间数据的表示、存储、管理和检索上存在许多缺陷，从而形成了空间数据库这一新的数据库研究领域，它涉及计算机科学、地理学、地图制图学、摄影测量与遥感、图像处理等多个学科。

空间数据库研究的主要内容包括以下几个方面：
（1）**空间数据模型**，描述空间实体和空间实体关系的数据模型，**一般用传统的数据模型加以扩充和修改来实现**，有的用面向对象的数据模型来实现。
（2）**空间数据查询**，包括**位置查询**、**空间关系查询**和**属性查询**，前两种查询是空间数据库特有的查询方式。
（3）**空间数据库系统**，大多数空间数据库系统是以现有的数据库管理系统为基础建立的。**上层是各种空间应用**，如GIS应用、CAD应用等；**中间层是空间数据库系统**，它结合传统的数据库技术，实现对空间对象的存储和查询，并提供对空间应用开发的支持；**下层是成熟的数据库管理系统**，一般采用对象关系数据库管理系统，或面向对象数据库管理系统，实现对常规数据的存储和查询。
（4）**查询语言**，大多是以SQL语言为基础，增加相应的函数，实现对空间对象和空间关系的查询。为了提高访问效率，研究了针对空间数据的索引结构，如**面向空间点的索引结构**（网格文件、K维树、自适应K维树）和**面向矩形的索引结构**（R树、四叉树、单元树等）。

近年来，随着手机等移动设备的普及，基于位置的服务成为新的研究热点。因此，面向道路网络的空间对象管理和移动对象管理等方面的技术，成为空间数据管理中的新内容。

---
# 13.4 数据管理技术的发展趋势
==数据、应用需求和计算机硬件技术，是推动数据库发展的三个主要动力或三个重要因素==。进入21世纪以来，数据和应用需求都发生了巨大变化，硬件技术有了飞速发展，尤其是大数据时代的到来，数据库技术、更广义的数据管理技术和数据处理技术遇到了前所未有的挑战，也迎来了新的发展机遇。
## 13.4.1 数据管理技术面临的挑战
数据的变化如下所述：
- **随着数据获取手段的自动化、多样化和智能化，数据量越来越巨大，对于海量数据的存储和管理，要求系统具有高度的可扩展性、可伸缩性，以满足数据量不断增长的需要**。传统的分布式数据库和并行数据库，在可扩展性和可伸缩性方面明显不足。
- **数据类型越来越多样和异构**，从结构化数据扩展到文本、图形图像、音频、视频等多媒体数据，HTML、XML、网页等半结构化/非结构化数据，还有流数据、队列数据和程序数据等。这就**要求系统具有存储和处理多样异构数据的能力，特别是异构数据之间联系的表示、存储和处理能力，以满足对复杂数据的检索和分析的需要**。传统数据库对半结构化/非结构化数据的存储、管理和处理能力十分有限。
- **图形图像、视频音频等视觉听觉数据**，由于传感、网络和通信技术的发展，使得对它们的获取、传输更加便利，而这类数据的语义蕴含在流数据中，并且存在大量冗余和噪声。许多应用中数据快速流入并要立即处理，**数据的快变性、实时性要求系统必须迅速决定什么样的数据需要保留，什么样的数据可以丢弃，如何在保留数据的同时存储其正确的元数据等**，现有技术还远远不能应对。

 应用和需求的发展如下：
 - 数据处理和应用的领域，已经从 `Online Transaction Processing, OLTP` 为代表的事务处理，扩展到`Online Analytical Processing, OLAP` 分析处理，从对数据仓库中结构化的海量历史数据的多维分析发展到对海量非结构化数据的复杂分析和深度挖掘；并且希望把数据仓库的结构化数据，与互联网上的非结构数据结合起来进行分析挖掘，把历史数据与实时流数据结合起来进行处理。
人们已经认识到，**基于数据进行决策分析具有广阔的前景和巨大价值**，但是数据的海量异构、形式繁杂、高速增长、价值密度低等问题，阻碍了数据价值的创造。**大数据分析已经成为大数据应用中的瓶颈**。==现有的分析挖掘算法缺乏可扩展性，缺乏对复杂异构数据的高效分析算法，缺乏大规模知识库的支持和应用，缺乏能被非技术领域专家理解的分析结果表达方法==。对数据的组织、检索和分析都是基础性的挑战。
- 计算机硬件技术是数据库系统的基础。当今，计算机硬件体系结构的发展十分迅速，数据处理平台由单处理器平台向多核、大内存、集群、云计算平台转移。处理器已全面进入多核时代，在主频缓慢提高的同时，处理核心的密度不断增加；内存容量变得越来越大，成本却越来越低；非易失性内存、闪存等技术日益成熟。
因此，我们必须充分利用新的硬件技术，满足海量数据存储和管理的需求。==一方面要对传统数据库的体系结构包括存储策略、存取方法、查询处理策略、查询算法、事务管理等进行重新设计和开发，要研究和开发**面向大数据分析的内存数据库系统**；另一方面，针对大数据需求，以集群为特征的云存储成为大型应用的架构，要研究与开发新计算平台上的数据管理技术与系统==。
## 13.4.2 数据管理技术的发展与展望 
==大数据给数据管理、数据处理和数据分析提出了全面挑战==。支持海量数据管理的系统应具有**高可扩展性**（满足数据量增长的需要）、**高性能**（满足数据读写的实时性和查询处理的高性能）、**容错性**（保证分布系统的可用性）、**可伸缩性**（按需分配资源）等。传统的关系数据库在系统的伸缩性、容错性和可扩展性等方面，难以满足海量数据的柔性管理需求，NoSQL技术顺应大数据发展的需要，蓬勃发展。

==NoSQL是指非关系型的、分布式的、不保证满足ACID特性的一类数据管理系统==。NoSQL技术有如下特点：
（1）对数据进行划分 `partitioning` ，通过大量节点的并行处理获得高性能，采用的是**横向扩展**的方式 `scale out` 。
（2）放松对数据的**ACID一致性约束**，允许数据暂时出现不一致情况，接受**最终一致性** `eventual consistency` 。即NoSQL遵循 `Basically Available, Soft State, Eventual Consistency, BASE` 原则，这是一种**弱一致性** `weak consistency` 约束框架——其中，基本可用 `Basically Available` 是指**可以容忍数据短期不可用**，并不强调全天候服务；柔性状态 `Soft State` 是指**状态可以有一段时间不同步，存在异步的情况**；最终一致性 `Eventually Consistency` 是指**最终数据一致，而不是严格的一致**。
（3）对各个数据分区进行备份（一般是三份），应对节点可能的失败，提高系统可用性等。

NoSQL技术依据存储模型，可分为**基于 `Key-Value` 存储模型、基于列分组 `Column Family` 存储模型、基于文档模型**和**基于图模型的NoSQL数据库技术**四类。

==分析型NoSQL技术的主要代表是 `MapReduce` 技术，这一技术框架包含三方面的内容：**高度容错的分布式文件系统**、**并行编程模型**和**并行执行引擎**==。`MapReduce` 并行编程模型的计算过程，可分解为两个主要阶段，即 `Map` 阶段和 `Reduce` 阶段——`Map` 函数处理 `Key/Value` 对，产生一系列的中间 `Key/Value` 对；`Reduce` 函数合并所有具有相同 `Key` 值的中间 `Key/Value` 对，计算最终结果。==用户只需编写 `Map` 函数和 `Reduce` 函数，`MapReduce` 框架在大规模集群上自动调度执行编写好的程序，扩展性、容错性等问题由系统解决，用户不必关心==。 

自2004年Google首次发布 `MapReduce` 以来，该技术得到业界的强烈关注。一批新公司围绕 `MapReduce` 技术创建起来，提供大数据处理、分析和可视化的创新技术和解决方案，在并行计算研究领域迎来了第一波研究热潮（2006-2009）；数据库研究领域紧随其后（2009-2012），掀起了另外一波研究热潮。

传统数据库厂家，包括曾经反对 `NoSQL/MapReduce` 技术的一些厂家（如Oracle、VoltDB、Microsoft等），纷纷发布大数据技术和产品战略。各公司和研究机构都投入力量，基于 `MapReduce` 框架展开了研究，例如研发应用编程接口——SQL、统计分析、数据挖掘、机器学习编程接口等，以帮助开发人员方便地使用 `MapReduce` 平台进行算法编写。

==传统关系数据库系统提供高度的一致性、精确性、系统可恢复性等关键特性，仍然是事务处理系统的核心引擎，无可替代==。同时，数据库工作者也在努力研究，保持ACID特性的同时具有NoSQL扩展性的NewSQL技术。针对大内存和多核多CPU的新型硬件，研发面向实时计算和大数据分析的内存数据库系统。通过列存储技术、数据压缩、多核并行算法、优化的并发控制、查询处理和恢复技术等，提供比传统关系数据库管理系统快几十倍的性能。

理论界和工业界继续发展已有的技术和平台，同时不断地借鉴其他研究和技术的创新思想，改进自身，或提出兼具若干技术优点的混合技术架构。例如，Aster Data（已被TeraData收购）和Greenplum（已被EMC收购）两家公司利用 `MapReduce` 技术，对PostgreSQL数据库进行改造，使之可以运行在大规模集群上（MPP/Shared Nothing）。总之，RDBMS在向 `MapReduce` 技术学习。

`MapReduce` 领域对RDBMS技术的借鉴是全方位的，包括存储、索引、查询优化、连接算法、应用接口、算法实现等各个方面。例如，RCFile系统在HDFS的存储框架下，保留了 `MapReduce` 的扩展性和容错性，赋予HDFS数据块类似于PAX的存储结构，通过借鉴RDBMS技术，在Hadoop平台上实现列存储，提高了Hadoop系统的分析处理性能。==各类技术的相互借鉴、融合和发展，是未来数据管理领域的发展趋势==。

当然，大数据时代下所面临的挑战不仅包括扩展性这样明显的问题，还包括异构性、数据非结构化、错误处理、数据隐私、及时性、数据溯源、可视化等问题。这些技术挑战同时横跨多个应用领域，因此仅在一个领域范围内，解决这些技术挑战是比较困难的。

---
【数据库系统】第四部分 数据库新技术(14) 大数据管理
# 本章参考文献
![在这里插入图片描述](https://img-blog.csdnimg.cn/92d7c47928ea412d80041ad0603b817e.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/494574990bc442f0926cf760ef8681c3.png)

# 14.1 大数据概述
大数据是当今科技界、工业界甚至各国政府关注的热点，国际著名的学术期刊 *Nature* 和 *Science* 等相继出版专刊，专门探讨大数据带来的挑战和机遇。大数据正在孕育新的学科——数据科学，正在创造价值、正在形成新的产业，正在给我们展现无穷的、变化的、灿烂的前景。毫无疑问，对于大数据的挖掘和运用，预示着新一波生产力增长和科技发展浪潮的到来。

这里介绍**什么是大数据、大数据的特征、大数据的应用、大数据管理系统**，着重从数据管理和数据处理的角度来讨论这些问题和技术。
## 14.1.1 什么是大数据
大数据和数据库领域的**超大规模数据** `very large data` 、**海量数据** `massive data` 有什么不同？


## 14.1.2 大数据的特征
---
# 14.2 大数据的应用
当前大数据的应用丰富多彩，这里介绍两个应用案例，说明大数据应用具有的特点，以及对大数据管理和大数据系统提出的技术需求和挑战。
## 14.2.1 感知现在，预测未来——互联网文本大数据管理与挖掘
互联网媒体又称**网络媒体**，是以互联网为传输平台，以计算机、移动电话、便携设备等为终端，以文字、声音、图像等形式来传播新闻信息的一种数字化、多媒体的传播媒介，相对于传统的报纸、广播、电视等媒体而言，也称为“第四媒体”。
### 1. 互联网媒体文本大数据应用：时事探针
高速发展的互联网媒体，在给人们获得信息带来便利的同时，也带来了新的挑战，其中之一就是“**信息过载**”问题——当一个重要新闻事件发生后，各种互联网媒体会有大量相关报道，这些信息每时每刻不断地增加，如此大量往往超过了个人所能处理的范围。**首先，用户很难快速查找和浏览有用信息；其次，大量的信息是冗余和包含噪音的；再次，用户很难对海量的文本信息进行汇总和理解**。因此，==如何处理和分析互联网媒体大数据，帮助人们在海量数据中获取及分析真实有价值的信息，从而正确感知现在、迅速预测未来，做好应急事件的预案和方法，是一个具有重大价值并且亟待解决的研究问题==。

中国人大研究开发了一个互联网舆情分析系统，称为时事探针系统。该系统可以实时监控、收集互联网媒体数据，并对数据进行深入的挖掘和分析。其主要功能包括动态数据抓取、历史数据保留、数据深度智能分析、数据可视化展示、敏感信息实施捕捉、预定阈值报警等。该系统可以有效地帮助用户、企业以及政府机构对所关注的新闻话题在互联网媒体中的报道，进行感知、获取、跟踪、预警和深入分析，具有极大的应用价值。

例如，使用这一系统对“高考”这一话题进行分析，下图显示媒体对于高考这一话题整体关注度比较高，从2014年5月份开始，随着高考的临近，报道量持续增加。
![在这里插入图片描述](https://img-blog.csdnimg.cn/404488fc54934e7ebe28e98a4775c4d1.png)
下图展示了对“高考”热议话题的多维分析。该图显示与“高考”有关的主要人物、主要地点、相关机构和热议话题。**多维分析**让用户对“高考”这一话题的主要内容一目了然。
![在这里插入图片描述](https://img-blog.csdnimg.cn/5915eea62366459b920bbb34d2f5faed.png)
为了深入了解报道内容，用户还可以在时事探针上进行**多维度交叉分析**。例如，要深入了解英语退出高考的信息，可以选择相关话题中的“英语退出高考”，时事探针系统会自动更新其他维度。下图显示有关该话题的正面报道、负面报道和中性报道的分布情况。显示相关报道集中在5月19日左右，热门人物是顾明远，讨论最多的地点为上海和北京，核心报道内容为顾明远和教育部否认“英语退出高考”：
![在这里插入图片描述](https://img-blog.csdnimg.cn/ec34014748da4e50a001c6dd8799430f.png)
### 2. 互联网文本大数据管理的挑战
==目前，互联网上的新闻报道以及相应的用户反馈（如评论、转发等）以文本内容为主==。该类文本大数据的出现，对现有数据库管理系统提出了挑战——首先，**文本数据中的主题是开放的，每天的新闻文档分别描述成千上万个无直接关联的新闻事件，无法事先预定义关系模式和值域**；其次，**文本大数据一般由自然语言生成，没有确定的结构，无法直接用关系型数据进行存储和查询**；最后，**互联网上的数据量巨大、变化速度快，对数据管理系统的可扩展性和实时性提出了很高的要求**。

对于文本大数据处理，目前广泛使用的互联网搜索引擎（包括新闻媒体引擎）只是对文本数据的简单索引和查找，不能满足用户对所关注话题进行实时监测、深入分析、决策支持等需求。例如，用户可通过搜索引擎获取关于“马航失联”的最新报道，但仍然无法直接通过搜索引擎，了解在该主题中的主要时间、地点、人物、相关事件以及最新进展（？），必须自己整理分析。

### 3. 互联网文本大数据管理系统
如上所述，现有的搜索引擎和关系型数据库，都不能满足用户对互联网文本大数据管理和查询的需求。==互联网文本大数据管理系统在设计时，需要参考并融合**传统信息检索系统**、**数据库系统**以及**数据分析系统**（如数据仓库和OLAP）的特长和技术，以设计数据处理的模型、存储、索引、查询等机制==。同时，==为了满足可扩展性和实时性的需求，需要吸收和借鉴**分布式大数据处理系统**（如Hadoop和NoSQL系统）的设计和经验==。

时事探针系统的结构如下图所示，==这是一个面向互联网文本大数据的、通用的管理和分析平台==。其核心设计理念是，**使用信息检索技术，对无结构的互联网文本数据进行索引，以满足用户查找相关新闻的需求**；同时，**对相关文档中包含的关键信息进行挖掘和抽取，以生成结构化数据，并汇总和分析这些数据，以辅助用户理解报道中包含的高阶知识**。
![在这里插入图片描述](https://img-blog.csdnimg.cn/d49444edfba04b77becc524876932152.png)

具体来说，整个系统分解为离线处理、在线处理两个部分。其中离线部分是设计的重点，主要完成下述功能：
1. **多源异构网络大数据的感知和获取**。由于互联网内在的分布性和自组织性，==数据的感知和获取是网络大数据处理非常重要的**第一步**==。和传统搜索引擎一样，使用**网络爬虫**抓取互联网媒体网站的内容，并存储到原始文档库中。本部分的主要挑战是，如何针对给定的主题*实时智能*地收集相关的网络数据，从而为后续的处理提供准确丰富的数据来源。
2. **文档理解、结构化数据抽取和集成**。互联网的生命力很大程度上来自于它的开放性，而这种开放性的一个负面效果是，网络数据缺乏统一结构、质量良莠不齐。大而低质量的无结构数据往往不能有效地支撑大数据分析和应用。
为了对文本数据进行深入分析，需要采用**数据抽取**技术，==从中挖掘出高质量的结构化信息==；另一方面，属于同一个实体或概念的数据，往往在多个数据源中以不同的形式表示，**数据集成**技术被用于==将这些不同形式的数据进行统一和集成==。==「数据抽取和集成」是大数据研究的一个难点和热点==，具体技术包括**文档编码检测**以及**HTML文本转换**、**文档语言**（如中文、日文或者英文）**检测**、**正文及相关属性**（标题、时间、作者、主要图片等）**抽取**、**文档内容段落及句子切分**、**文本分词**、**命名实体**（时间、地点、人物、机构等）**识别**、**动词专有名词抽取**、**情感分析**、**话题检测**、**知识库实体匹配及消歧**、**事件检测及抽取**等。
3. **数据存储和索引**。==原始文档库主要用于保存抓取下来的原始网页，其中主要进行文档的写入和读取，无删除操作，并发计算和查询的需求不大，**可直接使用关系型数据库或NoSQL数据库**==。由于原始文档库中的文档在写入时，一般按照时间顺序写入，在对原始文档库中的文档进行处理时，也一般按照时间顺序进行，因此**需要对文档抓取时间进行索引**。
==结构化文档库中，主要存储对文档进行深入理解后抽取的信息==，包括文档标题、文档正文、文档时间、文档作者、主要图片等文档级别的信息，也包括句子级别的信息，如句子文本、情感值、句子所包含的命名实体、关键词等。
在传统的关系数据库中，关系一般遵循范式的要求，以尽可能节省存储空间，并保证数据一致性。而事实上，==因为互联网文本数据量巨大，若严格按照范式的要求进行设计，查询时可能需要大量的连接 `join` 操作和随机读取，写入时也可能需要在多个表上进行查询和加锁，实践证明**这会极大地降低系统性能**==。因此，在时事探针中，**增加了部分数据冗余以降低交叉查询的代价**，提高数据查询的效率。例如，冗余存储“文档正文”和句子中的“句子文本”。
==在结构化文档库上，有大量的并发读写和查询操作。针对互联网文本数据的特点，对数据一致性和完整性的要求可适当放宽==。例如，对某一事件的报道可能有数千条，个别报道的丢失一般不会对整个事件的理解造成重大影响。互联网文本数据管理在一定程度上能够容忍丢失更新、不可重复读、读脏数据等不一致性问题，因此**结构化文档库上要尽量减少读写锁，并采用较低的事务隔离级别**。
4. **离线主题文本立方体建立及更新**。文本立方体是针对特定主题建立的多维度数据立方体，是时事探针系统的**主要分析模型**。==和传统的关系数据仓库上建立的单个数据立方体不同，系统中每个主题都可以建立一个对应的文本立方体，以对该主题进行分析操作==。文本立方体可根据用户查询在匹配的所有文档上，对结构化数据进行高效并行统计而建立。假设“马航失联”这一主题在互联网媒体中一共有一万篇报道，每个报道中有不同的相关人物、相关地点、相关机构。在这些报道文档中，可建立包含相关人物、相关地点、相关机构这三个维度 `dimension` 的文本立方体，每个维度中的项由所有文档中出现的实例（如所有人物）构成。==和传统的数据立方体不同，在文本立方体中不具有直接的度量值可以使用。时事探针系统通过比较文档（记录）和维度值的紧密程度来计算度量值==，如对于相关人物 $A$ ，考虑 $A$ 在文档 $D$ 中出现的次数、位置、所在句子的长短等特征，并同时考虑报道的来源来计算 $A$ 在 $D$ 中的度量值。
5. **在线处理部分负责接收用户查询，检索相关文档及文本立方体并返回给用户**。其主要模块包括关键词分词、倒排表文档匹配及排序、文本立方体生成及缓存、文档及文本立方体展示及交互。

综上所述，互联网文本大数据管理的特点如下：
（1）互联网文本大数据蕴含着丰富的社会信息，可以看作是对真实社会的网络映射。
（2）实时、深入分析互联网文本大数据，帮助人们在海量数据中获取有价值的信息，发现蕴含的规律，可以更好地感知现在、预测未来，体现了第四范式数据密集型科学（？）发现的研究方式和思维方式。
（3）互联网文本大数据管理，对大数据系统和技术的挑战是全面的、跨学科跨领域的，需要创新，也要继承传统数据管理技术和数据仓库分析技术的精华。

## 14.2.2 数据服务，实时推荐——基于大数据分析的用户建模
随着以个性化为主要特点的Web 2.0兴起，很多大数据应用的数据来源于规模庞大的用户群。依托数百万、千万甚至上亿规模的用户，面向大众的信息服务类应用在为大规模用户提供信息服务的同时，通过**用户原创内容** `User Generated Content, UGC` 或**系统日志**等方式，不断地收集数据。这些数据与用户的行为紧密相关，被用来分析用户的兴趣特征，创建用户的描述文件 `user profile` ，这就是基于大数据分析的用户建模。
### 1. 面向用户建模的大数据系统框架
==用户建模的目标是为了准确把握用户的行为特征、兴趣爱好等，进而较为精确地向用户提供个性化的信息服务或信息推荐==。例如，互联网网站通过对用户点击日志的分析，识别用户的偏好，以支持个性化的页面布局、精准的广告投放等；电信行业通过对用户消费信息、当前位置、使用习惯等数据的分析，为用户及时推荐符合用户需求的服务、产品、内容等。当前，「基于大数据的用户建模」在很多大型的信息服务应用中，发挥着至关重要的作用。

面向用户建模的大数据系统，一般具有下图所示的基本架构。==在大数据采集、存储的基础上，使用**在线分析**和**离线分析**两类技术，从大数据中发现用户的兴趣特征，构建**动态的用户兴趣模型**，以**数据服务**的方式管理和维护用户兴趣模型中的数据，支持上层的信息推荐等各种各样的应用==。这类系统中，「数据分析」和「数据服务」构成了大数据系统的两类典型的负载。
![在这里插入图片描述](https://img-blog.csdnimg.cn/8b1b9a3cb98a44c49a9885435ef0cecf.png)

### 2. 数据分析：用户建模的典型工具
传统的信息服务类应用，一般采用静态的用户建模方法，即系统在构建之初就定义好了用户兴趣模型所包含的属性维度。==随着互联网和大数据技术的发展，面向大众的信息服务应用，不再满足于**静态的用户建模**，而是开始关注从用户行为相关的实时大数据中，使用众多的数据分析和挖掘技术，得到能够反映用户兴趣和其变化的**动态用户兴趣模型**==。这种动态性不仅包含属性值的变化，还包含用户兴趣模型中属性类型、属性数量的变化。



---
# 14.3 大数据管理系统
## 14.3.1 NoSQL数据管理系统
## 14.3.2 NewSQL数据系统
## 14.3.3 MapReduce技术
## 14.3.4 大数据管理系统的新格局 


---

【数据库系统】第四部分 数据库新技术(15) 内存数据库系统
# 本章参考文献
![在这里插入图片描述](https://img-blog.csdnimg.cn/77333ad016b348ffba924887d3d6cb60.png)![在这里插入图片描述](https://img-blog.csdnimg.cn/d20145e7418241e5a6ca523c031fe07e.png)


# 15.1 概述
**内存数据库** `Main Memory DataBase, MMDB` **系统**是指，**将数据库的全部或大部分数据放在内存中的数据库**[1]，其实现技术的研究始于20世纪80年代，目的是==有效利用内存的优势，提高数据库的性能==。随着计算机硬件技术的发展、高性能数据处理需求的推动，特别是大数据时代的到来，**内存数据库系统已经成为数据库系统的一个新方向**。2013年Gartner发布前十大战略性技术趋势，将内存计算列入重要的发展趋势之一。这里介绍内存数据库的基本知识、相关技术。
# 15.2 内存数据库的发展历程
==内存数据库是将内存作为主存储设备的数据库系统==，也称**主存数据库** `In-Memory DataBase` 。==与内存数据库相对的是**磁盘数据库** `Disk Resident DataBase, DRDB` 是使用磁盘作为常规数据存储设备、使用内存作为*工作数据缓冲区*的数据库系统==。
- 在磁盘数据库中，**磁盘**是常规的**数据存储设备**，**磁盘阵列或磁带机**是数据的**后备存储设备**，内存作为磁盘数据库的缓存使用。==磁盘数据库的数据组织、存储访问模型及处理模型，都是**面向磁盘访问特性**而设计的，磁盘数据通过缓冲区被处理器间接访问，查询优化的核心是「**减少磁盘的输入输出**」==。
- 在内存数据库中，**内存**是常规的**数据存储设备**，**磁盘**是数据的**永久存储及后备存储设备**。==内存数据库的数据组织、存储访问模型及处理模型，都针对**内存特性**进行了优化设计，内存数据被处理器直接访问==。
![在这里插入图片描述](https://img-blog.csdnimg.cn/0bf60a69c009449f98629a582127311f.png)

**内存数据库中的数据常驻内存，消除了磁盘数据库中巨大的输入/输出代价**。同时，数据的存储和访问算法以「内存访问特性」为基础，**实现处理器对数据的直接访问，在算法和代码效率上高于「以磁盘输入/输出为基础的磁盘数据库」**。在内存数据库中，**使用针对内存特性优化的存储结构、索引结构和操作算法，进一步优化了内存数据库的性能**，因此，与「数据全部缓存到内存的磁盘数据库」相比，内存数据库的性能仍然高出数倍。

---
# 15.2 内存数据库的发展历程
内存数据库的研究起步较早，20世纪60年代末就出现了内存数据库的雏形。由于当时内存容量较小、成本较高，内存数据库主要作为**嵌入式系统或磁盘数据库辅助的存储与加速引擎**存在，主要目的是==把磁盘数据库中使用频繁的“热数据”集中存放在内存中，提高这些关键数据的查询和处理效率==。随着内存的价格不断下降、容量不断增大，内存数据库的实用性得到显著提高，从而促进了内存数据库技术的研究与发展。

## 1. 内存数据库的雏形期
1969年，IBM公司研制了国际上最早的层次数据库管理系统IMS。IMS在一个系统中提供了两种数据管理方法，一种是采用内存存储的 `Fast Path` ，另一种是支持磁盘存储的 `IMS` 。`Fast Path` 支持内存驻留数据，是内存数据库的雏形，它体现了内存数据库的主要设计思想，也就是==将需要频繁访问、要求高响应速度的数据直接存放在物理内存中访问和管理==。内存数据库起步于层次数据库，其后的发展逐渐转向关系型内存数据库。
## 2. 内存数据库的研究发展期
1984年，`D. J. De  Witt` 等人发表了“内存数据库系统的实现技术”一文，**第一次**提出了 `Main Memory DataBase` 的概念。专家预言，异常昂贵的计算机内存价格一定会逐渐下降，大容量的数据有可能全部存储在内存中，因此开展了对内存数据库关键技术的研究，包括内存计算的AVL树、哈希算法、使用非易失内存或**预提交和成组提交技术**，解决内存易失性问题、内存数据库恢复机制等。

1985年，IBM推出了在IBM 370上运行的OBE内存数据库，OBE在关系存储和索引上大量使用指针，连接操作使用嵌套循环算法，查询优化的重点是内存的处理代价。

1986年，`R. B. Hagman` 提出了使用**检查点技术**实现内存数据库的恢复机制。威斯康星大学提出了**按区双向锁定模式**，解决内存数据库中的并发控制问题，并设计出MM-DBMS内存数据库。贝尔实验室推出了**DALI内存数据库模型**，重要特点是==使用内存映射体系，采用分区技术、把数据库的数据文件映射到共享内存==，处理器可以直接通过指针，访问存储在内存数据库中的信息，还可以根据需要来打开或关闭「数据库的并发控制和日志机制」。

1987年，ACM SIGMOD会议中，有论文提出了以**堆文件** `heap file` 作为内存数据库的数据存储结构。`Southern Methodist` 大学则设计出MARS内存数据库模型，该模型采用**双处理器**分别用于数据库和恢复处理，==事务提交点之前的任务由数据库处理器负责，恢复处理器负责事务提交，将日志和更新的数据写到磁盘数据库中，周期性的检查点同样由恢复处理器负责==。MARS采用双处理器、易失性内存、非易失性内存存储设备，将事务处理划分为两个独立的阶段，独立加速各自阶段的处理性能。

1988年，普林斯顿大学设计出TPK内存数据库。TPK提供了一种多处理器架构下的多线程处理模式，包括输入、执行、输出、检查点四类线程，通常配置为**单查询执行线程**和**单检查点线程**——==单查询执行线程的设计不需要并发控制机制，而输入和输出线程的数量可以为多个，并且使用队列结构、与其他线程连接==。TPK的多线程内存数据库，实现了一种多阶段的查询处理技术。

1990年，普林斯顿大学又设计出System M内存数据库。System M由一系列**操作服务线程**构成，包括消息服务线程、事务服务线程、日志服务线程、检查点服务线程等。==System M可以支持并发查询服务线程，但仍然要控制活动事务服务线程的数量==。
## 3. 内存数据库的产品成长期
随着互联网的发展，越来越多的网络应用需要高性能、高并发的数据库系统支撑，传统企业级的数据库应用，如电信、金融等领域同样需要高性能的实时数据库系统。应用需求催生了内存数据库市场。

在硬件方面，半导体技术快速发展、内存存储密度不断提高，动态随机存取存储器 `DRAM` 的容量越来越大、价格越来越低。这些为计算机内存的不断扩大提供了硬件基础，使得内存数据库的技术在可行性、成本的合理化方面逐步成熟，一些公司陆续推出了不同的内存数据库产品。
- 1994年，美国OSE公司推出了**第一个商业化的、开始实际应用的内存数据库产品** Polyhedra。1996年，TimesTen公司成立并推出第一个商业版内存数据库TimesTen 2.0，2005年该公司被Oracle公司收购。1998年，德国SoftwareAG公司推出了内存数据库Tamino Database。1999年，日本UBIT会社开发出了内存数据库产品XDB；韩国Altibase公司推出了内存数据库Altibase。2000年，奥地利QuiLogic公司推出了内存数据库SQL-IMDB。2001年，美国McObject推出了内存数据库eXtremeDB；加拿大Empress公司推出了内存数据库EmpressDB。
- 2003年，荷兰CWI研究院研制了**基于列存储模型的内存数据库** MonetDB[3][4]，其后又研制了**基于向量处理技术**的MonetDB/X100系统，2008年推出其商业化版本Vectorwise。2010年Ingres公司和CWI研究院，合作推出了VectorWise 1.0版本。2011年3月VectorWise 1.5版获得了TPC-H 100GB数据量测试的第一名，当前仍然是TPC-H性能最高的数据库（？）。
- 2008年，IBM收购Solid公司的内存数据库SolidDB，成为IBM家族的一个产品，IBM提出Blink BI（商业智能）内存查询处理引擎，并为Informix提供内存加速包IWA `Informix Warehouse Accelerator` 。
- 2011年，SAP公司推出SAP HANA `High-Performance Analytic Appliance` [5]高性能分析应用系统，这是面向企业分析型应用的内存计算技术的产品。
- Oracle公司在2008年推出软硬件集成设计的Oracle Exadata数据库服务器，Oracle Exadata是由Database Machine（数据库服务器）与Exadata Storage Server（存储服务器）组成的一体机平台。2012年推出Oracle Exadata X3 Database In-Memory Machine，大幅增加了内存配置，==实现将全部数据加载到内存，将所有的数据库I/O全部转移到闪存，以提供高性能的数据访问和查询处理，成为Oracle新一代的内存数据库一体机平台==。

综上所述可以发现：
1. **最初的内存数据库仅仅是针对「特定的应用需求定制的内存数据处理系统」**，如要求高实时响应的电信应用。这类系统通过应用程序来管理内存和数据，不支持SQL语句，不提供本地存储，没有数据库恢复技术，性能好但不是通用平台，难以维护和推广。
2. 后来，==内存数据库系统能支持部分的SQL语句，以及简单的系统恢复，能够快速处理简单事务，主要针对功能简单的事务处理应用==，如交换机、移动通信等应用系统。
3. 随后，针对传统数据库的商业应用领域，研制了通用的内存数据库系统，它们具备了高性能、高通用性以及高稳定性，能处理复杂的SQL语句，其应用几乎包括磁盘数据库的所有应用领域。

近年来，针对大内存上的大数据实时分析处理任务，又研制了分析型内存数据库，主要面向只读 `read-most` 查询处理或 `append-only` 类型的更新任务，以列存储与混合存储、多核并行处理、复杂分析查询处理为特点，为用户提供秒级甚至亚秒级分析处理能力。随着未来众核协处理器、通用计算图形处理器 `General Purpose Graphic Unit, GPGPU` 等新的高性能计算平台进入数据库领域，**内存数据库将成为大数据实时分析处理平台**。

---
# 15.3 内存数据库的特性
==内存是计算机存储体系结构中，**能够被程序可控访问**（相对于硬件控制的 `cache`）**的最高层**次，是**能够提供大量数据存储的最快的存储层**==。内存数据库具有优异的数据存储访问性能、较高的数据访问带宽和并行访问能力等特性。
- 硬件相关性：**内存数据库的性能受硬件特性的直接影响**。计算机硬件技术的发展，主要体现在高端计算设备和存储设备上，如多核处理器、众核协处理器 `Many Integrated Core, MIC` 、通用GPU、相变存储器 `Phase Change Memory` 、固态硬盘 `Solid State Disk, SSD` 存储等。这些计算能力和存储性能的提升，有助于提高内存吞吐率（众核技术）、内存持久存储能力（PCM技术）或为内存提供二级存储（SSD技术）。==硬件技术在多核及众核处理器、高性能存储和高速网络等方面的发展，为内存数据库提供了**高并行处理、高性能存储访问、高速连通的硬件平台**。内存数据库的设计，应该充分考虑并有效利用由新硬件技术带来的功能扩展和性能提高==。
- 高吞吐率和低延迟访问：**数据库的查询处理性能，主要取决于数据的存储、访问性能**。内存数据库不需要磁盘数据库的缓冲区机制，数据能够被处理器直接访问。==**内存的高带宽和低访问延迟**，保证了内存数据库具有较高的事务吞吐率和较低的查询处理延迟，能够支持高实时响应的应用需求==，在金融、电信、电子商务平台等查询负载重、查询响应时间要求高的应用环境中，得到了广泛的应用。
- 并行处理能力：==**内存具有良好的并行数据访问能力**==（当前为四通道内存访问机制？）==和**随机访问性能**，因此内存数据库的查询处理能力带有天然的并行性，还能充分利用随机访问能力，提高查询的数据访问效率和CPU指令效率==。以磁盘为中心的磁盘数据库，难以充分利用当前新硬件带来的高度并行计算能力，而内存数据库在查询处理模型中，则能充分考虑这一点。因此，==在内存数据库的查询处理设计中，既要研究和开发面向内存特性的查询处理优化技术，又要研究并行处理优化技术==。


---
# 15.4 内存数据库的关键技术
由于内存数据库的上述特点，我们在内存数据库实现中不能照搬磁盘数据库的相关技术。==通用的内存数据库管理系统，要为用户提供**SQL接口**，具有**内存存储管理、面向内存的查询处理和优化**等基本模块，还应提供**多用户的并发控制、事务管理和访问控制**，能够保证**数据库的完整性和安全性**，在内存数据库出现故障时能够**恢复系统**。== 此外，==内存数据库作为处理器直接访问的数据管理系统，还需研究**自底向上的、「面向内存和多核并行处理」的新的系统框架和实现技术**==。

下面简要介绍内存数据库中的若干关键技术。
## 15.4.1 数据存储
数据库的数据存储一般有**行存储模型**、**列存储模型**和**混合模型**等。

在行存储模型中，元组是连续存放的，适合事务处理中一次更新多个属性的操作，能够保证「对多个属性的操作产生最小的内存访问」；但对于只涉及表中相对较少属性的分析处理，即使该查询只涉及元组的某个或某些属性，其他属性也会被同时从内存读入到缓存，降低了缓存利用率。
列存储模型将关系按列进行垂直划分，相同属性的数据连续存储。当访问特定属性时，只读入所需要的属性所在的分片，所以节省内存带宽，并且具有较高的数据访问局部性，可减少缓存失败，提高数据访问效率。同时，列存储将相同类型的数据集中存储，能够更好地压缩数据以减少内存带宽消耗，利用**单指令多数据流** `SIMD` 技术，提高并行处理效率，通过列存储的数据定长化处理，支持对数据按偏移位置的访问。但是，如果查询所需要的属性较多，列存储需要连接多个划分来满足查询要求，这会导致性能下降，特别是元组重构时需要进行较多的连接操作，代价较高。

针对行存储模型和列存储模型各自的不足，A. Ailamaki等提出了一种混合存储模型[7[ `Partition Attributes Across, PAX` ，该模型将同一元组的所有属性存储在一页内，在业内对元组进行垂直划分。假设关系的属性个数为 $m$ ，将每一页划分为 $m$ 个 $\textrm{MiniPage}$ ，每个 $\textrm{MiniPage}$ 对应一个属性，连续存放每一页中所有元组的该属性的值。由于元组在页内垂直划分，所以该模型具有较好的数据空间局限性，可优化缓存性能；同时，同一元组的值存储在同一页内，所以元组的重构代价比较少。

`Data Morphing` [8]也是一种混合存储技术，它在页内按属性访问特征划分为属性组，将属性访问关联度高的属性组合存储，在一次 `cache line` 访问时获得尽可能多的属性值，提高这些属性访问时的缓存效率。下图展示了行存储a)、PAX存储b)、属性组存储c)的页内物理数据分布：


内存数据库系统既有联机事务处理 `OLTP` 更新密集型应用，也有联机分析处理 `OLAP` 复杂分析型应用，因此行存储和列存储这两种存储模型，被不同的内存数据库系统所采用。例如，TimesTen、SolidDB等事务型内存数据库采用的是行存储模型；MonetDB、HANA、VectorWise等分析型内存数据库采用的是列存储模型。BrightHouse、Oracle Exadata等采用混合存储模型。

BrightHouse在PAX存储模型的基础上，实现了 `Data Pack` 存储机制[9]，如下图所示。它首先将记录水平分片为**分组** `row group` ，$2^{16}$ 行为一个行组，每个行组以列方式存储在 `Data Pack` 数据单元内。BrightHouse在 `Data Pack` 上建立一张表（粗糙属性信息表），用来记录 `Data Pack` 内每列数据的最大值、最小值等信息。因此，在对列数据过滤操作时（如 `weight > 30`），可通过与粗糙属性信息表中 `Data Pack` 最大值（如 $25$）和最小值（如 $15$）的比较，直接跳过不满足过滤条件的 `Data Pack`（不对其进行访问），从而提高列数据访问的效率。

Oracle Exadata采用了一种 `Compression Unit, CU` 的混合列压缩技术，CU对列存储进行分段，并在分段内通过压缩技术，组织不同列的混合数据块存储，如下图所示。

在结构化内存数据库技术发展的同时，「基于 `Key/Value` 的内存存储模型」也逐渐成为满足高实时响应应用的解决方案，这种NoSQL的内存存储技术，具有良好的扩展性，在很多大型社会网络应用中使用。

与磁盘数据库相比，内存在访问模式和访问速度上的优势，为内存数据库的数据组织和存储方式，提供了更大的灵活性和多样性。
## 15.4.2 查询处理及优化
内存数据库的查询处理性能主要由两个因素决定：内存数据访问性能和内存数据处理性能。

## 15.4.3 并发与恢复
### 1. 并发控制
内存数据库与磁盘数据库的并发控制机制类似，细节上存在一定差异。由于数据存储在内存中，内存数据库中的事务执行时间一般较短，因此持续时间也较短，系统中冲突较少。因此，可以采用以下方法减少锁的开销：使用较大的封锁粒度（如表级锁）；采用乐观加锁方式；减少锁的类型；将锁信息存储在数据本身。

对于内存数据来说，封锁产生的CPU代价会对性能产生严重的影响，特别是对于工作负载主要由短小事务构成的OLTP应用场合，每个事务要求极短的响应时间，在几十毫秒甚至微妙之内完成。针对此问题，S. Blott等提出了接近串行的并发控制协议 `almost serial protocol` 。该协议的特点是，写事务在整个数据库上施加互斥锁 `mutex` ，通过时间戳和互斥锁，可在事务的提交记录没有到达磁盘之前，允许新事务开始，并且保证任何提交的读事务不会读到未提交的数据。

并发控制会带来一些系统代价，如CPU代价、存储代价等，影响系统性能。而内存数据库对性能要求非常高，所以利用内存优势，结合内存数据库的应用需求，在保证事务ACID特性的同时，尽量减少并发控制对性能的影响，这是需要进一步研究的问题。

对于分析型内存数据库，并发控制的目标是**减少多个查询对 `cahce` 的并发访问冲突**，提高内存数据库的吞吐性能。并发查询处理需要接近的问题，包括不同查询任务并发执行时的优化技术、相近查询任务执行时的共享查询处理等。
- 不同查询任务的并发执行，包括OLTP和OLAP并发执行，以及不同数据局部性特征的OLAP查询并发执行。Hyper提出了**基于操作系统 `snapshot` 机制的OLTP和OLAP混合负载并发执行技术**，通过操作系统级的 `snapshot` 隔离OLTP更新数据和OLAP只读查询数据，支持不同类型的查询任务的并发执行。MCC-DB通过染色技术，为不同数据局部性特征的查询任务，分配不同的内存地址空间，减少「弱局部性查询任务」对「强局部性查询任务」产生的**LRU污染问题**——指在LRU机制下，`cache` 中一次性访问的弱局部性数据，将频繁访问的强局部性数据驱逐出 `cache` 。
- 相近查询任务的并发处理，其优化技术的核心是**通过对大数据表的共享扫描，减少并发查询时独立大表扫描所产生的 `cache` 缺失**，主要通过**查询分组**以及**查询操作符批处理技术**，实现共享扫描基础上的高并发查询处理。
 
### 2. 恢复机制
==由于内存的脆弱性和易失性，内存数据库中的数据容易被破坏和丢失，所以**需要在磁盘等非易失性存储介质中进行备份，并且在对数据更新时，要将日志写到非易失性存储介质中**==。

磁盘数据库中的日志，都需要在事务提交时写入磁盘。但在内存数据库中，如果在事务提交时将日志写入磁盘，则由于写日志所产生的磁盘I/O，会延长事务的处理时间，降低内存数据库的性能。所以，==将日志写在何处、何时将日志写入磁盘，在内存数据库中是一个非常重要的问题==。一些研究者提出了**预提交、组提交**等方法，以降低日志I/O的代价，并提出使用PCM、flash等非易失性内存存储日志的方法——**首先将日志存储在非易失性内存中，然后提交事务，再异步地将日志写入磁盘**。在实际产品中，TimesTen采用了两种方式记录日志：一是将日志记在内存的一个区域中；二是可以将日志记在磁盘文件上。RAMCloud则采用了一种主从式内存日志机制，即当数据被修改时，将更新日志写入两个或更多的内存后备服务器，**日志首先被存储于后备服务器的内存中，再采用异步方式批量写入磁盘**。

日志的增加是非常迅速的，为了减少日志量以及恢复的时间，数据库都使用检查点技术来截断日志。内存数据库也是如此。例如，MySQL Cluster使用了**全局检查点** `GCP` 和**局部检查点** `LCP` ，当出现单点失败时，可以使用该失败结点的局部检查点进行数据恢复，当出现全局失败时，则需要使用全局检查点进行统一恢复。TimesTen中也使用了两种检查点技术：**阻塞检查点**和**非阻塞检查点**。

==在发生系统崩溃时，如何从备份和日志中恢复数据，也是一个值得研究的问题==。为了能够尽快恢复系统的使用，一般可通过两步来恢复数据：**第一步，首先恢复热点数据，即执行事务所必须的数据；第二步，在后台恢复其他非热点数据**。另外，也可根据数据在磁盘上的存储顺序、优先级（是否为热点数据）以及访问频率等参数，来确定数据的装载顺序。

---
【数据库系统】第四部分 数据库新技术(16) 数据仓库与联机分析处理技术

# 本章参考文献
![在这里插入图片描述](https://img-blog.csdnimg.cn/85db9296fb9d40818931028b387a523d.png)


# 16.1 数据仓库技术
第15章已经提到，计算机系统中存在着两类不同的数据处理工作：**操作型处理**和**分析型处理**，也称作**联机事务处理** `OLTP` 和**联机分析处理** `OLAP` 。
- **操作型处理也叫事务处理，是指对数据库联机的日常操作**，通常是对以一个或一组记录的查询和修改，如火车售票系统、银行通存通兑系统、税务征收管理系统等。这些系统要求快速响应用户请求，对数据的安全性、完整性以及事物吞吐量要求很高。
- **分析型处理是指对数据的查询和分析操作，通常是查询和分析海量的历史数据**，如金融风险预测预警系统、证券股市违规分析系统等。这些系统要访问的数据量非常大，查询和分析的操作十分复杂。

==OLTP和OLAP两者之间的差异，使得传统的数据库技术不能同时满足两类数据的处理要求==，因此20世纪80年代数据仓库 `Data Warehouse, DW` 技术就应运而生。**数据仓库的建立，将操作型处理和分析型处理区分开来。传统的数据库技术为操作型处理服务，数据仓库为分析型处理服务**。二者各司其职、泾渭分明。越来越多的企业认识到数据仓库能够带来收益，逐步在原有数据库基础之上建立起了自己的数据仓库系统。

**随着大数据时代的来临，数据仓库对于企业决策的支持作用越来越大**。由此，数据仓库也成为各大厂商看重并着力发展的业务领域。IBM、Oracle、Teradata等厂商纷纷采用各种软硬件技术（如MPP并行处理、列存储等），将其产品扩展到PB级数据量。另外，新兴的互联网企业也在尝试利用一些新技术（如MapReduce），开发能支持大规模非结构化数据处理的数据仓库解决方案，**如Facebook在Hadoop基础上，开发出Hive系统，用来分析点击流和日志文件**。

数据仓库和数据库只有一字之差，似乎是一样的概念，但实际则不然。==数据仓库是为了构建新的分析处理环境而出现的一种数据存储和组织技术==。由于分析处理和事务处理具有极不相同的性质，因而两者对数据也有着不同的要求。数据仓库概念的创始人 `W. H. Inmon` 在其 *Building the Data Warehouse* 一书中列出了操作型数据与分析型数据之间的区别，具体如下表所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/6538115f325144bc80e5b62d029ac22c.png)

基于上述操作型数据和分析型数据之间的区别，可以给出数据仓库的定义：==数据仓库是一个用以更好地支持企业（或组织）决策分析处理的、面向主题的、集成的、不可更新的、随时间不断变化的数据集合==。**数据仓库本质上和数据库一样，是长期存储在计算机内的、有组织的、可共享的数据集合**。

## 1. 数据仓库的基本特征
数据仓库和数据库主要的区别是，数据仓库中的数据具有以下四个基本特征。
1. **主题与面向主题**。==数据仓库中的数据是面向主题进行组织的==。**主题是一个抽象的概念，是在较高层次上将企业信息系统中的数据综合、归类并进行分析利用的抽象**；在逻辑意义上，它对应企业中，某一宏观分析领域所涉及的分析对象。例如对一家商场而言，概括分析领域的对象，应有的主题包括供应商、商品、顾客等。面向主题的数据组织方式，会根据分析要求将数据组织成一个完备的分析领域，即主题域。
主题是一个在较高层次上对数据的抽象，这使得面向主题的数据组织，可以独立于数据的处理逻辑。因而，我们可以在这种数据环境上，方便地开发新的分析型应用；同时，这种独立性也是建设企业全局数据库所要求的（？），所以面向主题不仅适用于分析型数据环境的数据组织，同时也适用于建设企业全局数据库的组织。
2. **数据仓库是集成的**。前面提到，操作型数据与分析型数据之间差别甚大，数据仓库的数据是从原有的、分散的数据库数据中抽取来的，因此**数据在进入数据仓库之前必然要经过加工与集成、统一与综合**。这一步实际是数据仓库建设中最关键、最复杂的一步。
首先，要统一原始数据中所有矛盾之处，如字段的同名异义、单位不统一、字长不一致等；然后将原始数据结构做一个从面向应用到面向主题的大转变；还要进行数据综合和计算。数据仓库中的数据综合工作，可以在抽取数据时完成，也可以在进入数据仓库以后进行综合时完成。
3. **数据仓库是不可更新的**。==数据仓库主要供决策分析之用，所涉及的数据操作主要是数据查询，一般情况下并不进行修改操作==。数据仓库存储的是相当长一段时间内的历史数据，是不同时点数据库快照的集合，以及基于这些快照进行统计、综合和重组的导出数据，不是联机事务处理的数据。OLTP数据库中的数据经过抽取 `extracting` 、清洗 `cleaning` 、转换 `transformation` 和装载 `loading` 存放到数据仓库中，这一过程简记为 `ECTL` 。一旦数据存放到数据仓库中，数据就不可再更新了。
4. **数据仓库是随着时间变化的**。数据仓库中的数据不可更新，是指数据仓库的用户进行分析处理时，是不进行数据更新操作的，但并不是说在数据仓库的整个生存周期中数据集合是不变的。
数据仓库中的数据是随着时间的变化不断变化的，这一特征表现在以下三个方面。第一，**数据仓库随时间变化不断增加新的数据内容**； 第二，**数据仓库随时间变化不断删去旧的数据内容**；第三，**数据仓库中包含大量的综合数据**，这些综合数据中很多与时间有关，如数据按照某一时间段进行综合、或隔着一定的时间片进行采样等，**这些数据就会随着时间的变化不断地重新综合**。因此，数据仓库中数据的标识码都包含时间项，以标明数据的历史时期。


## 2. 数据仓库中的数据组织
==数据仓库中的数据分为多个级别：早期细节级、当前细节级、轻度综合级、高度综合级==。数据仓库的数据组织结构如下图所示。源数据经过抽取、清洗、转换、装载进入数据仓库。首先进入当前细节级，根据具体的分析处理需求再进行综合，进而成为轻度综合级和高度综合级。随着时间的推移，早期的数据将转入早期细节级。

由于数据仓库的主要应用是分析处理，绝大部分查询都针对综合数据，因而**多重级别的数据组织可以大大提高联机分析的效率**。==不同级别的数据可以存储在不同的存储设备上==。例如，可以将综合级别高的数据存储于快速设备甚至放在内存中。这样，对于绝大多数查询分析，系统性能将大大提高；而综合级别低的数据则可存储在磁带磁盘阵列、光盘组成的磁带上。
![在这里插入图片描述](https://img-blog.csdnimg.cn/2ffc7487174a4839ae00e8a7c426b077.png)

## 3. 数据仓库系统的体系结构
**数据仓库系统的体系结构**如下图所示，由数据仓库的后台工具、数据仓库服务器、OLAP服务器和前台工具组成。
- **数据仓库的后台工具**包括数据抽取、清洗、转换、装载和维护 `maintain` 工具，简称为 `ECTL` 工具或 `ETL` 工具。
- **数据仓库服务器**相当于数据库系统中的数据库管理系统，它负责管理数据仓库中数据的存储管理和数据抽取，并给OLAP服务器和前台工具提供存取接口（如SQL查询接口）。数据仓库服务器目前一般是关系数据库管理系统，或扩展的关系数据库管理系统，即由传统的数据库厂商对数据库管理系统加以扩展和修改，使它能更好地支持数据仓库的功能。
- **OLAP服务器**透明地为前台工具和用户提供多维数据视图，用户不必关心它的分析数据（即多维数据）到底存储在什么地方，是怎么存储的。
- **前台工具**包括查询报表工具、多维分析工具、数据挖掘工具和分析结果可视化工具等。
![在这里插入图片描述](https://img-blog.csdnimg.cn/19a33db8b1a3484e8bb67d384e9e7eb5.png)

---
# 16.2 联机分析处理技术
联机分析处理是以海量数据为基础的复杂分析技术。联机分析处理支持各级管理决策人员从**不同的角度**，快速灵活地对数据仓库中的数据进行**复杂查询**和**多维分析处理**，辅助各级领导进行正确决策，提高企业的竞争力。
## 1. 多维数据模型
==多维数据模型是数据分析时用户的数据视图，是**面向分析的数据模型**，用于给分析人员提供多种观察的视角和面向分析的操作==。

多维数据模型的数据结构可以用一个**多维数组**来表示：（维 $1$ ，维 $2$ ，...，维 $n$ ，度量值）。例如，下图所示的电器商品销售数据，是按时间、地区、电器商品种类，加上度量“销售额”组成的一个三维数组（地区，时间，电器商品种类，销售额）。三维数组可以用一个立方体来直观地表示。一般地，多维数组用多维立方体 `CUBE` 来表示，也称为**超立方体**。
![在这里插入图片描述](https://img-blog.csdnimg.cn/88e2acbf65464fc5a946c5424f160772.png)

## 2. 多维分析操作
常用的联机分析处理·多维分析操作有**切片** `slice` 、**切块** `dice` 、**旋转** `pivot` 、**向上综合** `roll-up` 、**向下钻取** `drill-down` 等。通过这些操作，用户能从多角度和多侧面观察数据、剖析数据，从而深入地了解包含在数据中的信息与内涵。

## 3. 联机分析处理的实现方式
联机分析处理服务器透明地为分析软件和用户提供多维数据视图，实现对多维数据的存储、索引、查询和优化等功能。一般来说，按照多维数据模型的不同实现方式，联机分析处理服务器分为**MOLAP结构**、**ROLAP结构**、**HOLAP结构**等多种结构。
- **MOLAP结构**直接以多维立方体来组织数据，以多维数组来存储数据，支持直接对多维数据的各种操作。人们也常常称这种「按照多维立方体来组织和存储的数据结构」为**多维数据库** `Multi-Dimension DataBase, MDDB` 。
- **ROLAP结构**用关系DBMS或扩展的关系DBMS来管理多维数据，用关系表来组织和存储多维数据，同时，它将多维立方体上的操作映射为标准的关系操作。ROLAP将多维立方体结构划分为两类表，一类是**事实表** `fact table` ，另一类是**维表**。事实表用来描述和存储多维立方体的度量值、各个维的码值，维表用来描述维信息。==ROLAP用关系数据库的二维表来表示事实表和维表，即ROLAP用“星型模式”和“雪片模式”来表示多维数据模型==。
**星型模式** `star schema` 通常由一个中心表（或事实表）和一组维表组成，如下图所示，星型模式的中心是销售事实表，其周围的维表有时间维度、顾客维度、销售员维表、制造商维表和产品维表。事实表一般很大，维表一般较小。
将星型模式中的维表按层次进一步细化，就形成了**雪片模式**。对于上图的星型模式，顾客维表可以按所在位置分类聚集；时间维表则可以有两类层次——日、月或日、星期；制造商维表可以按工厂、工厂所在地区分层等。如下图所示，在星型维表的角上又出现了分支，这样变形的星型模式就是**雪片模式** `snow flake schema` 。
![在这里插入图片描述](https://img-blog.csdnimg.cn/4a113cb05a5644789752ac570874e942.png)

- **HOLAP结构** `Hybrid OLAP` 则是MOLAP和ROLAP的混合结构。

联机分析处理软件提供的是多维分析和辅助决策功能，对于深层次的分析和发现数据中隐含的规律与知识，则需要**数据挖掘** `Data Mining, DM` 技术和相应的数据挖掘软件来完成。

---
# 16.3 数据挖掘技术
面对日益激烈的市场竞争，客户对数据库系统迅速应答各种业务问题的能力的要求不断提高，不仅要求回答发生了什么、为何发生，还要回答将发生什么。数据挖掘技术正好支持回答“将发生什么”这类业务问题。

## 1. 数据挖掘的概念
==数据挖掘是从大量数据中**发现并提取**隐藏在内、人们事先不知道的、但又可能有用的信息和知识的一种新技术==。它的目的是帮助决策者寻找「数据间潜在的关联」，发现经营者忽略的要素，而这些要素对预测趋势、决策行为也许是十分有用的信息。

数据挖掘技术涉及数据库、人工智能、机器学习、统计分析等多种技术，它使**决策支持系统** `Decision Support System, DSS` 跨入了一个新阶段。数据挖掘技术从一开始就是面向应用的，尤其是在银行、典型、保险、交通、零售（如超级市场）等商业领域，有着极其广泛的应用前景。
## 2. 数据挖掘和传统分析方法的区别
传统的决策支持系统，通常是在某个假设的前提下，通过数据查询和分析来验证或否定这个假设。数据挖掘和传统数据分析（如查询、报表、联机应用分析）的本质区别是，==数据挖掘是在没有明确假设的前提下去挖掘信息、发现知识==。

数据挖掘技术是基于大量的、来自实际应用的数据，进行自动分析、归纳推理，从中发掘出数据间潜在的模式或产生联想，建立新的业务模型以帮助决策者调整企业发展策略。

数据挖掘所得到的信息应具有**事先未知、有效**和**可实用**三个特征。事先未知的信息是指该信息是未曾预料到的，即数据挖掘是要发现那些不能靠直觉发现的信息或知识，甚至是违背直觉的信息或知识。挖掘出的信息越是出乎意料，就可能越有价值。例如，一个典型商业应用示例是，一家连锁店通过数据挖掘发现，小孩尿布和啤酒之间的销售模式有着惊人的联系。

## 3. 数据挖掘的数据源
==数据挖掘的数据主要有两种来源，即数据可以是从数据仓库中来的，也可以是直接从数据库中来的==。这些实际的应用数据往往是不完全的、有噪声的、模糊的、随机的，因此要根据不同的需求在挖掘之前进行预处理。

==从数据仓库中直接得到数据挖掘的数据，有许多好处==。因为数据仓库的数据已经过了预处理，许多数据不一致的问题都较好地解决了，在数据挖掘时大大减少了清洗数据的工作量。

当然，也不是非得为了数据挖掘建立一个数据仓库，它不是必需的。建立一个巨大的数据仓库，要把各个不同源的数据集成在一起，解决所有的数据冲突问题，然后把所有的数据导到一个数据仓库内，这是一项巨大的工程，可能要用几年的时间、花上百万经费才能完成。==如果只是为了挖掘数据，可以把一个或几个联机分析处理数据库导入到一个只读的数据库中，然后在上面进行数据挖掘==。

所有的数据还要再次进行选择，具体的选择方式与任务相关。**挖掘的结果需要进行评价才能最终成为有用的信息**，按照评价结果的不同，数据可能需要反馈到不同的阶段，重新进行分析计算。

## 4. 数据挖掘的功能
数据挖掘的功能主要有以下几种：
1. 概念描述。即归纳总结出数据的某些特征。
2. 关联分析。若两个或多个变量的取值之间存在某种规律性，就称为关联。关联包括**相关关联**和**因果关联**，关联规则不仅是**单维关联**，也可能是**多维关联**。
3. 分类和预测。即找到一定的函数或模型，描述和区分数据类之间的区别，用这些函数和模型预测未来。这些数据类是事先已经知道的。分类的结果表示为**决策树**、**分类规则**或**神经网络**。
4. 聚类。即将数据分为多个类，使得类内部数据之间的差异最小，而类之间数据的差异最大。==与分类不同的是，聚类前并不知道类的个数==。聚类技术主要包括**传统的模式识别方法**和**数学分类学**等。
5. 孤立点的检测。**孤立点**是指数据中的整体表现行为不一致的数据集合。这些数据虽然是一些特例，但往往在错误检查和特例分析中是很有用的。
6. 趋势和演变分析。即描述「行为随着时间变化的对象」所遵循的规律或趋势。

一个典型的数据挖掘系统的体系结构如下图所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/6f89b1826b7642fe90fb71106db1d252.png)

**在进行挖掘之前，首先要明确挖掘的任务**，比如说是要进行分类、聚类或寻找关联规则等；然后根据这些任务，预处理所选择的数据，之后再选择具体的算法进行挖掘；最后，要评价挖掘出来的模式，削减其中重复的部分，将最终的结果展现出来。

---
# 16.4 大数据时代的新型数据仓库 
多年来，作为一种有效的**商务智能** `Business Intelligence, BI` 解决方案，数据仓库+联机分析处理+数据挖掘 `DW+OLAP+DM` 架构一直被众多企业所采用，支持企业决策。在大数据时代，由于系统面临的需求在数据量、数据类型、决策分析复杂度和硬件环境等方面，发生了质的变化，经典的 `DW+OLAP+DM` 架构已经无法胜任新的 `BI` 需求，必须对其进行适应性调整。

## 1. 系统需求的变化
和传统的数据仓库相比，大数据时代BI系统面临的需求发生了如下变化：
- **数据量急剧增长**。数据仓库中的数据量从TB级升到PB、ZB级，且仍在持续爆炸式增长。
- **数据类型多样**。除了结构化数据外，大数据时代的数据仓库还必须能够处理大量的半结构化、非结构化数据。包括文本、音频、视频、图片、文字、消息等。数据类型的多样化源于媒介类型的极大丰富。社交网站、在线视频、数码摄像、移动通信、电子商务、遥感卫星等，每天都在源源不断产生各种各样的数据。
- **决策分析复杂**。大数据时代，决策分析逐渐由常规分析转向深度分析 `deep analytics` 。数据分析日益成为企业利润必不可少的支撑点。根据 `The Data Warehousing Institute` 对大数据分析的报告，企业已经不满足于对现有数据的分析和监测，更期望能对未来趋势有更多的分析和预测，以增强企业竞争力。这些分析操作包括诸如**移动平均线分析**、**数据关联关系分析**、**回归分析**、**`what-if` 分析**等复杂统计分析，统称为**深度分析**。
- **底层硬件环境变化**。近年来，新硬件技术的发展使计算机处理能力得以提升，**多核处理器和众核处理器**提供了强大的并行处理能力，**大内存**提供了更大的存储能力，**高速网络**更好地优化了网络延迟。由于数据量的迅速增加，数据库/数据仓库的规模不得不随之增大，从而导致其成本的急剧上升。出于成本的考虑，越来越多的企业将应用（数据处理平台），由高端服务器转向了**由中低端硬件构成的大规模机群平台**。

## 2. 传统数据仓库面临的问题
通过上面的论述可以发现，在大数据时代，系统的需求已经发生了根本性的改变。如果继续沿用图16.2所示的抽取+离线存储+分析的分层计算模式，会存在如下问题：
1. **数据移动代价过高**。图16.2所示的数据仓库系统的体系结构中，在数据源层和分析层之间，引入了一个存储管理层，虽然可以提升数据质量并针对查询进行优化，但也付出了较大的**数据迁移代价、执行时的连接代价**——数据首先通过复杂且耗时的ETL过程，存储到数据仓库中；在联机分析处理服务器中，又转换为星型模式或雪片模式；执行分析时，又通过连接方式，将数据从数据库中取出。这些代价在TB级数据量时，也许可以接受，但面对大数据，其执行时间至少会增长几个数量级。更为重要的是，对于大量的即席分析，这种数据移动的计算模式是不可取的。
2. **不能快速适应变化**。传统的数据仓库假设主题是较少变化的，其应对变化的方式是「对数据源到前端展现的整个流程中的每个部分进行修改」，然后再重新加载数据，甚至重新计算数据，导致其适应变化的周期较长。这种模式比较适合**对数据质量和查询性能要求较高，而不太计较预处理代价**的场合。但在大数据时代，分析处在变化的业务环境中，这种模式将难以适应新的需求。
因此，==在大数据时代，海量数据与系统的数据处理能力之间存在鸿沟==：一边是至少PB级的数据量，另一边是面向传统数据分析能力设计的数据仓库和各种商务智能工具。==如果这些系统或工具发展缓慢，这个鸿沟将会随着数据量的持续爆炸式增长而逐步拉大==。虽然传统数据仓库可以舍弃不重要数据，或者建立数据集市来缓解此问题，但也只是权宜之计，并非系统级解决方案；且舍弃的数据在未来可能会重新使用，以发掘更大的价值。

## 3. 大数据时代的新型数据仓库
为了应对大数据时代系统在数据量、数据类型、决策分析复杂度、底层硬件环境等变化，**以较低的成本高效地支持大数据分析**，新型的数据仓库解决方案需具备下表所示的几个重要特性。
![在这里插入图片描述](https://img-blog.csdnimg.cn/5781439da7c94180a30e062742e1563a.png)

满足上述特性的数据仓库解决方案，可以有多种形式，每一种方案都有其优缺点，但基本思想都是「**将传统的结构化数据处理和新型的大数据处理，集成到一个统一的异构平台中**」，即共存的策略。

大数据时代，一种典型的新型数据仓库体系结构如下图所示。其中，Hadoop或NoSQL等大数据处理平台，和现有的基于关系DBMS的数据仓库平台，通过连接器软件组合在一起，两个平台之间的数据通过**连接器**进行交换——连接器发挥着类似于Java数据库连接 `Java DataBase Connector, JDBC` 的作用。
![在这里插入图片描述](https://img-blog.csdnimg.cn/cebb47a6aaf94346961961f59b53d4f7.png)

目前，大部分关系数据库、商务智能工具、NoSQL等软件开发商，都提供了自己开发的Hadoop和NoSQL连接器。由于其所处的特殊位置，连接器的性能（主要是传输数据的带宽）也经常会成为系统的瓶颈。

# 总结
==数据仓库 `DW` 、联机分析处理 `OLAP` 和数据挖掘 `DM`  是作为三种**独立的**信息处理技术出现的，数据仓库用于数据的存储和组织，OLAP集中于数据的分析，数据挖掘则致力于知识的自动发现==。它们都可以**分别应用到**信息系统的设计和实现中，提高相应部分的处理能力。然而，==由于这三种技术内在的联系性和互补性，将它们结合起来，就成为一种新的**决策支持系统架构**==，成为BI的三个支柱。这一架构以数据库中的大量数据为基础，具有如下特点：
1. **在底层的数据库中，保存了大量的事务级细节数据**。这些数据是整个决策支持系统的数据来源。
2. **数据仓库**对底层数据库中的事务级数据进行集成、转换、综合、重新组织成面向全局的数据视图，**为决策支持系统提供数据存储和组织的基础**。
3. **联机分析处理从数据仓库中的集成数据出发，构建面向分析的多维数据模型，再使用多维分析方法，从多个不同的视角，对多维数据进行分析比较**。分析活动从以前的方法驱动，转向了数据驱动，分析方法和数据结构实现了分离。
4. **数据挖掘以数据仓库和数据库中的大量数据为基础，自动发现数据中的潜在模式，并以这些模式为基础，自动地进行预测分析**。数据挖掘表明，知识就隐藏在日常积累下来的大量数据之中，仅靠复杂的算法和推理，并不能发现知识，数据才是知识的源泉（？）。

大数据时代，系统面临的需求在数据量、数据类型、决策分析复杂度、底层硬件环境等发生巨大变化，**为了应对这些变化，新型数据仓库通常采用共存策略，将传统的结构化数据处理和新型的大数据处理集成到一个统一的异构平台中**。

