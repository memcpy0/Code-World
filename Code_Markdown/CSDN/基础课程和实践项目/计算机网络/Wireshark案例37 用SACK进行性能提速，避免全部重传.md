每当我要写一个真实的 Wireshark 案例时，感觉就像在自我表扬。这实在不符合阿满低调的个性，但是没办法，谁让 Wireshark 这么神奇呢？不久前我处理的一个 Data Domain 项目，便是极好的例子。

我之前对 Data Domain 的了解并不多，只知道是普林斯顿大学一位华人教授的发明，后来被我司收购了。所以当项目经理打我电话时，也是听得一头雾水。大概了解到的症状是多台 AIX 同时往 Data Domain 读写数据（如图 1 所示）。写的时候性能都很好，能超过 90MB/s；但读的时候性能却很差，在 20MB/s 以下。驻场的团队已经耗在上面好几天了，却一直没有进展，留给我的时间已经不多了。
图 1
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131647963.png)
鉴于项目的紧迫性，我挂了电话便立即出发。还好这个客户的数据中心在上
海郊区，我得以在路上仔细分析。
1. 一般存储设备都是读比写快，Data Domain 应该也不例外。目前的现象是读比写慢得多，所以根本原因应该不在 Data Domain 本身。
2. 网络很值得怀疑。一般存储端的带宽大，客户端的带宽小。==读文件时数据从大带宽进入小带宽，就如同大河水流入小河，有可能会溢出==（表现在网络上就是拥塞）==而导致性能问题。写文件时方向相反，所以拥塞概率低==，性能就会好一些，正好符合这个案例的症状。
3. 只要在两端各抓一个网络包，就能证实我的猜测。

好不容易等到客户收集好网络包，用 Wireshark 打开一看，果然发现了好多重传（如图 2 所示）。重传对性能的影响是极大的，即便是 0.5%的比例也会使性能大幅度下降。
图 2
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131649710.png)
我随机看了几个重传包，发现方向都是从 Data Domain 到 AIX 的。说明这些包从 Data Domain 出来之后，在路上丢失了，最终没有到达 AIX。Data Domain
因为一直没有等到 AIX 的确认包，所以只能选择重传。

这就意味着我之前在路上的推测是正确的，**网络上存在瓶颈**。客户也确认 AIX
端的带宽只有存储端的 1/10，是可能有问题。不过由于网络项目已经实施完毕，
无法变动，所以只能从 Data Domain 和 AIX 上想办法。

明明知道问题发生在网络上，却要到存储端和客户端上去想办法，是不是有点头痛医脚的感觉？但这的确是可行的，我至少能想到三个方案。
- 方案 1. **把 Data Domain 的发送窗口强制成较小的值**，这样每次发出去的数据量就少一些，拥塞的概率也减小了。就像大河里流的水量很少，即便流入小河也不会漫出来一样。发得慢当然对性能有影响，但由于避免了丢包，所以总性能反而有所提升。该方案的缺点是**限制了 Data Domain 给所有网络设备发送数据的速度，不仅是针对 AIX**。
- 方案 2. **把 AIX 的接收窗口强制成较小的值**。这样 Data Domain 给 AIX 传数据时的发送窗口就被限制了，而且给其他客户端发数据时不受影响。但该方案的缺点是**限制了 AIX 从所有网络设备接收数据的速度，不只是针对 Data Domain**。
  以上两个方案都需要选定一个较小的窗口值，这个值要怎么算出来呢？图 3是一个丢包的例子，发送方一口气发出 6 个包，但其中最后一个丢失了，最后导致了超时重传。
  图 3
  ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131650166.png)
    从图 3 中可以估算出丢包时的拥塞点大约为前 5 个包所携带的字节数。只要按这个方法随机找出多个拥塞点，就大概能选定合适的窗口值了。
- 方案 3．图 2 中的 Wireshark 截图显示重传的包为 5190、5192、5194……5230（20 个），而且这些重传包都是连续的（图 4 显示了其中的一部分）。
    图 4
    ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131650309.png)
    但==当我检查接收方的网络包时，发现其实只有 5190 的原始包是真正丢失了，其他的包都到达了接收方，所以没必要重传==。那为什么发送方要重传这么多呢？这是因为==发送方发现 5190 的原始包丢失后，无法确定后续的其他包是否也丢了，只好选择全部重传==。而==接收方虽然知道丢了哪些包，却没有任何机制可以告知发送方==。这个问题其实在 1996 年的 RFC 2018 中就已经给出了解决方案，它就是 Selective Acknowledgment，简称 SACK。**在接收方和发送方都启用 SACK 的情况下，接受方可以告诉发送方“我没收到的只是 5190 的原始包，但是我收到了其他的**。”因此发送方只需重传 5190 即可。在启用了 SACK 的网络包中，我们能在Dup Ack 包里看到这些信息。图 5 是在一个启用 SACK 的环境中抓的包，最底部就是 SACK 信息。
    图 5
    ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131652658.png)
    把图 5 中的“Ack=991851”和“SACK=992461-996175”两个信息综合起来，发送方就知道 991851～992460 的包没有收到，而后面的 992461～996175 的包反而已经收到了。

因为本案例中存在大量不必要的重传，而且 Dup Ack 包中也没有 SACK 信息，已经足以说明 SACK 没有启用。我决定先不限制发送窗口，把 SACK 打开再说。是否启用 SACK 是在 TCP 三次握手时协商决定的，如图 6 中方框内的参数所示。**只要双方中有一方没有发“SACK_PERM=1”，那该连接建立之后就不会用到 SACK**。
图 6
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131653384.png)

我们分别检查了 DataDomain 和 AIX，果然发现 AIX 上默认关闭了 SACK。于是客户在 AIX 上运行了“no -p -o sack=1”命令，读性能立即就飙升到 90MB/s以上，远远超过项目需求。有了这个结果，我也不考虑方案 1 和方案 2 了，毕竟都有副作用。
