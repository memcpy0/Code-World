前文介绍过一个文件共享协议，即 Sun 设计的 NFS。理论上 **NFS 可以应用在
任何操作系统上**，但因为历史原因，**现实中只在 Linux/UNIX 上流行**。那 Windows 上一般使用什么共享协议呢？它就是微软维护的SMB协议，也叫Common Internet File System（CIFS）。CIFS 协议有三个版本：SMB、SMB2 和 SMB3，目前 SMB 和 SMB2 比较普遍。
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131136510.png)
在 Windows 上创建 CIFS 共享非常简单，只要在一个目录上右键单击，在弹
出的菜单中**选择属性-->共享，再配置一下权限就可以了**。如图 1 所示，在其他电脑上只要输入 IP 和共享名就可以访问它了。
图 1
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131136689.png)
我在读大学时，曾把整个 D 盘共享出来，几天后就有雷锋在里面放了几部小电影。**CIFS 在企业环境中应用非常广泛，比如映射网络盘或者共享打印机**；同事间共享资料也可以采用这种方式。由于使用 CIFS 的用户实在太多，微软的技术支持部门每天都会收到很多关于 CIFS 问题的咨询（我读大学时曾在那里兼职过一年）。

要想成为 CIFS 方面的专家，就必须了解它的工作方式。比如在我的实验室
中，客户端 10.32.200.43 打开共享文件 `\\10.32.106.72\dest\abc.txt` 时，底层究竟发生了什么？借助 Wireshark，我们可以把这个过程看得清清楚楚。

**首先，CIFS 只能基于 TCP，所以必定是以三次握手开始的**。从图 2 可见，
CIFS 服务器上的端口号为 445。
图 2
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131342249.png)
接下来的第一个 CIFS 操作是 Negotiate（协商）。协商些什么呢？请关注图 3
的底部，可见客户端把自己支持的所有 CIFS 版本，比如 SMB2 和 NT LM 0.12（为了便于和 SMB2 对比，接下来我们称它为 SMB）等都发给服务器。
图 3
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131342338.png)
服务器从中挑出自己所支持的最高版本回复给客户端。从图 4 中可知，服务器选择的是 NT LM 0.12（SMB），这说明了该服务器不支持 SMB2。
图 4
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131343983.png)
理解了协商过程就可以处理 CIFS 版本相关的问题了。比如我接到过新加坡
某银行的咨询，他们想知道如何让客户端 A 和服务器 C 之间用 SMB2 通信，而客户端 B 和服务器 C 之间用 SMB 通信。我的建议是==在 A 和 C 上都启用 SMB2，而在 B 上只启用 SMB，这样就能协商出想要的结果==。协商好版本之后，就可以建立 CIFS Session 了，如图 5 所示。
图 5
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131344557.png)
Session Setup 的主要任务是身份验证，常用的方式有 Kerberos 和 NTLM（本
例就是用到 NTLM）。这两种方式都**非常复杂且有趣**，我会另写一篇文章专门介绍。

假如有用户抱怨访问不了 CIFS 服务器，问题很可能就发生在 Session Setup。
Session Setup 过后，意味着已经打开 `\\10.32.106.72` 了。接下来要做的是打开
`\dest` 共享。如图 6 所示，这个操作称为 Tree Connect。
图 6
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131345279.png)

点开这两个 Tree Connect 包，**最有价值的信息当属服务器返回的 Tree ID**（如图 6 底部所示）。**从此之后客户端就能利用这个 ID 去访问/dest 共享的子目录和子文件**。这一步看似简单，但初学者也会有一些疑问。
> 常见问题 1：如果用户无权访问此目录，会不会在 Tree Connect 这一步失败？答案：不会。Tree Connect 并不检查权限，所以即便是无权访问的用户也能得到 Tree ID。检查权限的工作由接下来的 Create 操作完成。

> 常见问题 2：某用户已经打开了 `\\10.32.106.72\dest\abc.txt` ，如果还想再打开 `\\10.32.106.72\source\abc.txt` ，需要再建一个 TCP 连接吗？
> 答案：没有必要，在一个 TCP 连接上能维持多个打开的 Tree Connect。

过了 Tree Connect 是不是该开始读 abc.txt 了？其实还差很多步骤，**接下来客
户端还要在服务器上查询很多信息**。看了图 7 你就能理解为什么人们都嫌 CIFS
协议啰嗦了。
图 7
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131427836.png)
其实从 13 号到 68 号包都是类似图 7 所示的网络包，图 7 只显示了一小部
分，我不想把所有内容都贴出来浪费纸张。**这些包查询了文件的基本属性、标准属性、扩展属性，还有文件系统的信息等**。幸好 SMB2 对此有所改进。
再多的属性也有查完的时候，到了 69 号包终于看到 Create Request \abc.txt 了
（见图 8）。
图 8
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131428651.png)
Create 是 CIFS 中非常重要的一个操作。**无论是新建文件、打开目录，还是读
写文件，都需要 Create**。有时候我们因为没有权限遭遇“Access Denied”错误，
或者覆盖文件时收到“File Already Exists”提醒，都是来自 Create 这个操作。经常有人会咨询的几个关于 Create 的问题如下所示。
> 常见问题 1：如果 `\dest` 的权限里禁止某用户访问，但 `\dest\abc.txt` 的权限里允许该用户访问，那他打开 `\\10.32.106.72\dest\abc.txt` 时会不会失败？
> 答案：如果该用户先打开 `\\10.32.106.72\dest` ，就会在“NT Create \dest”这一步收到 Access Denied 报错，当然就无法再进一步打开 abc.txt 了。而如果直接在地址栏输入 `\\10.32.106.72\dest\abc.txt` ，则可以跳过“NT Create \dest”这一步，所以不会有任何报错。也就是说**可以直接打开子文件 abc.txt，却打不开上级文件夹 \dest，这个结果可能是很多人意想不到的**。

> 常见问题 2：Windows 的 Backup Operators 组中的用户有权限备份所有文件，但不一定有权限读文件。那服务器是怎么知道一个用户是想备份还是想读的？
> 答案：**备份和读这两个行为的确非常相似**，都是依靠 Read 操作来完成的。它们的不同点在于，**备份时在 Create 请求中的“Backup Intent”设为 1，而读时“Backup Intent”设为 0**（如图 9 所示）。服务器就是依靠 Backup Intent 来决定是否允许访问的。
> 图 9
> ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131429517.png)

> 常见问题 3：如果多个用户一起访问相同文件，CIFS 如何处理冲突？
> 答案：在 Create 请求中有 Access Mask 和 Share Access Mask 两个选项。前者表示**该用户对此文件的访问方式**（读、写、删等），后者表示**该用户允许其他用户对此文件的访问方式**。举个例子，用户 A 发送的 Create 请求中，Access Mask 是 “读+写”，Share Access Mask 是“读”，表示自己要读和写，并同时允许其他人只读。假如接下来用户 B 也发送 Access Mask 为“读+写”的 Create 请求，就会收到“Sharing Violation”错误，因为 A 不允许其他人写。图 10 中的 Access Mask 只是读。
> 图 10
> ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131430225.png)
> 注意：这里讨论的访问冲突指的是 CIFS 协议层的。有些应用软件还有专门的机制防止访问冲突，比如 Word 和 Excel，但 Notepad 就没有。

> 常见问题 4：CIFS 如何保证缓存数据的一致性？
> 答案：**客户端可以暂时把文件缓存在本地**，等用完之后再同步回服务器端。 这是提高性能的好办法，就像我们写论文时，都喜欢把图书馆的资料借回来，以备随时查阅。假如不这样做，就得频繁地跑图书馆查资料，时间都浪费在路上了。
> ==当只有一个用户在访问某文件时，在客户端缓存该文件是安全的==，但在有多个用户访问同一文件的情况下则可能出现问题。**CIFS 采用了 Oplock（机会锁）来解决这个问题**。Oplock 有 Exclusive、Batch 和 Level 2 三种形式。Exclusive 允许读写缓存，Batch 允许所有操作的缓存，而 Level 2 只允许读缓存。Oplock 也是在Create 中实现的，如图 11 底部所示，该客户端被授予 Batch 级别的机会锁，表示他可以缓存所有操作。
> 图 11 
> ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131432876.png)

为了更好地理解 Oplock 的工作方式，我们假设一个场景来说明。
1．用户 A 用 Exclusive/Batch 锁打开某文件，然后缓存了很多修改的文件内容。
2．用户 B 想读同一个文件，所以发了 Create 请求给服务器。
3．如果此时服务器忽视 A 的 Oplock，直接回复 B 的请求，那 B 就读不到被A 修改后的内容（也就是出现数据不一致）。因此**服务器通知 A 释放 Exclusive/Batch 锁，换成 Level 2 锁**。
4．**A 立即把缓存里的修改量同步到服务器上**。
5．服务器给 B 回复 Create 响应，同时授予其 Level 2 锁。**B 接下来再发读请
求，从而得到 A 修改后的文件内容**。

到了 Create 这一步，距离 TCP 连接的建立已经过去 0.093 秒。虽然听上去很短，但在局域网中已经算是很长一段时间了。这段时间足够我实验室的 NFS 服务器响应 45 个 64KB 的读操作，而本例中的读操作却刚要开始，可见 CIFS 协议有多啰嗦。这让我想起一个经典问题，“为什么复制一个 1MB 的文件比复制 1024个 1KB 的文件快很多，虽然它们的总大小是一样的？”原因就是**读写每个文件之
前要花费很多时间在琐碎的准备工作上**。一个 1MB 的文件只需要准备一次，而
1024 个 1KB 的文件却需要 1024 次。

从包号 71 开始，读操作终于出现了。如图 12 所示，CIFS 的读行为看上去和NFS 非常相似，都是从某个 offset 开始读一定数量的字节。文件的内容“I need a vacation!”能从包里直接看出，说明传输时没有加密。
图 12
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131434717.png)

**还有很多有趣的行为是从这两个包里看不出来的，必须设计一些实验才能归纳出来**。比如下面几个常见问题，可能会感兴趣。
- 常见问题 1：同样是用 SMB 协议读一个文件，Windows XP 和 Windows 7的表现有何不同？
  答案：通常一个新的操作系统发布时，微软都会罗列它的种种好处，但大家基本上听听就过去了，没有人会去较真。我仔细对比了 Windows XP 和 Windows 7 的读行为之后，发现 Windows 7 的确有所改进。Windows XP 发了一个读请求之后就会停下来等回复，收到回复后再发下一个读请求。而 **Windows 7 则可以一口气发出多个读请求，就像 NFS 一样**。下面是在这两种操作系统上读同一个文件的过程，两者的差别在 Wireshark 中一目了然。
    Windows XP 的 Request 和 Response 是交替的（见图 13）：
    图 13
    ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131435017.png)
    Windows 7 的 Requests 是多个一起发出的（见图 14）： 
    图 14
    ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131435980.png)

这两种读方式在延迟小的网络中体现不出差别，**在带宽小的环境中差别也不大**
（因为发送窗口小，一个读请求本来就要多个往返才能传完）。**但在高延迟、大带宽的环境中就很不一样了**，Windows 7 的性能会比 Windows XP 好很多。在网络有丢包的情况下差别还会更大，因为 Windows XP 比 Windows 7 更容易碰到超时重传。

常见问题 2：利用 Windows Explorer 从 CIFS 共享上复制文件，为什么比
Robocopy 和 EMCopy 之类的工具慢很多？
答案：如果复制一个大文件可能是看不出差别的，但如果是复制一个包含大量
小文件的目录，的确是比这些工具慢很多。这是因为 **Windows Explorer 是逐个文件复制的（单线程），而这些工具能同时复制多个文件（多线程）**。比如上文提到的前0.093 秒里虽然交互多次，但占用带宽极少，多个文件并行操作的效率会高很多。下面两个图是 EMCopy 的单线程和双线程复制同一文件夹的结果，后者明显要快得多。
单线程的复制（见图 15）：
图 15
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131437187.png)
双线程的复制（见图 16）： 
图 16
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131438301.png)

常见问题 3：从 CIFS 共享里复制一个文件，然后粘贴到同一个目录里，为什
么还不如粘贴到客户端的本地硬盘快？
答案：==前者需要把数据从服务器复制到客户端的内存里，然后再从客户端的内存写到服务器上，相当于读+写两个操作==。而后者只是从服务器读到客户端内存里，然后写到本地硬盘，相当于网络上只有读操作，这样就快了一些。图 17 是前者的网络包。
图 17
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131438583.png)
SMB3 对此有了本质上的改进，**可以完全实现服务器端的本地复制**，这样前者反而比后者快了。

常见问题４：在 CIFS 共享上剪切一个文件，然后粘贴到同一共享的子目录
里，为什么就比粘贴到本地硬盘快呢？
答案：**在相同的文件系统上剪切、粘贴，本质上只有“rename”操作，并没
有读和写，所以是非常快的**。请看图 18 的抓包，该操作是把 abc.txt 剪切到一个叫 `\test` 的子目录。
图 18 
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131441659.png)
常见问题 5：为什么在 Windows 7 上启用 SMB2 之后，读性能提高了很多？
答案：这是因为 SMB2 没有 SMB 那么啰嗦。从图 19 可见，读之前的查询用
了不到 10 个包，而 SMB 往往要用数十个包来查询各种信息。
图 19
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131442294.png)

---
# NFS与CIFS的比较
作为技术人员，我们能看到的明争暗斗比其他人更多，甚至能从协议细节中看到高手过招的痕迹。比如说 Windows 和 Linux 之争，也能体现在它们的共享协议 CIFS 和 NFS 上。之前已经分别解析过它们的工作方式，这里再来探讨它们的历史和发展趋势。

早期 CIFS 协议的设计比 NFS 落后不少，甚至可以看到一些“不专业”的痕迹。我个人意见最大的有两点。
- **早期 CIFS 协议非常啰嗦**，这一点在前面的《剖析 CIFS 协议》一文中已有详解。比如打开一个文件之前竟然需要 50 多个包的来回，部分网络包如图１所示。
  图 1
  ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131449341.png)
- **早期 CIFS 协议的读写操作都是同步方式的**。如图２所示，它只会在收到上一个读响应（Read AndX Response）之后，才发出下一个读请求（Read AndX Request）。这种方式的带宽利用率很低，因为很可能 TCP 发送窗口还没有用完，一个操作就完成了。CIFS 的设计人员当时可能没有考虑到网络带宽的快速发展。
    图 2
    ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131450109.png)
    早期的 NFS 上就没有这个问题，如图 3 所示，多个读请求被一起发出去了（也可以说是异步的）。
    图 3
    ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131451207.png)
    幸好 CIFS 很快就向 NFS 学习，等到 Windows 7 出来的时候，这两个问题都解决了。
- 当然早期的 NFS 协议也有落后的地方，比如对文件属性的管理过于简单。但到了 NFSv4 面世的时候，也已经和 CIFS 趋同了。这些江湖暗斗只有专业人士才能感觉到。

竞争往往能激发意想不到的创造力，这两个协议的新特性就是如此产生的。无论是早期的 CIFS 还是 NFS，每个操作都是在各自的网络包中完成的。==即便不太罗嗦的 NFS 协议在读一个文件之前，也需要通过 READDIRPLUS 操作获得其File Handle（FH），再通过 GETATTR 操作获得该 File Handle 的属性，最后通过ACCESS 和 READ 操作打开文件==。图 4 显示了 READ 之前的三个操作至少花费了三个 RTT（往返时间）。
图 4
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131453592.png)
相比起 CIFS，这已经可以算是极简主义了。不过 NFSv4 中又提出了一个全
新的理念，称为“COMPUND CALL”（复合请求）。==客户端可以把多个请求放在一个包中发给服务器，然后服务器也在一个包中集中回复，这样就能在一个往返时间里完成多项操作了==。

道理听起来似乎很简单，但真正做起来并不容易。以图 4 中的 READDIRPLUS +
GETATTR + ACCESS + READ 为例，如果用 COMPUND 方式，发送方在没有收到 READDIRPLUS 回复之前，怎么知道 GETATTR 操作应该指定什么 File Handle 呢？NFSv4 用了类似编程时用到的“变量”思维来实现，首先是 **READDIRPLUS操作所得到的 File Handle 被作为变量**传给 GETATTR 请求；接着 **GETATTR 操作得到的文件属性**又传给 ACCESS 和 READ。==变量的传递完全发生在服务器端，所以客户端不需要参与，也就没有来回发包的需要==。

图 5 是一个包含了 7 个操作请求的 NFSv4 包，COMPUND 方式对效率的提高
幅度由此可见一斑。我认为这个思路值得很多应用层协议参考。
图 5
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131455870.png)
说完 NFS 的最新进展，我们再回头看看 CIFS 已经发展成什么样了。虽说现
在的微软已经没有当年风光了，==但在对 CIFS 协议的改进上，绝对称得上亮丽
的一笔，在我看来已经远远把 NFS 抛到脑后了==。在 Windows 8 和 Windows 2012 所支持的最新 CIFS 版本 SMB3 上，**出现了很多适应当前需求的革命性创新**。

不知道是否记得《剖析 CIFS 协议》一文中提到的“常见问题 3”及其答案？当我通过 CIFS 复制 abc.txt，然后粘贴到同一目录生成 abc-Copy.txt 时，网络包如图 6 所示。
图 6
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131456861.png)
这说明复制粘贴过程实际是这样的。
1．客户端发送读请求给服务器。
2．服务器把文件内容回复给客户端（这些文件内容被暂时存在客户端内存中）。
3．客户端把内存中的文件内容写到服务器上的新文件 abc-Copy.txt 中。
4．服务器确认写操作完成。

在这个过程中，文件内容通过第 2 步和第 3 步在网络上来回跑了两次，是很
浪费带宽资源的。为此 **SMB3 设计了一个叫“Offload Data Transfer”的功能，能够把过程变成这样**。
1．客户端向服务器发送复制请求。
2．服务器给了客户端一张 token。
3．客户端利用这张 token 给服务器发写请求。
4．服务器按要求写新文件。
5．服务器告诉客户端复制已经完成。
 
图 7 显示了这两种复制方式的差别，实心箭头表示文件内容的流向。
图 7
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131456967.png)
可见在 SMB3 的复制过程中，我们只是在网络上传输了一些指令，而文件内容并
没有出现在网络上，因为**复制数据完全由服务器自己完成了**。假如是复制一个大文件，**那对性能的提升幅度是非常可观的**，你甚至可以在数秒钟里复制几个 GB 的数据，远超网络的瓶颈。在虚拟化的应用场合中，**通过这个机制克隆一台虚拟机也可以变得很快**。

**SMB3 的另一个破天荒改进是在 CIFS 层实现了负载均衡**。与其他 CIFS 版本不同，一个 SMB3 Session 可以基于多个 TCP 连接。如图 8 所示，Windows 8 服务器上的
两个网卡，可以分别和文件服务器上的两个网卡建立 TCP 连接，然后一个 SMB3
Session 就基于这两个连接之上。当其中一个 TCP 连接出现故障，比如网卡坏掉
时，SMB3 连接还可以继续存在。
图 8
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131457027.png)

考虑到现在全球化的大公司越来越多，有了很多总部和分部，所以远距离的文件
传输就成了大问题。比如说，中国总部的机房中存在一个大文件，从澳大利亚分部访问该文件是非常慢的。尤其是当分部中有很多用户需要访问同一个文件时，相同的内容就需要在有限的带宽中传输多次。**SMB3 提出了一个叫 BranchCache 的机制来解决这个问题**。当澳大利亚分部的第一个用户访问该文件时，文件从中国传输过去，然后就被缓存起来（比如存到分部的专用服务器上）。接下来澳大利亚分部如果有其他用户访问该文件，就可以通过文件签名从缓存服务器上找到了。

这个机制听上去有点“脑洞大开”的意思，不过我在实验室中实施过这个功
能，用户体验还是非常好的，当然也增加了实施和购买专用服务器的开支。

最后不得不提的是 **SMB3 的一个“Continuous Availability”特性**。以前很多
厂商的文件服务器号称支持 Active/Standby（当前待机）模式，即文件服务器的两个机头共享硬盘，当一个机头宕机时，能即时切换到待机的机头上。“即时”这个词实际上是有虚假宣传嫌疑的，因为 SMB3 之前的 CIFS 版本把文件锁之类的信息放在机头的内存中，新的机头起来时无法获得这些信息，所以是没办法无缝地提供访问的，必须让客户端重新访问一次。

SMB3 对此的解决方案是把文件锁之类的信息存到硬盘上，所以新机头起来
时便可以获得这些信息，这样，提供无缝服务就成了一种可能。为了方便理解，
我也做了一个示意图，如图 9 所示。
图 9
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131458709.png)
1．Windows 8 客户端通过机头 1 访问文件，生成的文件锁等信息被保存
在硬盘中。
2．机头 1 发生故障，切换到机头 2 上，机头 2 从硬盘中获取信息。
3．Windows 8 仍然能锁定该文件，因为机头 2 继承了机头 1 的信息。