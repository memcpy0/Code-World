能否解释一下 Westwood 和Vegas 等 TCP 算法的差别？这个问题让我颇感意外。真是士别三日，当刮目相看，假如新工作是设计一个网络平台，那还是很有必要知道这些知识的，因为**不同的场景适合不同的 TCP 算法**。而要了解这些算法，就得从 **TCP 最原始的设计开始讲起**。

最早系统性地阐述了慢启动、拥塞避免和快速重传等算法的并非 RFC，而是 1993 年年底出版的奇书《TCP/IP Illustrated, Volume 1: The Protocols》，作者是我以前提到过的一位教父级人物——Richard Stevens。直到 1997 年，这本书中的内容才被复制到了 RFC 2001 中。**我第一次读到这些算法时拍案叫绝，完全不知道还有优化之处**。比如书中介绍了一个叫“临界窗口值”的概念，==当拥塞窗口处于临界窗口值以下时，就用增速较快的慢启动算法；当拥塞窗口升到临界窗口值以上时，则改用增速较慢的拥塞避免算法==。从图 1 可见，临界窗口前后的斜率有明显的变化。这个机制有利于拥塞窗口在最短时间到达高位，然后保持尽可能长的时间才触碰拥塞点，思路还是很科学的。
图 1
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131113842.png)
那临界窗口应该如何取值才合理呢？我能想到的，就是**在带宽大的环境中取
得大一些，在带宽小的环境中取得小一些**。RFC 2001 也是这样建议的，它把临
界窗口值定义为发生丢包时拥塞窗口的一半大小。我们可以想象==在带宽大的环
境中，发生丢包时的拥塞窗口往往也比较大，所以临界窗口值自然会随之加大==。可以用下面的例子来加以说明。

在拥塞窗口为 16 个 MSS 时发生了丢包，而图 3 在拥塞窗口为 8 个 MSS时就丢包了，说明当时图 2 中的带宽很可能比图 3 中的大。根据 RFC 2001，我们希望接下来图 2 的拥塞窗口能快速恢复到临界窗口值 16/2=8 个 MSS，然后再缓慢增加；也希望图 3 中的拥塞窗口能快速恢复到临界窗口值 8/2=4 个 MSS，然后再缓慢增加。这样做的结果就是图 2 的拥塞窗口比图 3 的增长得更快，更配得起它的带宽。以上这些分析，看上去很有道理吧？
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131114371.png)
有些聪明人就不认同以上分析。比如有一位叫 Saverio Mascolo 的意大利人看
了这个算法之后，**觉得太简单粗暴了**。真实环境的丢包状况比上面的例子复杂得多，比如在相同大小的拥塞窗口中，有时候丢包的比例大，有时候丢包的比例小，**统一按照拥塞窗口的一半取值是不理想的**。我们可以看看下面这个例子。
 
图 4 和图 5 在发生丢包时的拥塞窗口都是 16 个 MSS，不过图 4 丢了 4 个包，
而图 5 丢了 12 个。如果按照 RFC 2001 的算法，两边的临界窗口值都应该被定义为 16/2=8 个 MSS。这显然是不合理的，因为图 4 丢了 4 个包，图 5 丢了 12 个，说明当时**图 4 的带宽很可能比图 5 的大，应该把临界窗口值设得比图 5 的大才对**。

归纳一下，理想的算法应该是==先推算出有多少包已经被送达接收方，从而更精确地估算发生拥塞时的带宽，最后再依据带宽来确定新的拥塞窗口==。那么如何知道
哪些包被送达了呢？熟悉TCP协议的读者应该想到了—**可以根据接收方回应的
Ack 来推算**。于是不安分的 Saverio 先生依据这个理论提出了 Westwood 算法（当然实施起来不是我说的这么简单），后来又升级为 Westwood+。
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131115230.png)
从设计理念就可以看出，==当丢包很轻微时，由于 Westwood 能估算出当时拥
塞并不严重，所以不会大幅度减小临界窗口值，传输速度也能得以保持==。在经常发生非拥塞性丢包的环境中（比如无线网络），Westwood 最能体现出其优势。目前关于 Westwood 的研究有很多，我甚至能找到不少中文论文，实际中也有应用，比如部分 Linux 版本就用到了它。我一向有“人肉”IT 界牛人的习惯，Saverio 先生当然也在列。不过当我打开他的主页时，发现都是意大利文，只好作罢。

这里要插播一个有趣的情况。RFC 2581 也同样改进了 RFC 2001 中关于临界窗口值的计算公式，**把原先“拥塞窗口的一半”改为 FlightSize 的一半**，其中
FlightSize 的定义是“The amount of data that has been sent but not yet acknowledged（已发送但未确认的数据量）。”如果根据这个定义，我们会惊奇地算出图 4 的临界窗口值为 4/2=2 MSS，而图 5 的临界窗口值为 12/2=6 MSS。这跟“图 4 应该大于图 5”的期望是完全相反的，难道 RFC 2581 有错误？这可是经过无数人检验过的著名文档。我曾经忐忑不安地把这个问题发给过几位国外同行，说“Could you confirm if there is any problem with my brain or RFC 2581?”幸好得到的答复大多认为我的大脑是正常的，他们也认为这个算法有问题。最后有一位大牛现身，说我们对 RFC 2581 的要求太高了，当初设计的时候根本没考虑这么多。**引进 FlightSize 只是为了得到一个安全的临界窗口值，而不是像 Westwood+一样追求比较理想的窗口**。

接下来我们说说 Vegas 算法。如果说 Westwood 只是对 TCP 进行了细节性的、
改良性的优化，**Vegas 则引入了一个全新的理念**。本书之前介绍过的所有算法，都是在丢包后才调节拥塞窗口的。==Vegas 却独辟蹊径，通过监控网络状态来调整发包速度，从而实现真正的“拥塞避免”==。它的理论依据也并不复杂：**当网络状况良好时，数据包的 RTT（往返时间）比较稳定**，这时候就可以增大拥塞窗口；当网络开始繁忙时，数据包开始排队，RTT 就会变大，这时候就需要减小拥塞窗口
了。该设计的最大优势在于，==在拥塞真正发生之前，发送方已经能通过 RTT 预测到，并且通过减缓发送速度来避免丢包的发生==。

与别的算法相比，Vegas 就像一位敏感、稳重、谦让的君子。我们可以想象当环境中所有发送方都使用 Vegas 时，总体传输情况是更稳定、更高效的，因为几乎没有丢包会发生。而**当环境中存在 Vegas 和其他算法时，使用 Vegas 的发送方可能是性能最差的**，因为它最早探测到网络繁忙，然后主动降低了自己的传输速度。这一让步可能就释放了网络的压力，从而避免其他发送方遭遇丢包。这个
情况有点像开车，如果路上每位司机的车品都很好，谦让守规矩，则整体交通状
况良好；而如果一位车品很好的司机跟一群车品很差的司机一起开车，则可能被
频繁加塞，最后成了开得最慢的一个。

除了本文提到的 Westwood 和 Vegas，还有很多有意思的 TCP 算法。比如
Windows 操作系统中用到的 Compound 算法就同时维持了两个拥塞窗口，其中一个类似 Vegas，另一个类似 RFC 2581，但真正起作用的是两者之和。所以**说Compound 走的是中庸之道，在保持谦让的前提下也不失进取**。在 Windows 7 上，默认情况下 Compound 算法是关闭的，我们可以**通过下面的命令来启用它**。
```java
netsh interface tcp set global congestionprovider=ctcp
```
启用之后如果觉得不合适，可以通过以下命令来关闭。
```java
netsh interface tcp set global congestionprovider=none
```
图 6 是在我的实验机上启用的过程。
图 6
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131122004.png)
Linux 操作系统则在不同的内核版本中使用不同的默认 TCP 算法，比如 Linux
kernels 2.6.18 用到了 BIC 算法，而 Linux kernels 2.6.19 则升级到了 CUBIC 算法。

后者比前者的行为保守一些，因为在网络状况非常糟糕的状况下，保守一点的性能反而更好。

在过去几十年里，虽然 TCP 从来没有遇到过对手，不过它自己已经演化出无
数分身，形成百家争鸣的局面。本文无法一一列举所有的算法，点到的也如蜻蜓
点水，假如你想为自己的网络平台选取其中一种，还需要多多研究。