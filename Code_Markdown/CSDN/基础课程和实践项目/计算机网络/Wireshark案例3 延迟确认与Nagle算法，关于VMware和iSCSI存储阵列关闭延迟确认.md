有位读者在VMware的知识库里找到一篇文章，觉得像他正在遭遇的一个性能问题，便转发给我确认。这篇文章大概讲了这样一件事。
-问题描述：某些iSCSI存储阵列**在出现网络拥塞时处理不当**，会严重影响VMware的读写性能。**这和它们的TCP实现方式有关**。
-解决方式：在VMware和存储阵列上关闭**延迟确认**（DelayedACK）

VMware和iSCSI存储阵列是什么？我在知识库里找到一个网络拓扑，看起来很简单，大概如图1所示。无需理解得很深，只要把iSCSI存储阵列当作一台服务器，再把VMware当作其客户端就行了，**两者通过以太网传输数据**。
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307071442456.png)
乍看，这个“问题描述”与“解决方式”简直风马牛不相及。**网络拥塞怎么能靠关闭延迟确认来解决**？不过出于对VMware的一贯信任，决定还是好好研究一下。

我们先要明白什么叫**延迟确认**，它可以用一个简单的例子来说明：**在上海的笔记本上启动Wireshark抓包，然后用Putty远程登录一台位于悉尼的服务器**。由图2可见，在上海发出一个SSH请求之后，经过149毫秒左右（即1号包和2号包之间的时间差）收到了悉尼的回复，这是正常的往返时间。**但是笔记本收到回复之后，却没有立即确认，而是延迟了200毫秒以上（即2号包和3号包之间的时间差）才确认**。
图2
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307071444054.png)
这个现象就是传说中的延迟确认，下面介绍。

发送窗口一般只影响大块的数据传输，比如读写大文件。而**频繁交互的小块
数据不太在乎发送窗口的大小，因为发包量本来就少**。日常生活中这样的场景很多，比如用 Putty 之类的 **SSH 客户端**连上一台 Linux 服务器，然后随便输入一些字符，在网络上就交互了很多小块数据了。当网络状况良好时，我们会感觉一输
入字符就立即显示出来。究其原因，**是因为每输入一个字符就被打成 TCP 包传到服务器上，然后服务器也随即进行回复**。假如把这个过程的包抓下来，会看到很多小包频繁来往于客户端和服务器之间。**这种方式其实是很低效的**，因为一个包的 TCP 头和 IP 头至少就 40 字节，而携带的数据却只有一个字符。==这就像快递员开着大货车去送一个小包裹一样浪费==。

我做了一个实验来研究这个现象。先在 Putty 上缓慢地输入 3 个字符“j”，每
次按键的间隔在 300 毫秒以上，这时候 Wireshark 抓到了前 9 个包。接着我快速
敲击键盘，Wireshark 又抓了后面的包，Wireshark 截屏如图 1 所示。
图 1
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131103835.png)
前 3 个包的解说如下。
客户端：“我想给你发个加密后的字符‘j’。”
服务器：“我收到字符‘j’了，你可以把它显示出来。”
客户端：“知道了。”
接下来的 4、5、6 号包，以及 7、8、9 号包也是一样的情况

我的客户端 10.32.200.43 放在上海，而服务器 10.32.23.55 位于悉尼，它们
之间的往返时间大概是 150 毫秒。由于这些包是在客户端收集的，所以 1 号包
和 2 号包相差 150 毫秒是正常现象。**奇怪的是客户端收到 2 号包之后，竟然等
待了大约 200 毫秒才发出 3 号包**。本来是 1 毫秒之内可以完成的事，为什么要
等这么久呢？再看看 5 号和 6 号之间，以及 8 号和 9 号之间，也是大概相差 200
毫秒。这其实就是 **TCP 处理交互式场景的策略之一，称为延迟确认**。该策略的原理是这样的：==如果收到一个包之后暂时没什么数据要发给对方，那就延迟一段时间（在 Windows 上默认为 200 毫秒）再确认==。假如在这段时间里恰好有数据要发送，**那确认信息和数据就可以在一个包里发出去了**。第 12 号包就恰好符合这个策略，客户端收到 11 号包之后，等了 41 毫秒左右时我又输入一个字符。结果这个字符和对 11 号包的确认信息就一起装在 12 号包里了。

**延迟确认并没有直接提高性能，它只是减少了部分确认包，减轻了网络负担**。有时候**延迟确认反而会影响性能**。微软的 KB 328890 提供了关闭延迟确认的步骤。我在另一台客户端 10.32.200.131 上实施这些步骤后，结果如图 2 所示，果然不到 1 毫秒就发确认了（参见 6 号包和 7 号包的时间差）。
图 2
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131105844.png)
仔细看图 1 和图 2，会发现每个 SSH Request 都是 52 字节，这表明它只包含了
一个加密的字符。虽然在图 1 的 12 号到 18 号包之间的 100 毫秒里（还不到一个往返时间），我一共输入了 7 个字符，但这些字符也被逐个打成小包了。能不能设计一个缓冲机制，把一个往返时间里生成的小数据收集起来，合并成一个大包呢？**Nagle算法就实现了这个功能**。这个算法的原理是：==在发出去的数据还没有被确认之前，假如又有小数据生成，那就把小数据收集起来，凑满一个 MSS 或者等收到确认后再发送==。图 3 是我启用 Nagle 之后的新实验，第一个包把我输入的第一个字符发出去了。

在收到确认包之前的 150 毫秒里，我又输入 6 个字符。这 6 个字符并没有被逐个发送，而是被收集起来，等收到 2 号包之后，从 3 号包里一起发送。这就是为什么 3 号包携带的数据长度是 312 字节。
图 3
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131108167.png)
和延迟确认一样，Nagle 也没有直接提高性能，**启用它的作用只是提高传输
效率，减轻网络负担**。在某些场合，比如和延迟确认一起使用时甚至会降低性能。微软也有篇 KB 指导如何关闭 Nagle，但是一般没有这个必要，原因之一是很多软件已经默认关闭 Nagle 了。比如打开 Putty，到“Connection”选项里可见“Disable Nagle’s algorithm”默认就是选中的，如图 4 所示。
图 4
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131107952.png)
我启用 Nagle 的另一个原因是，很多高手说自己解决过 Nagle 所导致的问题。
我希望自己也能碰上一回，这样以后伪装成高手时就有谈资了，可惜目前为止还
没机会碰到。我曾经拿到过图 5 所示的一个包，据说是 Nagle 导致了写文件很慢。
之所以定位到 Nagle，是因为客户端收到“SetInfo Response”之后，要等上 100
多毫秒再发送下一个“SetInfo Request”。他们怀疑是客户端在这 100 多毫秒里忙
于收集小数据。
图 5
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307131107802.png)
我一开始非常高兴，以为终于碰到一回了。仔细一看非常失望，因为这个症
状并不符合 Nagle 的定义。**Nagle 是在没收到确认之前先收集数据，一旦收到确认就立即把数据发出去，而不是等 100 多毫秒之后再发**。如果说这个现象是延迟确认还更接近一点，但也不正确。它实际是应用层的一个 bug 导致的，换了个 SMB版本后问题就消失了，我就这样错失了一次伪装成高手的机会。

为了让大家更好地理解它，我们再做个对比实验：我在笔记本上关闭了延迟确认，然后再次连接悉尼的服务器。从图3可见2号包和3号包之间几乎没有时间差了（只有0.000121秒，可以忽略）。
图3
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307071444790.png)
**启用延迟确认是有好处的**，==假如在这等待的200毫秒里，上海的笔记本恰好有数据要发，就可以**在发数据时捎带确认信息**（也就是一般的seq+ack），省去了（而不是发送）一个纯粹的确认包==（还有一种可能？就是如果悉尼还有数据包过来，可以累积确认？？）。图4就符合这种情况。笔记本收到11号包之后，等了41毫秒左右（即11号包和12号包之间的时间差）**恰好又有一个SSH请求要发，就顺便把确认捎带过去了，因此省掉了一个纯粹的确认包**。之所以有很多TCP协议栈默认启用延迟确认，正是基于这个原因——**少一些确认包可以节省带宽嘛**。
图4
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307071446229.png)
延迟确认的坏处也很明显，就是**会凭空多出一段延迟**。这个机制的作用==很像你中午懒得去食堂吃饭，便等到下午出门上课时顺便去吃一点。结果就是少跑了一趟食堂，但是吃饭时间却被延后了==。

理解了延迟确认的原理，我们再回顾VMware的那篇文章。一般来说，偶尔浪费200毫秒的等待时间并不算严重的问题，VMware为什么要这么在意呢？又不是等待很多个200毫秒。当我联想到“很多个”时，终于明白了——**这世界上还真的存在一种很老的TCP的实现**（RFC2582），会导致拥塞时出现多个200毫秒的等待时间。详情且看下文分析。

图5从客户端的视角演示了启用延迟确认时，**某些TCP协议栈在处理网络拥塞时的状况**。图5这个传输过程发生了以下事件。
1．客户端在同一时刻（或者说同一窗口）发送了9个TCP包，其中3、4、5号因为拥塞丢失了。
2．到达服务器的6、7、8、9号包触发了4个“Ack3”，于是客户端快速重传3号包，此时**它并不知道4号包也丢了**。（见NewReno+延迟确认）
图5
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307071448279.png)
4．客户端重传4号包，然后服务器又等待了200毫秒才回复Ack5。
5．客户端重传5号包，然后服务器又等待了200毫秒才回复Ack10。
6．客户端传输新的10号包，自此该网络拥塞就完全恢复了。

由于当时没有抓包，因此**以上分析仅是我的推测**。还有另一种可能是**在某个200毫秒的延迟过程中，那些丢包的RTO（RetransmissionTimeout）已经被触发，所以进入了超时重传阶段**。无论符合哪一种可能，性能都会严重下降，因此VMware建议关闭延迟确认是很有道理的，只不过没把原理说清楚。我甚至怀疑写这篇文章的人也没真正理解，因为里面还提到了慢启动之类不太相关的东西。

假如把延迟确认关闭掉，那该TCP协议栈处理拥塞的过程就变成图6所示。包还是那些包，不过**浪费在延迟确认上的600毫秒就省下来了**。**只要往返时间不是太长，那些丢包也不会触发超时重传**，所以避免了第二种可能。
图6
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307071451982.png)

我把分析结果告诉了那位读者，确保这个修改没什么副作用。于是他壮着胆子关闭了延迟确认，果然VMware的性能就飙升了。图7是他在关闭之后抓的网络包，和上文分析的一模一样，果然连续丢了很多包，而且每个重传都需要确认一次。
图7
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307071452505.png)

我以前分享的案例都是先在Wireshark中找到症状，然后再结合协议分析找到原因的。而这次纯粹是依靠协议分析，预测能从包里看到什么，然后再用Wireshark验证的。听起来似乎是完全靠灵感，**但灵感不是天生的，它来自长期的训练**。==只有在Wireshark中看过了延迟确认和大量重传的样子，才可能意识到它们放在一起会出大问题==。
>注意：如果对那篇VMware的文章感兴趣，可以在其知识库http://kb.vmware.com中搜索1002598来找到它。