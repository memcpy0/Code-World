第一篇介绍了我主导开发的一个网络性能分析网站，也许它的功能不是你需要的，但**开发过程可以参考**。比如说，你也可以利用tshark命令开发一个监控上网记录的工具，用`tshark-r(file_name)-Y"http.request.full_uri"-Tfields–ehttp.request.full_uri`一句命令就可以生成原始数据，然后再编程做二次分析。

第二篇介绍了网络加速器，现在才创业做这个显然太晚了，不过Wireshark很适合用来分析加速器的很多知识点，在实际中也大有用武之地。
# 打造自己的分析工具
Wireshark好不好？当然好，几乎称得上业界最好，否则我也不会为它写了两本书。不过话说回来，再好的工具也有改进的空间，比如我能看到的不足之处就有两点。

对于特定职业的人群来说，Wireshark的很多功能是完全用不到的。
- 比如同一个公司的开发团队和运维团队，说起来都在用Wireshark，但实际上使用的是完全不同的功能。
- 初学者上手时根本不知道哪些功能适合自己的工作，不得不在探索上浪费很多时间。
- 每个人常用的功能就那么几个，却分布在不同的菜单里，有些还藏得很深。比如要查看NFS的读写响应时间，需要点五次鼠标才能找到，初学者根本记不住。

有没有办法“定制”一个分析工具，只提供我感兴趣的功能，而且简单到一键就能完成分析呢？也许在工业4.0时代会有这个服务，不过在此之前，我们只能自己开发了。今年我就和同事做了一个，本文详细地加以介绍，希望对你有些参考价值。

我们的项目需求是这样的。我司有很多团队需要和网络打交道，比如虚拟化、云计算、网络存储、镜像和备份等。大多数网络问题都很好解决，但性能问题却是公认的难点。==我司的这些团队成员都具备网络基础知识，比如熟读《TCP/IP详解卷1:协议》，但是缺乏网络包分析技能，也没有时间学习Wireshark==。假如有一个专门的工具来分析网络性能，生成的分析报告也简单易懂，肯定会大受欢迎的。

我期望这个工具能好用到什么程度？无需任何培训，只要丢个网络包进去，一份人人可以读懂的分析报告就出来了。考虑到这些团队在地理上非常分散（住在不同国家），行政上也属于不同部门，我决定把这个工具做成Web的形式，以便推广和维护。

接下来就通过一个真实的案例，演示一下它究竟有多好用。
## 案例症状
用户抱怨某系统运行起来非常慢，这个系统的功能是处理一些网络存储上的数据。排查过程
1．把一些要处理的数据复制到该系统所在的本地硬盘，运行速度就上去了，说明该系统本身没有问题。
2．网络工程师经过一系列检查，在网络上没有发现任何问题。
3．存储工程师看到存储的响应非常快，所以也没有发现问题。每一方都号称自己没有问题，那用户该怎么办？最后只好抓了个包，上传到我们的工具上分析。

图1就是该工具的首页，它的全称为NetworkPerformanceAnalyzer，简称NPA。用户唯一需要做的就是把网络包拖进方框，然后点一下Upload按钮。
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307121802462.png)

几秒钟后，分析报告就出来了。从上往下分别是“概况分析”、“应用层分析”、“传输层分析”等，下面我会逐项介绍。

图2显示的是“概况分析”，目的是给用户呈现一个直观的性能状况。比如“Databytesrate：22kBps”和“Captureduration:900seconds”，表明在抓包的900秒里，平均性能才22KB/s，实在是很差。流量图的柱体高度起伏不大，说明这段时间内传输均匀，没有爆发性的流量或者暂停。
图2
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307121803002.png)
接下来是“应用层分析”，具体可见图3。该工具自动判断出这个包的应用层协议是NFSv3，因此把NFS响应时间（ServiceResponseTime，SRT）和IOSize统计了出来。从图中的第一个方框可见READ的平均响应时间是0.226毫秒，算非常好了。可是**从第二个方框却看到每次读的数据量只有975字节，还不到1KB，实在是太小了**。这就像用货车从北京往上海运1000个包裹，假如每次能运100个，那10个来回时间就搞定了。而假如每次只能运1个，就得跑1000个来回，那浪费在路上的时间就非常可观了。

因此，这个案例的解决方式就是调整软件的IOSize，增大到每次读64K字节，性能立即得到大幅度提升。

你可能会好奇，为什么同样的IOSize，处理本地硬盘上的数据就没有性能问题呢？这就是网络的弱点了，==TCP/IP几层处理下来，总会增加一些延迟的。当来回次数特别多的时候，延迟的效应就被放大了==。
图3
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307121823193.png)

既然在应用层就已经找到症结，我们也没必要再去看传输层了。不过传输层可是性能问题的高发区，也是这个工具的特长之处，所以我忍不住再给大家看两个案例。

图4是VMware性能差的案例。抓包分析后，**发现总共250秒的抓包时间里，有190.8秒被浪费在延迟确认上了**，用上这工具之后简直就是秒杀。由于本书是黑白印刷的，所以看不出该工具已经把出问题的提示文本设置成红色背景，实际上是非常醒目的。
图4
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307121825965.png)

图5则是我上一本书的《深藏功与名》文章中提到过的某银行案例，**根本原因是网络拥塞导致的丢包，而且SACK也没有启用，两个根源都被这工具分析出来了**。当时要是用上这工具，也是很快就能解决的。
图5
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307121837091.png)
可以说，我司的大多数网络性能问题都可以用这个工具找到症结。有很多团队已经从中受益，因为他们不用再请林沛满吃饭看包了，自助就能完成。我当然也很高兴，因为得以摆脱耗时的重复性劳动，有了更多的时间可以带娃。看到这里，不知道你是否也想**打造一个适合自己职业的分析工具**呢？

有兴趣的话可以参考我的开发过程，大致可以分为三步。
- 第一步：收集旧问题。我们不可能开发一套具有人工智能的程序来分析网络包。换句话说，**自己打造的工具本质上不会比Wireshark更聪明。不过我们可以把自己的工作经验“传授”给这个程序，使它看上去比Wireshark智能很多**。要如何做到呢？==世界上绝大多数故障都不是第一次发生的，有经验的工程师可以把处理过的旧问题收集起来，归纳出每个问题在网络包中各有什么特征==。
    以后抓到新的包，就可以用这些已知特征逐个去套，一旦发现匹配得上的就提示用户。比如我已知有20个原因会影响网络性能，每个原因在网络包中都会有一些特征，就可以在新抓的网络包里用这20个特征去逐个匹配。一旦发现有符合的就提醒用户，就像图4和图5那样。
    Wireshark需要用户点击多个按钮才会去分析，但我们的工具会主动分析并生成报告，这对用户来说就是智能化的体验。==不只是网络性能问题，任何网络相关的技术领域都可以采用这个方法==，比如从事WindowsDomain相关工作的技术人员，可能保存着上百个常用的微软KB，其中包括DNS解析出错、Authenticator过大、UDP包被切分丢弃，等等。这些问题都可以在网络包中以某个特征体现出来，因此也可以写成程序去匹配。网管员做监控也是如此，很多场景都是固定的。
    **把这些旧问题收集好了，就已经向成功迈出一大步**。不过实际做起来可没那么轻松，你也许需要召集团队中最有经验的工程师，收集他们的需求和抓过的网络包，然后再筛选和测试。在这一步收集到的旧问题有多全面，就决定了你做出来的工具有多强大。
- 第二步：用tshark来做匹配。tshark是Wireshark的命令行形式，适合被其它程序调用来分析网络包；再加上其分析结果是文本输出的，所以作二次加工也很方便。基于这两点，选用tshark来匹配已知的特征是最合适的，如果你已经在上一步整理出了20个特征，那么再编辑20条tshark命令就基本可以搞定了。tshark命令的使用方法在上一本书中已经介绍过，这里就不重复了。简单举个的例子，已知性能问题的特征之一是TCP重传，那执行下面的命令就可以匹配了：
    输出示例如下：
    图6
    ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307121841766.png)
    在图6的输出中，列1的Frames表示所有重传包数，列2表示从IP_A到IP_B的重传包数，列3表示从IP_B到IP_A的重传包数。有了这些值，就很容易统计重传率和重传方向。当你不知道某个特征所对应的tshark命令是什么的时候，可以尝试从Wireshark中把它找出来，然后右键点击该特征，选择“Prepareafilter”→“Selected”，就可以在过滤栏生成表达式了，如图7所示。
    有了这个表达式就很容易应用到tshark命令中。
    图7
    ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307122053965.png)
     有些命令是不能用这个方法找到的，只能自己查tshark的官方文档了，链接为http://www.wireshark.org/docs/man-pages/tshark.html。**tshark命令真的非常强大，如果用得好，可以实现很多专业软件特有的功能**。这一步的tshark命令写得有多精确，就决定了你开发出来的工具有多可靠。
- 第三步：**程序化**。到这一步，你已经整理了很多常见的问题，并知道如何用tshark命令来匹配它们，是时候写个程序来完成整项工作了。比如说，上一步从tshark输出中得到了重传的包数，那就可以用程序来计算重传率，并决定是否应该通知用户。这个程序可得好好设计，因为它关系到运行效率（当你抓到的网络包非常大时，就会发现运行效率是极其重要的，否则等半个小时都没有结果）。
    举个例子，应用层上有HTTP、FTP、iSCSI、NFS、CIFS等协议，每一个协议都有不同的问题，每个问题又对应着不同的tshark命令。**我们总不能拿到一个网络包，就把所有tshark命令都运行一次吧？那样效率太低了**。正确的方法是让程序先判断包里的应用层协议是什么，然后再调用其相关的命令。
    那怎样知道抓到的包是什么协议的呢？我们可以根据端口号来判断，比如端口号为80时，就调用HTTP相关的命令；端口号为445时，就调用CIFS相关命令……还有些实在无法用程序自动判断的，可以由用户来辅助完成。比如在页面上提供多个按钮，对应着不同的协议，让用户自己选择。
    总而言之，产品经理必须非常熟悉业务流程，才能把这个程序写得高效、科学、友好。那用什么语言来写这个程序最好？这个没有定法。我们早期是用Perl写的命令行脚本，开发简单，运行速度也快。但它也有致命的缺点，就是界面不美观，推广和升级也很麻烦。后来我们改用Python+Flask做成了Web的形式，还请专业美工人士设计了界面，效果就好多了。
- 作为一个有强迫症的伪产品经理，我还想强调细节的重要性，比如网络包分析过程中，一定要在页面上显示一个转动的菊花来延长用户的耐心，见图8。不要小看这种小细节，如果分析时间超过三分钟，又没有菊花在转动，用户很可能以为程序已经死了，然后就点刷新，又得从头再来一次。对细节的重视程度，很大程度上决定了这个工具的用户体验。
    图8 
    ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307122053697.png)

这个工具就介绍这么多，希望对你有参考价值。如果你在开发过程中遇到什么问题，也欢迎进一步交流。**困难肯定会有的，但只要肯动手去做，你就成功了一半**。
# 一个创业点子
上周还听到一位从阿里离职的工程师在怂恿同伴出来一起开发手机APP，展望前景的语气让我想起了安利的培训。其实我六七年前也产生过一个稍纵即逝的创业念头。与现在流行的P2P、O2O等概念不同，那时的IT创业主要集中在传统的技术领域，比如我老板做的数据迁移设备就卖了一个很好的价钱。有趣的是那产品两年后就被淘汰了，命运跟现在的初创公司很像。而我当时想做的是一个网络加速器，它究竟是个什么东西呢？

细想起来，它跟我之前讲过的很多技术都有关联，不如最后一篇就写写它吧，就当作知识总结。那几年我接触了世界上很多知名公司的数据中心，发现他们都有一样的痛点，即跨站点（site）的网络存在性能瓶颈。比如图1这样的环境中，纽约的用户访问伦敦的文件服务器，或者两边的数据库做同步，都会慢得出奇。
图1
![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307122054050.png)
这类问题排查下去，一般会归根于带宽不足，解决方式就是花钱购买更大的带宽。然而很少人知道还有一个不花钱的办法，就是==通过传输层（基本都是TCP）的调优来提高带宽利用率，从而提升性能体验==。那时候我已经学会了分析网络包，知道传统的TCP协议栈不能很好地应对跨站点的场景，所以带宽利用率偏低。有些严重的甚至在50%以下，因此存在很大的提升空间。比如客户从我司购买的文件服务器在跨站点时访问不快，但经过专业调优之后，性能可以提升两倍以上。这就是商机所在：既然可以通过调优的方式来达到和购买带宽一样的效果，我们就有了盈利的空间。

接下来的问题就是怎样做成一个产品了。人工调优能做到的事情，理论上程序也可以做到。因此最早想做的产品是**改进型的TCP协议栈**，装在服务器上，使它在跨站点场景中能够更智能地工作，达到人工调优后的效果。不过很快就发现这个路子走不通，原因有三。
- 有很多操作系统不允许修改原有的TCP协议栈。比如我司的服务器就是完全封闭的，第三方厂商根本不知道怎么修改。
- 有些服务器虽然就是普通的Linux或者Windows，技术上能够修改，但厂商声明一旦动了协议栈就不再提供技术支持。
- 即使服务器都用上了改进过的协议栈，也会受到客户端配置的约束，难以充分发挥。比如在客户端关闭了TCPTimestamps（RFC1323），那在服务器上计算RTT（往返时间）时就会受到影响；或者客户端关闭了SACK，那在服务器上启用SACK也没有意义。没有用户愿意为了改善跨数据中心的访问，而大动干戈地对服务器的TCP层作出改动。万一改动之后影响了本地访问性能怎么办？
- 注意：这三点只说明该产品不适合本文所针对的场景，而不是说它没有价值。**事实上它在有些场景下可以工作得很好，现在也已经有商业化的产品了**，比如硅谷有家叫AppExNetworks的公司推出的单边加速器ZetaTCP就不错。我后来才发现其CEO是位华人，在北京也有分公司。

市面上还有一些很滑稽的加速器，比如通过每个包发两次来避免丢包的，在我看来就是浪费流量的七伤拳，不建议采用。既然这个路子完全走不通，我们只能设计一个不同的产品了，它至少要满足以下需求才行。
 - 它不需要对服务器或客户端的TCP协议栈作任何改动，所以实施的障碍会小很多。
 - 它完全独立工作，所以不受客户端和服务器上的TCP设置所影响。比如客户端上没有启用SACK时，它也能处理好连续丢包的问题。
 - 它只用于改善跨数据中心的的网络性能，对本地访问毫无影响。
 
 需求一旦明确，解决方案便呼之欲出了。如图2所示，**只要在两个站点的出口各自架设一台加速器，代理两个站点之间的所有TCP连接，就可以满足以上所有需求**。由于每台加速器与同站点设备之间的网络状况良好，所以**瓶颈只会落在两台加速器之间的网络上**，我们只需花心思提升这段网络的性能即可。
 
 也许有些读者看到这里会觉得好笑，现在这种加速器在国内外至少有十个牌子，连开源项目都有了，你还创什么业啊？现在的确是成熟的市场了，但是当年可完全不是这样，尤其没有听说过国内的公司。我也只是因为分析了足够多的网络包，便自然而然地萌生了引入加速器的念头。技术之外的话题就不多说了。
 图2
 
 我们先来分析一下这段网络存在什么问题，才能对症下药，总结下来主要有两个大问题。
 - 问题一：延迟高。位于同一站点的两台设备之间往返时间一般也就几毫秒，而跨城网络的往返时间可能达到几十毫秒，跨国网络甚至可达上百毫秒。高延迟为什么会影响性能呢？因为它会造成**长时间的空等**：发完一个窗口的数据量后，发送方就不得不停下来等待接收方的确认。**延迟越高，发送方需要等待的时间就越长**。一图胜千言，图3演示了发送窗口都是2个MSS，延迟时间分别为10毫秒和20毫秒时的传输过程，可见后者效率只有前者的1/2。这好比用同一辆货车运货，从上海运到江苏肯定比从上海运到北京快得多。
     图3
     ![](https://image-1307616428.cos.ap-beijing.myqcloud.com/Obsidian/202307122056261.png)

    有时候我们会在Wireshark中看到［TCP window Full］的提示，就表明发送方进入了等待状态。这种症状在跨站点通信时是很常见的，具体可见本书《Wireshark的提示》一文中的图9。那么这个问题要怎么解决呢？**在延迟时间无法减少的情况下，发送窗口越大，性能就越好，所以要尽可能增大窗口**。

- 问题二：丢包率高。丢包一般分两种情况：**一种是网络质量差导致的零星丢包**；**另一种是拥塞导致的大量丢包**。跨站点通信时这两种丢包概率都会增大，尤其是后者。这是因为链路上的情况比较复杂，而且不同的TCP连接会“恶意”地争夺本来就有限的带宽。比如图2中的文件服务器、数据库和邮件服务器等建立的TCP连接会各自为政，互相争夺带宽，直至发生丢包才停下来。这种情况很像上海马路上的车辆，为了加速而变道的车多了，就容易诱发交通事故。
    **丢包对性能的影响极大，可以说是网络传输的第一大忌**，具体原因我都在上一本书中阐述了，这里再简单解释一下：==传统TCP的流控机制是一旦丢包就认为发生了拥塞，所以发送方会急剧地减小发送窗口，甚至进入短暂的等待状态==（即超时重传）。1%的丢包率不只是降低1%的性能，而可能是50%以上。这个问题有办法缓解吗？也有。
    首先可以尽可能降低丢包的概率，比如**提前预测并采取措施避免拥塞的发生**；其次是**更精细地处理丢包后的流控，避免过度限流**。
    
一番分析下来，发现这两个问题还是很棘手的，但是不用担心，我们还手握王牌呢——在加速器上可以大做文章，大幅度缓解这两个问题所带来的影响。作为一个创业奸商，其实我们应该希望影响尽可能严重，带宽利用率最好在50%以下。因为这意味着留给加速器的提升空间就大了，客户购买之后能看到明显的效果，才会觉得物有所值。接下来要介绍的就是缓解这两个问题的措施，也是我们这个加速器的技术含量所在。
- 措施1：**启用TCP window scale**。这样可以使最大接收窗口从65,535字节（老的Windows操作系统甚至只有17520字节）增加到1,073,725,440字节。发送窗口是受接收窗口和拥塞窗口共同限制的，启用TCP window scale之后，**接收窗口就几乎限制不到了，当然内存也要跟得上才行**。关于TCPwindowscale的更多信息，可参考本书的另一片文章《技术与工龄》。
- 措施2：**监测延迟来避免拥塞**。网络包是以队列的方式通过网络设备的。当拥塞即将发生时，队列变长，延迟就会显著提高。我做了一个从台湾机房往上海机房传数据的实验，一般情况下的往返时间为74毫秒（见图4方框中的RTT），而拥塞丢包发生前会逐渐增加到1.69秒以上。根据这一特点，**我们可以让加速器在延迟明显增加时，自动放慢发送速度，从而避免拥塞的发生**。
    图4
    这==其实就是TCPVegas的理念。它用在服务器上时不见得很好，甚至有负作用==。想象一台启用了传统TCP协议栈的服务器和一台启用了Vegas的服务器抢带宽，当拥塞即将出现时，用Vegas的那台监测到了延迟并主动放慢速度，从而缓解了拥塞，但传统的那台却得寸进尺，一直激进地抢带宽。最终结果可能是传统的那台反而赢了——劣币淘汰良币。
    而在加速器上引入Vegas理念就不一样了，由于每个TCP连接都是一样的算法，所以**预测到拥塞时大家可以集体放缓，从而保证了公平性**。这就像马路上每位司机都礼貌谦让，就不会发生事故，整条马路的通行效率也提高了。
    除了能预测拥塞，==监测延迟时间还有助于区分零星丢包和拥塞丢包，因为发生零星丢包时的延迟一般不变==。
    区分它们有什么意义呢？**传统TCP协议栈遇到丢包都一律当作拥塞处理，立即放慢速度甚至暂停。这样一刀切并不科学**，零星丢包时重传一下就行了，没必要放慢速度。
- 措施3：**利用发送窗口实现优先级**。两个站点之间存在很多连接，且优先级各有不同，比如数据归档的优先级就可能低于其它应用，可以传慢一点。我们的加速器代理了两个站点之间的所有连接，因此很容易通过调节各个连接的发送窗口来实现优先级控制。优先级低的连接变慢了，就可以把带宽让给优先级高的连接，用户体验就会更好。
- 措施4：启用SACK。**SACK即Selective Acknowledgment，它是处理拥塞丢包时的法宝**，尤其是在高延迟的跨站点环境中，详情可参考本书的另一片文章《来点有深度的》。**SACK必须在发送方和接收方都启用**，这就是我们在两边各架设一台加速器的优势。单边TCP加速器的效果很可能因为另一端没有启用SACK而大打折扣。
- 措施5：**改进慢启动算法**。传统的TCP协议栈采用了非常保守的慢启动算法，即把拥塞窗口的初始值定义得非常小，不能大于4个MSS。而且一旦发生超时重传，又要从头进入慢启动阶段，如图5所示。
    图5
    这就意味着传输过程中至少有一段时间的窗口极小，效率非常低。随着硬件的更新换代，现在的网络带宽已经今非昔比了，完全没必要如此保守。作为一个专业的TCP加速器，我们有必要在这一点作出改进。比如赋予发送方一定的“智能”，**使用大一点但仍然安全的初始值**。根据我的经验，在这一块是很有提升空间的，因为传统的TCP协议栈的初始值在现代网络中显得实在太小了。
    措施6：**启用TCPT imestamps**。在本书的《一篇关于VMware的文章》一文中，已经介绍过**延迟确认是如何影响性能的**。不难理解，它也会严重影响RTT的统计。**我们需要精确地监测延迟时间来预防拥塞**，就必须在两边都启用TCP Timestamps（见RFC1323的RTTM一节）来排除延迟确认等因素的干扰。**这也是双边加速的好处之一，在服务器上单边加速时很难排除客户端的干扰**。

总结下来，这些措施合力实现了这样的效果：
- 在起步的时候，它传输得更快；
- 在抢夺带宽的时候，它更懂得谦让；
- 在出现拥塞时，它恢复得更迅速。
- 此外它还能在一定程度上避免拥塞，识别零星丢包等等，因此流量可以稳定在高位。

加速前后的某个TCP连接，流量变化大致可以用图6来表示。图6本文提到的这些措施我大多验证过，由于实验室中不存在高延迟，我还搭了一台专门制造延迟和丢包的路由设备来仿真。其中部分措施更是在用户环境中验证过多次。因此可以信心满满地说，这个加速器在技术上是完全可行的。那现在市面上的加速器采用的也是这些技术吗？

从部分公司所公布的文档上，我的确看到了一些交集，当然它们**还用到了压缩和消重等TCP之外的技术**。Wireshark在加速器领域也是大有可为，这就是为什么它的主要捐助者是加速器的领头羊Riverbed。